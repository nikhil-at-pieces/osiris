[
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 2, 2025 Tsavo <> Growth team Invited Smit Patel Tsavo Knott Nikhil L Ellie Zubrowski Ali Mustufa Shaikh Laurin McNulty Jack Ross Thaymisan Cavalcante Hanna Stechenko Attachments Tsavo <> Growth team Meeting records Transcript Summary The meeting focused on integrating AI across all growth team functions to automate tasks, improve KPIs with fewer resources, and assess the impact of AI on individual roles over the next 30 days. Tsavo Knott and Smit Patel emphasized experimenting with AI tools like GitHub Copilot and ChatGPT projects to automate workflows and encouraged sharing discoveries, while Thaymisan Cavalcante raised considerations for design-specific AI. The team agreed that June will be dedicated to AI exploration and upskilling, with a shift in growth sync focus towards AI integration and sharing related learnings. Details * AI Integration Across Teams Tsavo Knott discussed a new Google setting to enable notes for all meetings, leading to a large dataset of information. The goal is to use AI to automate tasks like generating social media posts from release notes and leveraging AI across all growth team functions, identifying tools, their limitations, and how they complement team roles. Tsavo Knott highlighted that GitHub Copilot, Cursor, and Claude are already in use, and the team should maximize their potential (00:01:14). * Rapid Prototyping Example Tsavo Knott shared an example where Nolan Judson and their team rapidly rebuilt HashNode's editor experience using Lovable and Cloud Code within 48 hours, demonstrating the potential of AI tools for quick development. This showcased how non-technical individuals can leverage these tools effectively, leading to significant productivity gains (00:01:14). * Focus on KPI Improvement with AI Tsavo Knott emphasized the company's objective to accelerate KPI growth with fewer human resources by extending individual productivity through AI. Tsavo Knott and Smit Patel will dedicate June to evaluating AI integration within the growth team rather than team performance itself. The team has a \"blank check\" for relevant AI tools to experiment with (00:02:15). * Evaluating AI Impact on Roles Tsavo Knott outlined a plan to assess the impact of AI tools on each team member's role over a 30-day period, comparing before and after productivity. This evaluation aims to identify repeatable AI-powered playbooks that can be shared across the organization to improve KPIs. Tsavo Knott plans to report on these findings at the end of June (00:03:19). * Integrating AI with Existing Systems Tsavo Knott mentioned the development of systems to capture organizational data (releases, fixes, support tickets) to enable team members to use AI tools for improving content like landing pages and videos. While acknowledging a learning curve, Tsavo Knott stressed the necessity of embracing AI to remain competitive. The initial testing on the edge side has shown promising results (00:04:21). * Sharing AI Projects and Discoveries Ellie Zubrowski shared their experience using ChatGPT projects trained on specific communication styles for tasks like generating reply options and writing articles (00:05:12). Smit Patel echoed this, explaining how they use a ChatGPT project trained on their own style for drafting tweets quickly (00:06:07).",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "support tickets) to enable team members to use AI tools for improving content like landing pages and videos. While acknowledging a learning curve, Tsavo Knott stressed the necessity of embracing AI to remain competitive. The initial testing on the edge side has shown promising results (00:04:21). * Sharing AI Projects and Discoveries Ellie Zubrowski shared their experience using ChatGPT projects trained on specific communication styles for tasks like generating reply options and writing articles (00:05:12). Smit Patel echoed this, explaining how they use a ChatGPT project trained on their own style for drafting tweets quickly (00:06:07).",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Smit Patel suggested moving beyond individual prompts to automating entire workflows using AI and workflow tools to increase efficiency (00:07:17). * Embracing Imperfection and Speed Smit Patel emphasized that as a startup, perfection in AI implementation isn't necessary; achieving 90% functionality and focusing on rapid iteration is acceptable (00:08:10). Smit Patel noted that the current go-to-market landscape is heavily disrupted, requiring everyone to upskill and reposition their roles by leveraging AI for routine tasks. Smit Patel highlighted that human taste and creativity remain essential elements that AI cannot replace (00:09:10). * Automating Workflows and Building Playbooks Tsavo Knott urged the team to research how AI can automate their pipelines and identify easy automation opportunities using tools like OpenAI and Perplexity (00:10:58). The focus should shift from using AI for individual tasks to building AI systems that run continuously and automate significant portions of work (00:15:08). Smit Patel elaborated on this, distinguishing between asking AI individual questions and creating automated workflows or playbooks using AI tools (00:16:58). * Addressing Concerns About Job Displacement Hanna Stechenko raised a question about the risk of being replaced by AI. Tsavo Knott clarified that individuals won't be replaced by AI itself, but by others who are more proficient in using these tools (00:17:56). Tsavo Knott emphasized the need to reinvent themselves and integrate AI into their thinking and work processes, similar to adapting to search engines in the past (00:18:48). * Design Team's Perspective on AI Tools Thaymisan Cavalcante acknowledged that while AI has advanced in coding, design-specific AI tools aren't as mature (00:19:57). Thaymisan Cavalcante stated that the design team already uses AI for user perspective analysis and SEO improvements and primarily builds directly in Framer, making prototyping in tools like Lovable potentially redundant (00:20:56). Thaymisan Cavalcante highlighted the need for AI tools that can work with existing design systems and components (00:22:01). * Importance of Experimentation and Adaptability Tsavo Knott encouraged the design team to still try out various AI tools like Lovable to discover potential efficiencies in their workflow, even if their current process in Framer is effective. Tsavo Knott emphasized that AI tools are rapidly evolving, and staying open to experimentation is crucial for long-term productivity and relevance (00:22:51). * Baseline AI Literacy and Domain-Specific Tools Smit Patel likened basic AI usage to knowing how to use Google, emphasizing that it's becoming a fundamental skill. Smit Patel stressed the importance of finding and testing AI tools specific to each individual's domain, guaranteeing their existence in some form. Smit Patel reiterated that AI will enhance capabilities but not replace the essential elements of taste and creativity in roles like design (00:23:50). * June as a Month for Reinvention and Learning Tsavo Knott reiterated that June is dedicated to individual reinvention through AI exploration, with a reflection on progress at the end of the month. The initial step is for everyone to research AI automation possibilities for their daily tasks using tools like OpenAI.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "domain, guaranteeing their existence in some form. Smit Patel reiterated that AI will enhance capabilities but not replace the essential elements of taste and creativity in roles like design (00:23:50). * June as a Month for Reinvention and Learning Tsavo Knott reiterated that June is dedicated to individual reinvention through AI exploration, with a reflection on progress at the end of the month. The initial step is for everyone to research AI automation possibilities for their daily tasks using tools like OpenAI.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sharing the insights and learnings from these AI explorations will be a key part of the growth team syncs throughout June (00:25:38). * Actionable Steps and Shift in Growth Sync Focus Smit Patel proposed moving the next growth sync to Thursday to allow everyone time to process the meeting and consider their workflows and potential AI integrations. Smit Patel outlined high-level AI initiatives for different team roles, including programmatic SEO, automated outbound emails, video analysis and generation, automated social content, and design workflow enhancements (00:26:44). The overarching goal for June is to upskill in AI and increase output, fostering a culture of rapid experimentation and learning (00:27:39). * Collaborative Learning and Sharing of AI Discoveries Tsavo Knott encouraged everyone to share links to their AI research conversations (e.g., ChatGPT prompts and responses) within the team to cross-pollinate learnings and insights (00:28:47). * Positive Feedback and Future Video Content Smit Patel praised Jack Ross's video, highlighting its creativity and the need for more such content (00:28:47). Jack Ross mentioned having automated parts of their video production workflow and plans to release a similar video weekly (00:29:31). Smit Patel encouraged producing even more video content, including potentially faceless videos, which can also perform well . * Clarification on AI Automation Concept Hanna Stechenko confirmed their understanding that the focus is on automating time-consuming tasks, particularly in areas like SEO . The team concluded the meeting with a positive outlook and commitment to exploring AI opportunities . Suggested next steps * Tsavo Knott and Smit Patel will work to provide systems that capture org-level data for the team to use with their AI tools. * Each team member will share a link to their AI research (e.g., ChatGPT conversation) in the group to cross-pollinate learnings. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript Jun 2, 2025 Tsavo <> Growth team - Transcript 00:00:00 Tsavo Knott: I actually spoke with Sam this morning. Uh we have a new setting in Google um to basically turn on notes for every single meeting, which means now we have, you know, across edge, across product, across ML, infrastructure, growth, like all of these notes are captured in addition to the stuff pieces is capturing. So, you know, during a release week, right, we have this huge kind of data lake of stuff. How can we dump that into a tool and kick out, you know, 14 tweets about what just got released and 14 tweets about what's coming down the line, right? And so we do product syncs with Ellie and Ollie uh once every two weeks. You know, we're talking about 2.5 local, you know, some of the the paid plans, the new models, required signin, like all these things are, you know, um in the the system in the digital content of our Google workspace. How can we use AI to like automate that stuff, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "stuff. How can we dump that into a tool and kick out, you know, 14 tweets about what just got released and 14 tweets about what's coming down the line, right? And so we do product syncs with Ellie and Ollie uh once every two weeks. You know, we're talking about 2.5 local, you know, some of the the paid plans, the new models, required signin, like all these things are, you know, um in the the system in the digital content of our Google workspace. How can we use AI to like automate that stuff, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um and then similarly you know on the website side or the design sprint side or the SEO side like every single kind of component of the growth team right now has tools that we have to figure out what are those tools how do we use them and and what are their limitations and the limitations outline what your new role as a growth team member is to complement the role that you replaced or part of the role 00:01:14 Tsavo Knott: that you replaced with these AI tools right um and so on our side like you know we're seeing it across the board. Obviously, you know, GitHub copilot, cursor, claude, enthropic pieces, like everyone on the the team, you know, they have to use these things and we're like, how do we make sure the growth team is also using these things to the max? Um, and a perfect perfect example of this is last Thursday after a couple of days um of trying to migrate the docs to Mintfi, it just wasn't working out, right? So I said, \"Hey, Nolan Judson, I know you guys aren't designers, you're not technical, you've never written code in your life, whatever else, but I want you to take the rest of the afternoon and try and build this thing out in lovable. And then of course, anything Lovable can't do, do it with Cloud Code.\" Um, and they basically rebuilt all of HashNode, like the entire editor experience, syncing with GitHub, a whole UI, like everything in a matter of 48 hours, right? We got a demo on it on a product sync this morning and the whole team was like shocked. 00:02:15 Tsavo Knott: Um and so you know it's like that for me was also a tipping point where you have you know non-designers non-technical folks you know immediately adopting these tools and using them in capacities that are surprising right so you know on our side we're forced as a company to say hey you know how do we get whatever KPI it is right whether it's number of tweets you know bookmarks impressions whatever else um or if it's number of you know page rankings or keyword hits or whatever uh how do we get whatever that KPI is up and to the right faster with less you know human resources um and and just like an extension of of yourself from a productivity perspective right and so I think you know Smid and I we're going to take June to evaluate this as opposed to evaluating the team itself and we're going to say hey how do we encourage every team member on the growth team to figure out what tools they need you know you guys have basically a blank check to say hey you know if there's a tool If it's claude code, you know, and it's max a max plan, like we'll buy it for you, right? 00:03:19 Tsavo Knott: Or if it's lovable, we'll buy it for you.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "perspective right and so I think you know Smid and I we're going to take June to evaluate this as opposed to evaluating the team itself and we're going to say hey how do we encourage every team member on the growth team to figure out what tools they need you know you guys have basically a blank check to say hey you know if there's a tool If it's claude code, you know, and it's max a max plan, like we'll buy it for you, right? 00:03:19 Tsavo Knott: Or if it's lovable, we'll buy it for you.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Whatever it might be, Figma AI, we'll buy it for you. But we want to go around, you know, everyone on this team and say, what does a singular 30-day period look like of that team member plus an AI tool and what's the before and after, right? And then we take that, we roll it up, we say, hey, you know, when we communicate to the board, we look at repeatable playbooks, right? And those playbooks are all about what's a motion you can do over and over to move that KPI up and to the right. And one of those playbooks is every single team member, how do we extend their their capability with AI? Um, and so I want to report that at the end of June. And that means that, you know, kind of June 2nd here, first Monday of the month. Um, you know, we want to set that as the groundwork, right? As like, hey, think about your role. And then every single week on growth team standup, growth team sync, you're going to not only report like what you got done, but also how you got it done as a way to share the learning, share the tools you're finding, whatever else across the org. 00:04:21 Tsavo Knott: And then on our side, we're going to work really hard to give you guys systems where it's capturing like all of the details across the org when it comes to releases, when it comes to, you know, fixes, issues, support tickets, whatever else. um as as a place for you to say, \"Hey, take in org level data, plug it into your tool, and help it make better landing pages, make better content, make better videos, whatever it might be.\" Um, that's the thesis, right? And I know there's a learning curve there. You got to go back and forth. You got to get into the tools to understand their limitations, but we have no choice but to do this, right? And go through this process. So, that's kind of where I'm at. That's where the company's at, you know, at this moment in time. We've tested it on edge side which is seeing really really promising results and I think you know you guys have a great opportunity to to put some points on the scoreboard in June. 00:05:12 Tsavo Knott: Not only points themselves but also how you scored them. I think that's that's the core result there. Um I'll pause. Any questions on some of this? I'd love to hear you know experiments that people have already done whatever else but uh I'll pause for now. Ellie Zubrowski: Um Jack Ross: Yeah. Ellie Zubrowski: I Jack Ross: Oh, sorry. Calling Ellie Zubrowski: sorry. Um one thing that I've been doing for a long time, I don't know if you guys do this, but um I have I use chat GBT and I have a bunch of projects in there.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "think that's that's the core result there. Um I'll pause. Any questions on some of this? I'd love to hear you know experiments that people have already done whatever else but uh I'll pause for now. Ellie Zubrowski: Um Jack Ross: Yeah. Ellie Zubrowski: I Jack Ross: Oh, sorry. Calling Ellie Zubrowski: sorry. Um one thing that I've been doing for a long time, I don't know if you guys do this, but um I have I use chat GBT and I have a bunch of projects in there.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Like I even have one called like Sabo um and it's literally just like trained on Sabo's um voice. So um I don't know. I think there's like 10 different projects in there. One of them is called like reply guy. So, I could just like copy something and then it'll just give me like 10 reply options. Um, I think there are some better tools like there's this one called Creator Buddy I wanted to try for a while. 00:06:07 Ellie Zubrowski: So, I don't know if you guys want to see that, but uh anyway, I highly recommend projects in chat GBT especially for like writing articles. you can put in like a bunch of files in there Tsavo Knott: Yeah. Ellie Zubrowski: and say and then give it instructions like look at all these files like multiple times and and only speak in this certain voice and then um it'll write articles like based on your projects. Smit Patel: Yeah, that's Tsavo Knott: Yeah. Smit Patel: that's a great example. Um, I I have been doing I have a project on on chat GPT and I have added you know all my previous like even going back 10 years like it's trained on my style, my tone and you know I've prompted it like a million times and that's how I'm getting my tweets done and you know it's takes me like 30 seconds. Um, so I think Elliot, what you said is an awesome example of of like the step one. What I think we need to think about right is how do we go beyond that like initial like okay you've got what's in front of you but how can you think broader like okay like how do you take what you know open AI model is allowing you to do which is like automate the creation piece but how about actually automating that entire flow right like SA mentioned earlier like say hey go and you know build a 00:07:17 Smit Patel: flow use one of these other like workflow tools out there's a million of these AI workflow tools out there um where you can say, \"Hey, go and scrape this website or go and scrape this blog and then put that, you know, and create a pipeline, put it in uh OpenAI and then have it generate like 20 tweets that are automatically scheduled automatically using another solution, right?\" So, I think that's what we we're trying to get that get at is so that your job is, you know, is just to review, right? Your job is not at that point not to go and create from scratch and you can now say, \"Okay, now I can like go and do like more projects. I can work on more initiatives, right? Because this thing is like 80% automated. Like it what used to take you like probably like a day or half a day to do. Now it's mostly automated, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "think that's what we we're trying to get that get at is so that your job is, you know, is just to review, right? Your job is not at that point not to go and create from scratch and you can now say, \"Okay, now I can like go and do like more projects. I can work on more initiatives, right? Because this thing is like 80% automated. Like it what used to take you like probably like a day or half a day to do. Now it's mostly automated, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "And of course there's going to be a little bit of that learning curve and that upfront investment, but you know that will pay off its dividend very fast. 00:08:10 Smit Patel: And you know, I think one thing that I I do want to emphasize is we're you know, we understand right like AI is not 100% there. Like that's that's a given. But I think we're a startup and we have this luxury where we don't need to be perfect. We're not a big company. We are not a Microsoft. We're not a Meta where if we ship something and it's broken or you know it's not like up to the 100% mark like it it's okay, right? If if it's 90% there, it gets the job done. That's totally fine, right? It's more about the shipping that's important because I think we're at this interesting like inception point or inflection point rather where we're like very close to getting that virality factor and we just need to like get some more hits on the board as fast as possible. So like if every person goes out you know and for example you have like programmatic SEO you've got like programmatic video creation you've got like programmatic devril you got programmatic social media stuff like design stuff like there is literally a cursor equivalent for each vertical right 00:09:10 Tsavo Knott: Yeah. Smit Patel: and I would be the first person to tell you this like even what worked six months ago is completely disrupted when it comes to any kind of go to market right uh all my experience in the last 10 years I've thrown it out of the window honestly because I think everything right now is going through a disruption. Any channel, any marketing strategy, any sales strategy like anything right every function right now is getting disrupted. So like the best thing we can do is accept that and say okay how do I upskill myself? How do I almost reposition my role, right? And use these tools to get whatever the easy parts are done and it all comes down to like the taste, right? Like cuz no like AI is not going to replace humans when it comes to taste creativity Tsavo Knott: Yeah. Smit Patel: cuz even for chat GBT you need to know what to prompt right like you need to tell it like for example I can go in there and say hey um edit this email but that's going to suck versus me going in there and saying hey you're an expert copywriter and product marketer can you edit this email now suddenly like that took you to put that prompt. 00:10:16 Smit Patel: Chad Tsavo Knott: Yeah. Smit Patel: GP is not going to tell you that. Right. So that's that's kind of the thought process we're at right now. Um Hannah, I think you had something you wanted to say.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "go in there and say hey um edit this email but that's going to suck versus me going in there and saying hey you're an expert copywriter and product marketer can you edit this email now suddenly like that took you to put that prompt. 00:10:16 Smit Patel: Chad Tsavo Knott: Yeah. Smit Patel: GP is not going to tell you that. Right. So that's that's kind of the thought process we're at right now. Um Hannah, I think you had something you wanted to say.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 13
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Hanna Stechenko: I have lots of thoughts but I don't know how to make the right questions at this moment. Tsavo Knott: I I would throw them into chat Smit Patel: Yeah. Tsavo Knott: and ask how do I how do I ask these questions? Like what are what are Hanna Stechenko: Yeah. Tsavo Knott: the most important questions to ask? Smit Patel: Yeah. Hanna Stechenko: Yeah. Smit Patel: And thank Hanna Stechenko: Well, Smit Patel: you on Chad Tsavo Knott: Yeah. Smit Patel: GBT in general. I think chat Hanna Stechenko: yeah. Tsavo Knott: Yeah. Smit Patel: GPT is like I would say base level right think there's Tsavo Knott: Right. Smit Patel: like million Hanna Stechenko: Yeah. Smit Patel: things that are out there and I know I sent some of you I always send stuff that's relevant to your domains that I see that's like that's the kind of stuff we need to focus 00:10:58 Tsavo Knott: Yeah, I would highly recommend everyone to, you know, after this call, go to, you know, OpenAI or Perplexity or whatever tool you want, whatever tool you you'd like to use, go to deep research and deeply describe like what you do in your role and then ask it, how can I automate the these pipelines, right? Like what are the easiest things to automate? What's the pros and cons? whatever else, right? Um, of course, I abstractly do not have all the details of your guys's, you know, roles, but for Lauren and and Ty, right? Like, if you guys are prototyping landing pages, it's probably easier to just describe the landing page to lovable, right? Have it crank out the landing page, circulate that to the team with a preview link, and then go ahead and build the final version of that landing page in Framer, right? To where it's like you don't have to even take the time inside of Figma or whatever else. is just like I mean I I I'll send you guys the stuff that Judson and Nolan built in a couple of of hours but it's insane right and so you know I think like you know once you do have a landing page take the whole take a whole screenshot of it drop it into 00:12:03 Ali Mustufa Shaikh: Yeah. Tsavo Knott: and say you know what do you what are your impressions of this landing page uh how do you think the funnel Ali Mustufa Shaikh: Wait. Tsavo Knott: can be tighter whatever else right and you go through all that eval before you even like loop in other team members to where you're like hey here's the eval I got from some big big models. Um, here's the the real questions that I want to get from the team. Right? So, I think like that's just again an idea about how to, you know, accelerate your role. But across the board, you know, I'm not going to have the details of what you guys do on a day-to-day.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 14
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "think the funnel Ali Mustufa Shaikh: Wait. Tsavo Knott: can be tighter whatever else right and you go through all that eval before you even like loop in other team members to where you're like hey here's the eval I got from some big big models. Um, here's the the real questions that I want to get from the team. Right? So, I think like that's just again an idea about how to, you know, accelerate your role. But across the board, you know, I'm not going to have the details of what you guys do on a day-to-day.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 15
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Just go ask, you know, these systems to do research on how you can automate a part of your your time, if you will. Um, and get things 90%. I think that's the key. Smit Patel: Yeah, I mean and you know things shouldn't to Sawa's point things shouldn't take long now because you know for example the design uh project that Sawa mentioned right like I think if Tai or Lauren if you're working on the homepage like ideally you go do a deep research you know prompt you know chat GPT to go and give you suggestions get it to that like wireframe that's like pretty much ready to ship and you know SA 00:13:09 Smit Patel: and myself can just tell you that hey like maybe go fix a couple of these words here or there like I think the goal is like the speed that's that's Tsavo Knott: Yeah. Smit Patel: what we need to get to like I think um these models are decent enough where I'm sure you know what they will tell you whether it's copy or whether it's layout is going to be like fairly good right it's going to be good enough to the point where we might just need to have like that extra Tsavo Knott: Heat. Smit Patel: 10 20% of review that needs to be done and now suddenly you know you're not you know going to like three of the other team members and saying, \"Hey, can you do this or what do you think of this? What do you think of that?\" So, it's just Ali Mustufa Shaikh: ? Smit Patel: like everyone can suddenly become have more ownership over things rather than having to rely on like different folks Tsavo Knott: Yeah. Smit Patel: um more, right? Of course, like let's say if it's an SEO question, certainly you're going to need, you know, Hannah to review it, but you know, we can get it to that 75% and then have Hannah put in that extra 15 or whatever. 00:14:00 Tsavo Knott: Yep. Smit Patel: Yeah. Tsavo Knott: And it's Hanna Stechenko: Yes, I have a question now. Finally made it up. So, um the question is um there is I think there is certainly an agreement in the team that we already use AI. Um and I think it's also from the examples that Ellie shared about the projects for scraping the website for example doing this programmatic SEO at this moment. Tai is building everything already on Figma. So, not even using prototyping. There are so many things that we are actually doing them but probably at and I'm just going to speak out for myself. I'm just not communicating them because I I don't know no one asks me or I just don't volunteer to say. Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 16
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "for example doing this programmatic SEO at this moment. Tai is building everything already on Figma. So, not even using prototyping. There are so many things that we are actually doing them but probably at and I'm just going to speak out for myself. I'm just not communicating them because I I don't know no one asks me or I just don't volunteer to say. Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 17
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Hanna Stechenko: Um so how do we then as a team articulate that with you um better like hey here's the stuff that we are doing is it maybe a part of the presentations or somehow to document it um so that there is sort of like expectations meeting reality. So we sometimes might be doing exactly the same thing but because of the miscommunication on or lack of understanding or you just don't read our minds. 00:15:08 Hanna Stechenko: That's also possible. We can explain or share and uh make things better. Tsavo Knott: Yeah. So, the short of it is we're going to take a dedicated section to the growth team syncs. And that section of the growth team sync is here's what I did this week, but also here's how I did it faster with AI, right? Like I think that's that's the goal. And you know the other thing to note is you have two types of AI, right? You have AI where you are telling it what to do over and over and over every time you have to do that task. And then the other side is AI is doing something on a cron job or based on events or whatever else for you, right? And so, you know, your goal is not just to use the AI tools, you know, when you need when you need them or when you have to do a task, but how can you build AI systems to completely automate part of your work? So now that time that you used to spend on those tasks before, even copying and pasting to OpenAI, how can you shift that time somewhere else, right? 00:16:05 Tsavo Knott: Shift that creativity somewhere else. Um, and of course like you know I would encourage everyone I mean with these tools now you can write Python scripts like which sounds intimidating but you you can right you know Smid vibe coded a whole uh like co-pilot chat like two weekends ago, three weekends ago. So you know I think that there are things where you're like hey I really really want to automate this. I do this all the time. Whatever else you can try and do it yourself. You can you know send it over to us. we might, you know, whip it up for you real fast, whatever. But think about things not in terms of how you use AI in the moment, but more so how do you have AI running continuously alongside you, right? I think that's the two mental frames, if you will. Smit Patel: Yeah, it's Hanna Stechenko: Thanks. Smit Patel: like a difference between like an individual like question Hanna Stechenko: Mhm. Smit Patel: versus a framework or a playbook, right, that you've created using AI, right? 00:16:58 Smit Patel: Like if you've got an automated workflow or that can be a playbook that you can document like that's the difference, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 18
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "in the moment, but more so how do you have AI running continuously alongside you, right? I think that's the two mental frames, if you will. Smit Patel: Yeah, it's Hanna Stechenko: Thanks. Smit Patel: like a difference between like an individual like question Hanna Stechenko: Mhm. Smit Patel: versus a framework or a playbook, right, that you've created using AI, right? 00:16:58 Smit Patel: Like if you've got an automated workflow or that can be a playbook that you can document like that's the difference, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 19
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So I think Hannah some of the examples at least so far we discussed and I'm sure there's more that you everyone's working on that obviously s and I don't have visibility but that's the difference right like going into chat GPT asking it a question is Hanna Stechenko: Yes. Smit Patel: not automating anything but Hanna Stechenko: Excellent. Smit Patel: if you if you can automate something like the programmatic SEO project we're working on like now I think the ideal case scenario right is like you can just go do that on your own where you don't need anyone else on the team to help you with right like then that's a playbook where you you know you're just doing like that 10% on it and the 90% is being done for you using an agent or some you know automation. I mean even like something basic like Zapier right that still counts at the end of the day right like I think AI is being used like broadly right now for even the stuff that was being done using Zapier before but that's the idea right AI automation it's kind of all the same 00:17:56 Tsavo Knott: Yeah. Yeah. Hanna Stechenko: And I have a second part more philosophical. How we do not fall fall in the loop of being replaced in six months. Tsavo Knott: No one's gonna Smit Patel: answer to Tsavo Knott: Yeah. No one No one's going to replace you. The only thing that's going to replace you is someone else who knows how to use these tools better than you do, Smit Patel: Exactly. Tsavo Knott: right? Like I I think that's that's the short of it is, you know, it's just like when Google came out, like you had a whole generation of people that figured out how to search for things on Google, how to navigate things, whatever else. You got people that were very good at Googling, right? And you know, it's like, you know, kids entering school these days for university, it's like they have to figure out how to use these tools to stand out in their career, right? and you're going to have a whole new generation of students and talent and digital workers that are AI natives. 00:18:48 Tsavo Knott: And so on our side, like to Smith's point, um we have to reinvent ourselves, right? And and figure out how to use these tools and extend, you know, the way we think about things, the work we do, whatever else, extend it into the AI kind of world, if you will. Um and even the way that developers are writing code is completely changed, right? Like on our side, we're we're writing so much more code. We're shipping so much more code. Like I I refuse to even review a PR unless someone who's sending me that PR took every single file and ran it through Cloud4 opus with extended thinking before they send me the PR, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 20
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "tools and extend, you know, the way we think about things, the work we do, whatever else, extend it into the AI kind of world, if you will. Um and even the way that developers are writing code is completely changed, right? Like on our side, we're we're writing so much more code. We're shipping so much more code. Like I I refuse to even review a PR unless someone who's sending me that PR took every single file and ran it through Cloud4 opus with extended thinking before they send me the PR, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 21
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "I'm like, do not waste my time with this review until this thing is like maxed out on the models, right? Um, and that's that should be, you know, everyone on on this side, too. Um, you know, and I think like Ty and Lauren on your guys side, you know, using two systems together, full page screenshot of the website, drop it into ChatgPT and say, \"Hey, uh, I'm a designer and I also have I I also have my my boss, right, who's an exec, you know, and I need to figure out a way to make the site look good and communicate the value prop. 00:19:57 Tsavo Knott: Um, and I need to describe to someone exactly how to rebuild it or exactly the changes we want to make to it.\" take whatever OpenAI gives you on the back side of that, go over to Lovable, drop it in and say, \"Build me a new prototype of this landing page, right?\" And like it can do that and you say, \"Tell me about the brand styles, the color schemes, the flow, everything like that.\" And now you don't have to go to Lovable and say like, \"Let me reprompt all of this stuff over and over.\" You just take a snapshot analysis, pass it into Lovable, and then you can start to prototype, right? where that might be a faster way to do it than building it over and over again in framework each time. Yeah. Questions on that. Thaymisan Cavalcante: uh from the design perspective I think it's a little unfair to compare with engineering given that it's how AI started like building and and coding for you um I don't think from the design perspective we are there yet there are there are new tools that are coming here even 00:20:56 Tsavo Knott: Yep. Thaymisan Cavalcante: Figma is not even like that big of a deal if you think about it it's just like renaming layers and like other stuff it's not it's Tsavo Knott: Yeah. Thaymisan Cavalcante: not the world that Tsavo Knott: Yeah. Thaymisan Cavalcante: um I get I totally get the point though Tsavo Knott: Yeah. Thaymisan Cavalcante: when Tsavo Knott: I Thaymisan Cavalcante: it comes Tsavo Knott: think Thaymisan Cavalcante: to the design team we already doing this process I completely agree with what Hannah said I think it's just a communication thing but we most of the time we already skip Figma we already build on frame we don't I don't think adding lovable to the mix would make sense because we don't even create prototypes at this point Tsavo Knott: Yeah. Thaymisan Cavalcante: we have um components in place on on framer that we just literally drag and drop two pages, Tsavo Knott: Yep. Thaymisan Cavalcante: build it really quickly, put on staging and send to approval. Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 22
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "already skip Figma we already build on frame we don't I don't think adding lovable to the mix would make sense because we don't even create prototypes at this point Tsavo Knott: Yeah. Thaymisan Cavalcante: we have um components in place on on framer that we just literally drag and drop two pages, Tsavo Knott: Yep. Thaymisan Cavalcante: build it really quickly, put on staging and send to approval. Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 23
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Thaymisan Cavalcante: Um, so I think it's just a matter of communication too and as you mentioned like I also use chatg for a lot of the things like from a user perspective how can we make sure that this page is is better how can we tight the flow how can we utilize SEO to make the traffic higher and anyways you you get the point. 00:22:01 Tsavo Knott: Yeah. Thaymisan Cavalcante: So I think we are we're already there in a way. Um, I think Tsavo Knott: Yeah. Thaymisan Cavalcante: I we just need to find all the tools like Smith mentioned that could potentially automate what we do, which is the trick, I guess, for the design particularly like I don't see right now. I don't know any tools that can do what we do. Like I don't I what I wish there was out there is like grab this design system that we have in place, these components that we have in place and build it for me, which Tsavo Knott: Yeah. Thaymisan Cavalcante: we don't. Tsavo Knott: Yeah. Thaymisan Cavalcante: I think there's someone probably building that already, but we don't have that yet. Tsavo Knott: Totally. And Thaymisan Cavalcante: Um, Tsavo Knott: I think the main thing is there will be parts of your workflow that it's Ali Mustufa Shaikh: Okay. Tsavo Knott: just not practical yet, right? But there are other parts where you're like, \"Hey, how can I apply AI to that to buy myself more time to spend on the the parts that you can't automate?\" 00:22:51 Tsavo Knott: Um, the one thing to note is definitely definitely try everything, right? So, if you haven't tried Lovable just in a two-hour period to try and build out a landing page, just try it out and see what the differences are between your flow inside of Framework and your flow inside of Lovable and just be like, \"Hey, maybe there is a world where, you know, this is way faster at, you know, prototyping and saves you, you know, 200 button clicks inside of Framer, right? I mean that takes you from you know button clicks, manual nav, whatever else down to five minutes you have a page you can send it to someone they can check it out right so just try these things and and just because you are using a tool like even the tools themselves they're changing so so fast right so the tools that you might have used in the past if they don't adapt and they don't use this stuff and and build it out really well they're also going to get deprecated over time right so just be open to everything. 00:23:50 Tsavo Knott: Try everything. It doesn't hurt to to see what's what's up with it. Yeah. Smit Patel: Yeah, keep in mind there's like a billion users of Chad GPT now, right? So I think it it's sort of like saying that, hey, I know how to use Google now, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 24
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "so so fast right so the tools that you might have used in the past if they don't adapt and they don't use this stuff and and build it out really well they're also going to get deprecated over time right so just be open to everything. 00:23:50 Tsavo Knott: Try everything. It doesn't hurt to to see what's what's up with it. Yeah. Smit Patel: Yeah, keep in mind there's like a billion users of Chad GPT now, right? So I think it it's sort of like saying that, hey, I know how to use Google now, right?",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 25
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "I mean, that's that's that's kind of like baseline now with when Tsavo Knott: Yep. Smit Patel: you say the word AI, right? So, I think it's finding those tools that are specific to your domain. And I guarantee you, I don't know. I don't have the answer to it. So, you know, I'm not going to, you know, just make claims here, but I guarantee you there's a tool for every single thing that everyone's working on here. Like, I see so many crazy things that are being worked on. It's just a matter of like, you know, finding them and testing them out. And again, like they might not all work, right? And I think the when it comes to design Tai like I think what it's not going to replace is your taste, right? 00:24:41 Smit Patel: Like you're a designer. Like it might not be able to tell it like it might not be able to go create your brand guidelines. It might not be able to create like that awesome logo that you came up with your in your head, right? But it will be able to go and like let's say if we wanted to run some crazy like ads experiment just saying you know thinking out loud and we wanted like a 100 landing pages built up like this AI is going to be able to help you with that right so that way you don't have to go do that or if we want like a 100 images being generated like let's just say hypothetically we have 100 images and we want put like pieces logo on it in like 30 seconds on 100 images AI will be able to do it right so it's like how can you become better faster That's that's kind of like what I would think about like rather than thinking about okay like this is not good enough because I know I I do recognize as a designer like you know you have a sense for perfection and like that's kind of important but at the same time it's like maybe there are other aspects right that you can automate. 00:25:38 Smit Patel: It's not like the final product that you need to automate necessarily. Tsavo Knott: Yep. Couldn't agree more. So, what we're going to do, obviously, like June's the month to to kind of like reinvent ourselves. Um, you know, we'll we'll kind of reflect at the end of June. Um, but we want to have a big month, right? And so, that means that, you know, take this week, whatever else it is, continue to do what you're doing.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 26
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "of reflect at the end of June. Um, but we want to have a big month, right? And so, that means that, you know, take this week, whatever else it is, continue to do what you're doing.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 27
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "But the first question if I were any of you is go to OpenAI deeply describe what what you do dayto-day and tell it to do deep research on how you can automate parts of your your roles right and if you find yourself in something where you're like hey like you know I'm doing this I totally forgot to ask you know you know OpenAI how to automate this like go ahead and ask it right continue continuously as you find yourself in these scenarios figure out how can I make this faster right um so that's definitely phase one and then phase two is sharing learnings and kind of like reflecting on how things got done in addition to just what got done is going to be an important part of the growth team syncs um for the next four in June here. 00:26:44 Tsavo Knott: Cool. Smit Patel: Yeah, I think what we can do is we can move the growth sync that we have tomorrow to Thursday so that everyone can just take the time digest this meeting think through like okay what are your existing workflows what are you know future projects you want to work on I think at a high level I know for a fact that you know for example we have some like highlevel uh initiatives in the work like programmatic SEO. We've got um you know, we're going to be kicking off um a project for um automating cold outbound emails soon um that Nicola and I are going to work on soon. Um Jack, for example, for you like I I know I've seen I don't know the names. I saw a bunch of tools that are like you know that can do some you know crazy things like they can go and analyze videos of other competitors and like extract like you know what are good things about it what are bad things and then go and generate new videos for you and there's like insane stuff right so I think for 00:27:39 Ali Mustufa Shaikh: Yep. Smit Patel: video what I'm expecting is we just go you know have a ton of new videos that we can just go pump out on our channels right Ellie obviously like think through the social pipelines like how we can have developer focused content that can be automated like I think that's an easy lowhanging fruit for you but also like content creation as well because you know we have we want to have good blogs as well so maybe like that's another um area to think through and then obviously Ty and Lauren like on the design side think through like what are workflows we can look at Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 28
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "also like content creation as well because you know we have we want to have good blogs as well so maybe like that's another um area to think through and then obviously Ty and Lauren like on the design side think through like what are workflows we can look at Tsavo Knott: Yeah.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 29
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Smit Patel: um yeah and you know Devril Ali like you know there's bunch of things that that can happen there as well maybe it's like something you know that that can go and you know fetch interesting information from different like you GitHub profiles or maybe we you know build some tool which goes and like lights a bunch of GitHub profiles. I'm just making like you know thinking out loud here but like just there's a lot of room to be creative right so I think at a high level the goal is like let's get AI you know upskill on AI and then we have to increase the output this month right so that way we're just moving super fast break things learn and then you know we're in a better place than we were like you know a quarter 00:28:47 Smit Patel: ago Tsavo Knott: Yep. Yeah. And after this meeting, you know, when you guys get a chance to go and and you know, discuss with AI how to improve your role, just shareable link that, you know, chatbt or anthropic chat or whatever, send it in the group, others can take a look at it, you know, and we can just cross-pollinate these learnings. Yeah. Okay. Smit Patel: Yeah. And Ali Mustufa Shaikh: Absolutely. Smit Patel: also just a random thought, random comment, Jack, that video was sick, by the way. I think we Tsavo Knott: Yeah. Smit Patel: need more of that, right? Like that Jack Ross: Awesome. Smit Patel: I I know, you know, it took a long time, but I think that's kind of the the level of creativity and it was just super cool, right? Like very different. So yeah, Tsavo Knott: Yeah. Smit Patel: keep Jack Ross: Thank Smit Patel: that Jack Ross: you. Smit Patel: up. Jack Ross: Got the workflow automated for that as well. I have uh the video cutting like the raw footage automated, got the captions got automated. 00:29:31 Jack Ross: Uh got Opus for like the putting shorts together. And yeah, now we're just looking for something to kind of bring like the the main piece to the the editing automation. But yeah, we'll have one video like that every week. So Tsavo Knott: Okay. Jack Ross: that's Smit Patel: Think Jack Ross: going to Smit Patel: more. Jack Ross: be Smit Patel: Think more. We need way Jack Ross: well just Smit Patel: more Jack Ross: just Smit Patel: than Jack Ross: long Smit Patel: one. Jack Ross: like like that and then we've got a bunch of other videos as well. But Smit Patel: Yeah. Jack Ross: yeah Smit Patel: Awesome. Hanna Stechenko: Is it the one on LinkedIn that we shared that you were in the field sort sort of? Well, next one. You got to make the ribs and also uh create the video. Smit Patel: Well, you could also have like faceless ones too, right? So, because the faceless videos do uh tend to do well as well.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 30
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Smit Patel: more Jack Ross: just Smit Patel: than Jack Ross: long Smit Patel: one. Jack Ross: like like that and then we've got a bunch of other videos as well. But Smit Patel: Yeah. Jack Ross: yeah Smit Patel: Awesome. Hanna Stechenko: Is it the one on LinkedIn that we shared that you were in the field sort sort of? Well, next one. You got to make the ribs and also uh create the video. Smit Patel: Well, you could also have like faceless ones too, right? So, because the faceless videos do uh tend to do well as well.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 31
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So, that's another way you can do it. Jack Ross: Yep. Also want Smit Patel: Hannah, Jack Ross: to chat Smit Patel: did Jack Ross: about Smit Patel: you have a comment or question? Hanna Stechenko: No, all clear. Um, yeah, I think now I understand more the concept. So, it's more about automating the stuff that can be done without uh spending tons of time. I don't know how it's for other other fields, but for SEO part, I uh I do understand what you mean. So, it's cool challenging, but uh we're gonna get that. Tsavo Knott: Okay, awesome, great. Thank you team will let you guys go but let's have a great week and happy Monday. All Jack Ross: Awesome. Hanna Stechenko: Thank Tsavo Knott: right. Smit Patel: Yeah, thanks Hanna Stechenko: you. Jack Ross: Okay. Smit Patel: everyone. But Ali Mustufa Shaikh: Yeah. Nikhil L: Attempts. Ali Mustufa Shaikh: Thank Nikhil L: Right. Ali Mustufa Shaikh: you so much. Transcription ended after 00:30:46 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "1_uEyuM095_aBI4aq1IagRO1PRqp-cTL15gNhIWXA_U0",
    "chunk_index": 32
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 5, 2025 Growth Sync üìà Invited Smit Patel Tsavo Knott Ellie Zubrowski Laurin McNulty jim@pieces.app Thaymisan Cavalcante Ali Mustufa Shaikh Nikhil L Luka Kalaj≈æiƒá Hanna Stechenko Jack Ross Attachments Growth Sync üìà Meeting records Transcript Recording Summary The team, including Thaymisan Cavalcante, Tsavo Knott, Laurin McNulty, Smit Patel, Ellie Zubrowski, Jack Ross, Hanna Stechenko, Ali Mustufa Shaikh, and Nikhil L, explored and tested various AI tools to improve workflows in design, content creation, social media engagement, video editing, SEO, and overall productivity. Discussions covered specific tools like Framer Workshop, Figma Buzz, MidJourney, Firecut, Grok, and Vertex AI, along with strategies for automating tasks such as blog post generation, social graphic creation, video editing, and competitor analysis to enhance efficiency and content scalability. The participants also addressed website redesign efforts, AI memory library categorization, and strategies for expanding content output and social media reach, with a focus on leveraging AI for automation and gaining competitive insights. Details * AI Tool Research and Testing Thaymisan Cavalcante mentioned the team tested various AI tools to determine their suitability for their workflow, particularly in design. The aim was to identify tools that could improve efficiency in tasks like layout generation for new website pages and wireframing. Tsavo Knott and Thaymisan Cavalcante discussed tools like Frame AI wireframer and lovable. * Framer Workshop and Component Libraries Thaymisan Cavalcante highlighted Framer's new \"workshop\" feature, an AI co-pilot integrated with the Framer API, which can directly create components within the framework. This reduces the need for external AI tools like ChatGPT for building Framer components. Thaymisan Cavalcante also suggested considering component libraries to accelerate project development by using pre-built design elements. * Automating Blog Entry Creation Laurin McNulty discussed the time-consuming process of manually creating blog entries and the potential for automation using tools like Arvo and Make AI or Zapier. These tools can autogenerate and publish SEO-enriched blog posts by connecting with the Framer API, which recently became available. Laurin McNulty noted this automation could significantly reduce the workload for themself and Hannah Stechenko. * Social Graphic Creation with AI Laurin McNulty presented Figma Buzz as a useful tool for quickly resizing social graphics for different platforms, addressing a tedious part of the process. While not fully AI-driven, Figma Buzz uses AI for resizing and includes an image generator. Laurin McNulty shared examples and expressed excitement about its capabilities. * Automated Blog Graphic Creation and AB Testing Laurin McNulty explored using MidJourney to generate blog thumbnails based on existing designs. They also mentioned that AB testing, now under TIN's responsibility, can be facilitated by a specific Framer plugin. * Reduced Page Build Time and Scalable Content Laurin McNulty estimated a 50 to 70% reduction in new page build time due to the adoption of these AI tools, particularly for projects like the pieces academy. Automating blog content creation is expected to result in zero lift, freeing up significant time.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "to generate blog thumbnails based on existing designs. They also mentioned that AB testing, now under TIN's responsibility, can be facilitated by a specific Framer plugin. * Reduced Page Build Time and Scalable Content Laurin McNulty estimated a 50 to 70% reduction in new page build time due to the adoption of these AI tools, particularly for projects like the pieces academy. Automating blog content creation is expected to result in zero lift, freeing up significant time.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* Demonstration of Figma Buzz Image Generation Laurin McNulty shared their screen to demonstrate Figma Buzz, showing how it could generate prompts and images based on a reference, including the use of specific hex colors. Laurin McNulty found GPT Image One produced the most favorable results, although it had some difficulties with logos and UI, which could be partially corrected with GPT. * Wireframer and Lovable for Brainstorming Laurin McNulty presented wireframer and lovable as tools for quickly generating basic, non-styled wireframes suitable for brainstorming. While wireframer is very simple, lovable responded better to prompts but still required manual steps to integrate into Framer with styling. * Positive Impact of AI on Productivity and Creativity Smit Patel expressed enthusiasm for the shift towards AI tools, emphasizing their potential to enhance productivity and allow creative roles to focus on creativity rather than repetitive tasks. Smit Patel believes AI can significantly reduce the time spent on routine processes. * Scaling Image Generation and Workflow Automation Smit Patel suggested focusing on developing a scalable workflow for image generation, particularly for programmatic SEO, where specific images could be automatically created for different applications based on prompts and UI. Smit Patel proposed a project to recreate the homepage using these new AI capabilities within the next few days. * Testing AI Tools for Homepage Redesign Thaymisan Cavalcante revealed they had already taken the initiative to use AI tools to create a new homepage for pieces, using specific prompts for typography, color palette, and design principles. They tested about eight tools with the same prompt to evaluate their responsiveness and adherence to design specifications. Thaymisan Cavalcante identified prompting as a key challenge and Smit Patel suggested following online resources for prompt engineering tips. * Evaluation of AI Tool Outputs for Homepage Design Thaymisan Cavalcante shared the results of testing various AI tools for homepage creation, noting which tools followed their prompts regarding typography and aesthetics. They highlighted unique features of some tools, such as Firebase Studio's briefing process and Replet's inclusion of social proof and a \"built for how you actually work\" section. Google Stitch was deemed a less successful test. * Next Steps for Homepage Redesign and Prompt Enhancement Smit Patel commended Thaymisan Cavalcante's progress and suggested the next step would be to combine the best elements from the different AI-generated outputs to create the final homepage. Smit Patel recommended adding context from user feedback, such as viral tweets, to improve prompting and suggested using standard decks and successful content as additional context for AI tools. Smit Patel also shared a link to an Anthropic AI prompt engineering deep dive. * Framer Workshop for Interactive Components Thaymisan Cavalcante demonstrated using Framer Workshop to quickly create a category dropdown list for the AI memory library. While the initial output required some refinement for mobile responsiveness and multi-select options, Thaymisan Cavalcante plans to use Workshop to further develop the component. * Model Switching in AI Tools and Quality Assurance Smit Patel inquired about testing different models within the AI tools.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "using standard decks and successful content as additional context for AI tools. Smit Patel also shared a link to an Anthropic AI prompt engineering deep dive. * Framer Workshop for Interactive Components Thaymisan Cavalcante demonstrated using Framer Workshop to quickly create a category dropdown list for the AI memory library. While the initial output required some refinement for mobile responsiveness and multi-select options, Thaymisan Cavalcante plans to use Workshop to further develop the component. * Model Switching in AI Tools and Quality Assurance Smit Patel inquired about testing different models within the AI tools.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Thaymisan Cavalcante confirmed the ability to switch models and noted that GPT performed best in their tests. Smit Patel suggested automating quality assurance processes, such as checking for typos and incorrect images on staging websites using AI tools with web browsing capabilities. Tsavo Knott added a suggestion to use large language models to evaluate landing page designs and improve prompting. * LinkedIn Engagement and Content Idea Generation Ellie Zubrowski shared tools for improving social media engagement, starting with LIGO for generating quick comments on LinkedIn and Twitter posts. Ellie Zubrowski also presented Creator Buddy, a tool for generating content ideas (tweets, long-form posts, video scripts) by simply pasting text from web pages, such as the AI memory page. They plan to test its algorithm analysis features for predicting post performance. * Opus Clip for Short-Form Video Creation and Audio Enhancement Ellie Zubrowski demonstrated Opus Clip, a tool they have been using to automatically generate short-form videos with captions from YouTube links. They also mentioned using an audio enhancement tool (link provided by Tsavo Knott) to improve the sound quality of recorded videos. * CapCut for Video Editing and YouTube Description Automation Ellie Zubrowski highlighted CapCut's AI-powered features for removing pauses in videos, significantly speeding up the editing process. They also described their workflow for using ChatGPT to generate timestamps and descriptions for YouTube videos based on the auto-generated transcript. * Meme Generation Tools Ellie Zubrowski discussed using a curated meme generator for trending memes and briefly experimented with an AI meme generator, noting that AI-generated memes are not consistently funny yet. Despite this, Ellie Zubrowski is most enthusiastic about Creator Buddy for its potential to easily generate diverse content. * Setting Goals for Social Media Engagement and Blog Content Smit Patel set a new goal for Ellie Zubrowski to achieve one viral tweet and one viral LinkedIn post per week. Smit Patel also suggested increasing the use of AI to generate blog posts, emphasizing the potential for a significant increase in content output. Smit Patel encouraged Ellie Zubrowski, as a developer, to explore building custom workflow automation tools for content creation and scheduling. * Leveraging Grok for X (Twitter) Strategy and Research Tsavo Knott recommended utilizing Grok, especially for X (formerly Twitter), to analyze successful content strategies of competitors and to identify trending topics and viral tweets. Tsavo Knott suggested using Grok for research and then refining the output with a larger language model like OpenAI to develop effective tweet styles and high-value content. While Smit Patel found Grok less effective for in-depth analysis, they agreed on its utility for identifying trends. Ellie Zubrowski confirmed Grok's strength in algorithm analysis and trending topics and will try the suggested workflow. Smit Patel also shared a tactic of quoting Grok's responses in tweets to potentially improve engagement.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "tweet styles and high-value content. While Smit Patel found Grok less effective for in-depth analysis, they agreed on its utility for identifying trends. Ellie Zubrowski confirmed Grok's strength in algorithm analysis and trending topics and will try the suggested workflow. Smit Patel also shared a tactic of quoting Grok's responses in tweets to potentially improve engagement.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* AI-Powered Video Editing with Firecut Jack Ross introduced Firecut, an AI plugin for Adobe Premiere Pro, which significantly speeds up video editing by automating tasks such as silence removal, identifying similar clips, auto-captioning, podcast editing, highlighting clips, integrating with Storyblocks, removing filler words and repetitions, and adding chapter detection. Jack Ross estimated that Firecut saves several hours of editing time per video and is currently using it for the pieces academy tutorial videos, with the first video ready for release soon. * Animation Tools and Short-Form Content Strategy Jack Ross switched to After Effects to leverage automation for animation using tools like Motion Array and Runway (an AI animation tool). Jack Ross is developing a strategy for short-form content, aiming to test 14 pieces over two weeks, drawing inspiration from competitors and successful social accounts. * AI for User-Generated Content (UGC) Jack Ross explored AI UGC platforms like Make UGC and Creatify as a more cost-effective alternative to traditional influencer campaigns. Creatify can analyze web pages to understand brand assets and context, generate scripts with different tones, and overlay these with AI avatars to create full UGC videos. A current limitation is the quality of AI voices, which Jack Ross is trying to improve by connecting Creatify with realistic voice platforms like 11 Labs. Jack Ross highlighted the potential to generate numerous UGC videos, analyze their performance, and refine the strategy based on data. * Competitor Social Analysis with AI Jack Ross is using Cassidy AI, an agentic web research tool, to analyze the social media content of competitors. The goal is to identify successful hook styles and content types by cataloging their videos, tagging them, and ranking them by views and engagement. This process will be automated to continuously monitor competitors and identify opportunities to adapt and improve pieces' social media strategy. The immediate focus is on releasing the pieces academy videos and then testing short-form content strategies based on the competitor analysis. Smit Patel expressed excitement about the video updates and wants to see consistent output and quality. * SEO Industry Changes and Adaptation Hanna Stechenko discussed the significant impact of AI on the SEO industry, including changes in key metrics and the need to adapt business and marketing strategies. Key factors include the appearance of large language models (LLMs) in search and the importance of visibility on AI platforms, as well as improving organic growth at scale through programmatic SEO and maintaining SEO hygiene. Hanna Stechenko also addressed automating low-effort manual SEO tasks related to content publishing and landing pages. * Hybrid SEO Approach and Tools for Organic Visibility Hanna Stechenko outlined a shift towards a hybrid SEO approach, combining human expertise with AI assistance across content creation, keyword research, and internal linking to achieve scalability. Hanna Stechenko noted a significant drop in organic click-through rates due to AI-powered search results and evaluated tools like Right Sonic and Aerops to address this.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Stechenko also addressed automating low-effort manual SEO tasks related to content publishing and landing pages. * Hybrid SEO Approach and Tools for Organic Visibility Hanna Stechenko outlined a shift towards a hybrid SEO approach, combining human expertise with AI assistance across content creation, keyword research, and internal linking to achieve scalability. Hanna Stechenko noted a significant drop in organic click-through rates due to AI-powered search results and evaluated tools like Right Sonic and Aerops to address this.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Right Sonic was favored for its analytics on LLM visibility, automated publishing, keyword optimization, content generation, and research capabilities, aligning better with the current budget and automation needs. * Time Savings and Potential for Vibe Coding Hanna Stechenko calculated potential time savings of approximately five hours per week through automation, allowing for more focus on SEO strategy and experimentation. Hanna Stechenko also plans to explore \"vibe coding\" to address specific SEO challenges, starting with internal linking, using an open-source project from Google Gemini. * Automating Content Creation and Replicating Successful Styles Smit Patel recommended that Hanna Stechenko dedicate a significant portion of their role to automating the creation of blog posts and content. Smit Patel suggested analyzing the tone and style of content from AI market leaders like Anthropic and OpenAI to replicate their approach, while focusing on creative and relevant topics. Smit Patel emphasized the need to increase content output, even if it means initially adopting successful styles from others to gain visibility. Hanna Stechenko agreed to this approach. * Using AI to Analyze YouTube Content for Trends Tsavo Knott suggested using AI to analyze YouTube videos from industry leaders to identify emerging trends and understand how pieces can align with these developments. Tsavo Knott pointed out that the voice in YouTube videos often feels more authentic than in blogs. * Networking and Demonstrating Pieces at Conferences Ali Mustufa Shaikh shared experiences from conferences in SF and LA, where they effectively engaged with dev advocates by demonstrating pieces' on-device capabilities in real-time. This led to conversations and potential collaborations, including with Zoom's Ojas regarding their Real-Time Media Streams. Ali Mustufa Shaikh also highlighted a valuable online resource (\"Supertools\") for discovering and comparing various AI tools. They mentioned using Gamma for presentation design and discovering new audio tools as well. * Custom Automated Flows with Langflow Ali Mustufa Shaikh discussed their weekend project of creating custom automated flows using Langflow to generate tweet threads based on trending topics. Ali highlighted Langflow's drag-and-drop interface for building agents and the ability to incorporate tone as a variable in content generation. * Automating Certificate and Badge Awards Ali Mustufa Shaikh brainstormed automating the process of awarding certificates and badges for their GenAI 101 events. Ali considered using Pieces due to its contextual understanding of their workshops and workflows for awarding certificates. * Exploring Common Room for Sentiment Analysis Ali Mustufa Shaikh shared their exploration of Common Room, a tool for developers that captures sentiment across various online channels. Ali mentioned its ability to compile data into a dashboard, providing insights into product feedback and sentiment, but noted its high cost after the free tier. * Fnot for Keyword Monitoring Ali Mustufa Shaikh introduced Fnot as a free and easy tool to monitor mentions of keywords, such as \"pieces,\" on platforms like Reddit and Hacker News, sending email notifications for such mentions. Ali emphasized the value of capturing this information early, given their reliance on email.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "captures sentiment across various online channels. Ali mentioned its ability to compile data into a dashboard, providing insights into product feedback and sentiment, but noted its high cost after the free tier. * Fnot for Keyword Monitoring Ali Mustufa Shaikh introduced Fnot as a free and easy tool to monitor mentions of keywords, such as \"pieces,\" on platforms like Reddit and Hacker News, sending email notifications for such mentions. Ali emphasized the value of capturing this information early, given their reliance on email.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* Workflow Automation Tool Aerops Smit Patel offered to forward Ali Mustufa Shaikh information about Aerops, a workflow tool similar to Langflow, which they learned about from an AI content creation course. Smit Patel noted that Aerops has pre-built templates that could save Ali time in creating automated flows. * Nikhil L's Automated Workflows and Vertex AI Nikhil L stated that their workflows are already automated using code and AI, preferring code for greater control. Nikhil L then introduced Vertex AI within GCP, which allows training ML models and creating pipelines for various content types, suggesting it could replicate the functionalities discussed with other AI tools. * Use Cases for Vertex AI in Data Analytics Nikhil L detailed three potential use cases for Vertex AI in data analytics: predictive lead scoring to optimize ad campaigns, dynamic user segmentation based on product event data for transactional notifications, and content creation based on analyzed trends and voice samples. Nikhil L offered to help the team with their automation needs using Vertex AI. * Automated Report Generation from Meeting Notes Tsavo Knott proposed using AI to ingest notes from various meetings (ML standups, etc.) to generate reports on release status and other key information. Tsavo Knott suggested distributing these reports via Google Docs or markdown in Ghat, enabling the whole company to stay informed and providing context for tasks like updating landing pages or documentation. Nikhil L confirmed this was feasible. * Website Launch and A/B Testing Strategy Smit Patel set the immediate task to launch the website next week. In response to Hanna Stechenko's question about A/B testing different versions, Smit Patel clarified the strategy would be to test one new version against the current website to gauge performance before iterating. * Clarification on Rebranding Efforts Smit Patel clarified that the current focus is not a full rebranding but a final push for \"pieces for developers\" this month, leveraging existing developer-centric branding and assets across all channels, including outbound campaigns. The goal is to assess the effectiveness of targeting developers before potentially shifting focus. * AI Memory Library Categorization Issue Hanna Stechenko reported an issue with the categorization in the AI memory library and mentioned needing to manually review it. Thaymisan Cavalcante noted the categorization didn't come through the shared Excel sheet, emphasizing the need for correct categorization, especially with plans to add more tools. * Discussion on Dynamic Categorization for AI Library Nikhil L suggested implementing a dynamic system where new categories added to the spreadsheet would automatically be created in the framework, avoiding manual intervention. While Thaymisan Cavalcante thought it wasn't currently allowed, Nikhil L argued for its efficiency in the long run. Hanna Stechenko and Nikhil L agreed to fix the current categorization manually but consider automation for future updates. * Strategy for Adding New Tools and Enhancements to AI Library Hanna Stechenko questioned whether to add more tools to the AI memory library immediately. Smit Patel recommended ensuring the existing 200 apps are accurate first.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "new categories added to the spreadsheet would automatically be created in the framework, avoiding manual intervention. While Thaymisan Cavalcante thought it wasn't currently allowed, Nikhil L argued for its efficiency in the long run. Hanna Stechenko and Nikhil L agreed to fix the current categorization manually but consider automation for future updates. * Strategy for Adding New Tools and Enhancements to AI Library Hanna Stechenko questioned whether to add more tools to the AI memory library immediately. Smit Patel recommended ensuring the existing 200 apps are accurate first.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Smit Patel also suggested enhancing the current pages, possibly by adding prompts related to each tool, either directly or on a separate page, to make the library more helpful. Nikhil L confirmed that automating the addition of prompts was possible with a proper structure. Suggested next steps * Ali Mustufa Shaikh will review the AI content creation course using Aerops forwarded by Smit Patel. * Nikhil L will create a pipeline to ingest notes from meetings in Google Drive and generate a report on the release status and other relevant topics, outputting to a Google Doc or sending a Markdown summary to Ghat. * Thaymisan Cavalcante will send the website examples to Smit Patel for feedback in Figma and finalize the website for the developer push with an A/B test next week. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript Jun 5, 2025 Growth Sync üìà - Transcript Transcription ended after 00:00:04 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "11pqKJAHHu2uWP60-AWazrgxd4P2cVhfe2ifhhBvlSBs",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 6, 2025 wg-day1-retention Invited Smit Patel Tsavo Knott Sam Jones Nikhil L Mack Myers Mark Widman Hiro Tamada Attachments wg-day1-retention Meeting records Transcript Summary Mark Widman, Tsavo Knott, Mack Myers, and Sam Jones discussed desktop app onboarding, bootstrapping funnel metrics, and the Northstar KPI of average messages per day, linking improvements to ongoing development. They also addressed a dip in nano model quality attributed to analytics events and data, discrepancies in workstream events and summaries, and the importance of using median over average for execution time. Tsavo Knott, Sam Jones, and Mark Widman covered topics including new language model impacts, invalid index errors, JSON mode data, time to first token metrics, target user base system requirements, on-device SLM considerations, and Smit Patel proposed consolidating analytics working groups. Details * Desktop App Onboarding and ISRs Mark Widman and Tsavo Knott discussed the process of users going from off to on onboarding for the desktop app and the generation of Internal Support Requests (ISRs). Tsavo Knott mentioned that the desktop app will become the only download, installing pieces OS and guaranteeing a connection on first boot (00:00:00). Mack Myers shared a board showing the drop-off rate between booting the desktop app and reaching the \"start forming memories\" screen, attributing potential reasons to privacy opt-outs or users changing their minds. Mack Myers suggested analyzing the conversion rate within the memory formation flow to identify drop-offs and errors (00:01:13), and Sam Jones noted that Miguel has related dashboards (00:02:21). * Desktop App Bootstrapping Funnel Tsavo Knott emphasized the importance of tracking a funnel for new desktop app users, specifically how many successfully boot for the first time, ensure core dependencies, sign in, and complete onboarding (00:02:21). Mack Myers confirmed that they will have this data available (00:03:29). * Northstar KPI: Average Messages Per Day Tsavo Knott highlighted the average number of messages per day as a key Northstar KPI, focusing on increasing the number of chats using Long-Term Memory (LTM). They believe that ongoing work on workstream summary, co-pilot, table rendering, and latte rendering will improve queries per user per day. Tsavo Knott also mentioned the potential positive impact of time to first token improvements and pre-warming (00:03:29). * Quality of Nano Models and Analytics Tsavo Knott and Sam Jones discussed a dip in the quality of nano models, which Sam Jones attributed to a misattributed analytics event and potential data corruption issues. Sam Jones clarified that the data corruption was likely earlier in the year and that the current metrics are LTM-specific. They also touched upon the transition from Quadrant to cache base in February (00:04:51). The data showed a period in April with a dip, possibly due to an unknown issue, but it seems to be recovering (00:05:58). * User Growth and Tool Usage Tsavo Knott noted a significant number of daily active users utilizing the MCP tool in Cursor, which is more than their company size. They also highlighted the positive average MCP tool calls per user per day (00:06:41).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "was likely earlier in the year and that the current metrics are LTM-specific. They also touched upon the transition from Quadrant to cache base in February (00:04:51). The data showed a period in April with a dip, possibly due to an unknown issue, but it seems to be recovering (00:05:58). * User Growth and Tool Usage Tsavo Knott noted a significant number of daily active users utilizing the MCP tool in Cursor, which is more than their company size. They also highlighted the positive average MCP tool calls per user per day (00:06:41).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Additionally, Tsavo Knott presented data on the number of users with generated workstream summaries and the average number of summaries per user per day, which Sam Jones equated to a significant amount of processing time. The number of workstream events processed per user per day was also reported as excellent (00:07:33). * Impact of New Language Models Mark Widman mentioned the addition of new language models on May 1st, including Gemini and OpenAI models, which users can access from the cloud. Tsavo Knott suggested this could be related to user bounce if users are looking for the latest models. They also discussed the models used for LTM queries and whether they are new or existing users (00:08:30). * Workstream Events and Summaries Discrepancy Tsavo Knott and Sam Jones identified a discrepancy between the number of users with workstream events processed and the number with summaries, with more users having summaries (00:08:30). Mark Widman clarified that it's possible to have more summaries than LTM events due to MCP but acknowledged the point about more users with summaries. Sam Jones suggested letting the new analytics data stabilize for a week before further analysis (00:09:33). They hypothesized that summaries might be generated across all users, with generation skipped if there's nothing to summarize. Mark Widman and Sam Jones discussed potential reasons for the discrepancy, including the timing of the event firing and the possibility of summary generation failures (00:10:28). * Median vs. Average Execution Time Tsavo Knott and Sam Jones discussed the use of median versus average for measuring execution time of models. Sam Jones explained that the median is a better metric due to the non-bell curve distribution and potential for outliers caused by timeouts or slow connections, which can skew the average (00:11:28). They agreed that the median provides a more accurate representation of the typical user experience (00:12:52). Mark Widman concurred, noting that while the average can highlight potential issues like model loading problems, the median is more reliable for general performance assessment until outlier analysis can be done (00:23:09). * Time Classifier Package Benchmarks Tsavo Knott mentioned work on benchmarks for the time classifier package. Sam Jones pointed out a confounding factor: the current back-off to a cloud model for span prediction, which results in higher execution times (00:14:49). Mark Widman confirmed the availability of data to distinguish between local and cloud model usage (00:15:47). * Analysis of Query Types and Context Intention Router Tsavo Knott noted the accumulation of a valuable dataset on query types (proper not, temporal, etc.) for content retrieval. Sam Jones expressed enthusiasm and inquired if the same analysis could be done for the context intention router (00:15:47). Mark Widman confirmed this capability, mentioning the effort invested in setting up this tracking (00:16:32). * General Queries with LTM On and Invalid Index Errors Sam Jones raised the issue of users making general queries with LTM switched on, which could negatively impact user experience due to longer processing times. Tsavo Knott reported an interesting number of invalid index errors (00:16:32).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "accumulation of a valuable dataset on query types (proper not, temporal, etc.) for content retrieval. Sam Jones expressed enthusiasm and inquired if the same analysis could be done for the context intention router (00:15:47). Mark Widman confirmed this capability, mentioning the effort invested in setting up this tracking (00:16:32). * General Queries with LTM On and Invalid Index Errors Sam Jones raised the issue of users making general queries with LTM switched on, which could negatively impact user experience due to longer processing times. Tsavo Knott reported an interesting number of invalid index errors (00:16:32).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones recalled a recent patch related to this, but Mark Widman was initially unsure. Tsavo Knott also noted a number of timeout errors (00:18:09). Mark Widman later clarified that the invalid index error is resolved, with the system catching it and using a default (00:19:15). * JSON Mode Data and Classifier Labels Tsavo Knott inquired about the destination of the results from the JSON mode. Mark Widman explained that the errors are likely caught and handled at a higher level (ISO server), defaulting to a standard behavior like running the LTM. In successful events, specific properties related to the action classifier and labels should be present. Sam Jones noted that the \"not set\" result was uninformative (00:19:59). They agreed to investigate the source of the \"not set\" values, as there were fewer in one specific view. The cloud model overwhelmingly indicated \"content retrieval\" as the task (00:21:11). * Importance of Micro Models and Cloud Backoff Sam Jones reiterated that refining the micro models is a top priority (P0), as this will eventually allow the removal of the cloud backoff. Tsavo Knott agreed (00:22:02). * Time to First Token Metrics Tsavo Knott presented data on the median time to first token, total time, and trends for context aggregation and completion of the first LLM token. They highlighted the difference between the median and average, with the average being more susceptible to outliers (00:22:02). Sam Jones reiterated that the average (mean) is currently not very informative due to outliers, such as users with very long completion times. They suggested that once timeout data is plotted and outliers can be removed, the mean will become more useful. Mark Widman concurred, stating that while outliers skew the average, the average can still indicate potential underlying issues (00:23:09). The P75 metric was also noted as interesting for identifying patterns among users with longer processing times. Tsavo Knott emphasized that the trend of metrics like P75 is a key indicator of whether performance is improving or worsening (00:24:33). * Target User Base and Minimum System Requirements Sam Jones raised a broader question about whether the goal is to build a system that works for everyone or a high-spec system for a specific user segment. Tsavo Knott believes the aim is a broader audience, similar to how Google Chrome became universally adopted due to its performance on various devices (00:25:27). They suggested aiming for an installation and permissioning process as simple as Zoom. While not intending to support very old devices, the focus is on digital professional workers and ensuring the software works well on their typical hardware (00:26:38). Sam Jones suggested establishing minimum system specifications to help define when the performance goals are met (00:27:42). Tsavo Knott mentioned positive discussions with Google Labs, including potential research into running the software on Android, highlighting the ongoing challenge of performance in diverse environments. They emphasized the company's focus on building efficient ML systems for low-compute environments (00:28:47).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "intending to support very old devices, the focus is on digital professional workers and ensuring the software works well on their typical hardware (00:26:38). Sam Jones suggested establishing minimum system specifications to help define when the performance goals are met (00:27:42). Tsavo Knott mentioned positive discussions with Google Labs, including potential research into running the software on Android, highlighting the ongoing challenge of performance in diverse environments. They emphasized the company's focus on building efficient ML systems for low-compute environments (00:28:47).",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott believes that optimizing individual components will contribute to overall better performance, given the increasing constraints of computing environments and the likelihood of more ML applications running on devices (00:29:53). * On-Device SLM and Performance Transparency Tsavo Knott expressed interest in knowing their application's position in the queue for using on-device Small Language Models (SLMs) at the Windows operating system level. This would allow them to inform users if slow performance is due to system-level resource contention rather than the application itself. They reiterated the need to make their application as fast as possible (00:30:46). * Upcoming Sprint and Word of Mouth Tsavo Knott summarized the meeting, noting positive word of mouth but emphasizing the need to achieve a state where the application \"just works\" by refining the nano models (00:30:46). The Northstar KPI remains LTM queries per user per day (00:31:37). * Consolidation of Analytics Working Groups Smit Patel suggested consolidating the various analytics working groups (e.g., analytics day, retention) into a single, potentially longer, meeting to improve attendance and avoid miscommunications (00:31:37). Tsavo Knott agreed with the idea of an \"analytics weekly\" meeting, potentially on Friday mornings . * Summaries for All Hands Meeting Tsavo Knott requested Mark Widman, Sam Jones, and Mack Myers to provide a brief summary of their current status for the upcoming demo-heavy all-hands meeting . Suggested next steps * Mark Widman will provide data on the usage of local vs. cloud models for backoff and the granular properties for the action classifier classify label task to Tsavo Knott. * Hiro Tamada will explore combining analytics, data retention, and related working groups into a recurring meeting. * Sam Jones, Mark Widman, and Mack Myers will provide a status summary to Tsavo Knott for the all-hands meeting slides. * The group will create a funnel tracking desktop app boots, core dependency checks, sign-ins, and onboarding after the 12.0 release. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript Jun 6, 2025 wg-day1-retention - Transcript 00:00:00 Mark Widman: regardless um whether they have any connecting apps and so on, if they go from off on onboarding to on onboarding specifically with regard to the desktop app, they're going to get another ISR. Tsavo Knott: Yeah. So that's why here I'm thinking like if we did that chart by onboarding true uh or some type of like Yeah. Onboarding true is particularly an interesting one because it's yeah it's that that first ISR where you know you have a connection and you know like that user went through. I'd love to see that uh ratio if you will. Hiro Tamada: Mhm. Tsavo Knott: Yeah. Hiro Tamada: Yeah. Tsavo Knott: But by the way, like I said, all of the stuff will change because the desktop app is going to be the only app you download now.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "uh or some type of like Yeah. Onboarding true is particularly an interesting one because it's yeah it's that that first ISR where you know you have a connection and you know like that user went through. I'd love to see that uh ratio if you will. Hiro Tamada: Mhm. Tsavo Knott: Yeah. Hiro Tamada: Yeah. Tsavo Knott: But by the way, like I said, all of the stuff will change because the desktop app is going to be the only app you download now.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "And it's going to install a piece OS, which means that like the guaranteed you're going to have a connection the first time it boots up, right? Mack Myers: Um, Hiro Tamada: Yeah. Mack Myers: can I share this too? Tsavo Knott: Yep. Mack Myers: Just making sure this is decent. This is uh this is a board I have that's more desktop app oriented 00:01:13 Hiro Tamada: Heat. Mack Myers: uh with some of the new onboarding steps. It doesn't go into like the start forming memories, but this is just like consider this the number of people who boot the desktop app and then get to the start forming memories screen um and the percentage of such. This drop off right here, it could be due to a couple of things. The first thing is that it could be users who opted in to get rid of privacy. So, checked out of the turn telemetry off. Um, it could be people that, to your point, Sam, they got in the app, they're like, \"Ah, maybe I don't want this.\" They could have fallen off. But, as you can see from this screen to these other screens, it's pretty much, you know, a near one:1 ratio. Um, Sam Jones: This is awesome. Mack Myers: so it's looking pretty good. And then the next phase of this would be you know here I don't know if Nquille or yourself ever did anything related to like the start forming memories onboarding tour with all those uh events that we sent over but it would also be interesting either through mix panel or you know big query if we were to put together a table that kind of maps out that flow and sees how users are converting in that start forming 00:02:21 Mack Myers: memories like that memory memories formation flow um to are users completing it? Are they dropping off? Are they getting to 30 memories? You know, are we experiencing errors? Stuff like that. Tsavo Knott: Yep. Mack Myers: Um to really measure how that's going. Tsavo Knott: Yeah. Sam Jones: Mark, Hiro Tamada: Miguel has Sam Jones: could Hiro Tamada: all the dashboards around that should be Sam Jones: could Mack Myers: Nice. Sam Jones: we have a look at the the 30-day and the three month just to see what the trend was through? Mack Myers: Um yeah, it's kind of Sam Jones: Okay. Mack Myers: similar. Um, and I am filtering it by 4.1.0 4.1.12 and 3 because Sam Jones: Perfect. Mack Myers: this mainly existed after 4.1. Tsavo Knott: I mean the fact that that's less than 10% is not not too bad. Um I think you know after this 12.0 going to release mech.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "similar. Um, and I am filtering it by 4.1.0 4.1.12 and 3 because Sam Jones: Perfect. Mack Myers: this mainly existed after 4.1. Tsavo Knott: I mean the fact that that's less than 10% is not not too bad. Um I think you know after this 12.0 going to release mech.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "We're going to want a version of this which is like desktop app, you know, boots for the first time, ensure core dependencies, you know, like how how many people make it through that and then they get into the sign in, how many people get through the signin and then how many people get through, you know, the onboarding stuff. 00:03:29 Mack Myers: Yep. We will exactly have all that stuff. Tsavo Knott: Yeah, that'll be the nice the a really nice funnel. Mack Myers: Yep. Tsavo Knott: Yeah, nice. Uh, okay. Cool. Um, let me just share my screen here as well. So, two things. Number one, um, I think so a Northstar KPI on our side is just, uh, average number of messages per day, right? So like trying to get around here like uh this is like 17 for non uh non-copilot chats um or something like that. And then you know down here this is LTM uh chats. So 5 79 something like that. Um I think you know again this is our northstar. It's like can we get these number of chats uh that use LTM up? But nonetheless, I think all the selection work we're doing inside the workstream summary and the co-pilot, the fixes for the table rendering, the latte rendering, I think overall it's going to improve this queries uh per user per day significantly. I also think that uh the time to first token stuff that we're doing and the pre-wararming um I don't know if that's gone in yet or not, but when you click on that input calling that pre-warm endo endpoint or the preparation endpoint, I think that'll help this out just be a better experience. 00:04:51 Tsavo Knott: And then of course Sam, the quality of the the nano models themselves. I think that's important. Um we had some type of dip in here. I can't remember what exactly Sam Jones: Yeah, Tsavo Knott: it was. Sam Jones: it was it it was a it was a couple of things. So one one of the analytics events was being misattributed to a separate pipeline um as far as I remember and then there was I think that correlated with potentially like some of the issues we were having around um uh data corruption. Um I could be wrong. Tsavo Knott: Yeah, I think the data corruption stuff was probably earlier in the year, but we would have never even made it to this point of time if the data corruption happened because Sam Jones: Um Tsavo Knott: remember these Sam Jones: yeah. Tsavo Knott: are these are LTM specific queries. The data corruption stuff is more so in the the down wow like at large across everyone. Sam Jones: Yeah, true. And at that time we were using Quadrant, right? 00:05:58 Sam Jones: Well, when did we switch from Quadrant to catch base? Tsavo Knott: Yeah, that was like February. Sam Jones: That was February. Tsavo Knott: Yeah. Sam Jones: Yeah. Mack Myers: Thank you.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "would have never even made it to this point of time if the data corruption happened because Sam Jones: Um Tsavo Knott: remember these Sam Jones: yeah. Tsavo Knott: are these are LTM specific queries. The data corruption stuff is more so in the the down wow like at large across everyone. Sam Jones: Yeah, true. And at that time we were using Quadrant, right? 00:05:58 Sam Jones: Well, when did we switch from Quadrant to catch base? Tsavo Knott: Yeah, that was like February. Sam Jones: That was February. Tsavo Knott: Yeah. Sam Jones: Yeah. Mack Myers: Thank you.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: So, Sam Jones: Okay, Tsavo Knott: this this Sam Jones: my Tsavo Knott: is that Sam Jones: bad. Tsavo Knott: April period of time. Sam Jones: I don't know. I saw that, too. I assumed there was some Yeah, I don't Tsavo Knott: It Sam Jones: know. Tsavo Knott: looks Sam Jones: I Tsavo Knott: like Sam Jones: don't know Tsavo Knott: it Sam Jones: what Tsavo Knott: looks like it's Sam Jones: that Tsavo Knott: coming back up. Um and then of course like this stuff will you know follow like I think around January or something like that somewhere in this region we did uh a product hunt. I can't remember what all the the dry I think we probably picked up a good couple thousand people from the ads campaigns we were doing over the holidays but Sam Jones: Yeah, there was like two weeks where nobody used the WP. It looks like 00:06:41 Tsavo Knott: yeah yeah Sam Jones: if you look down the D there, it just created I'm not I suspect that's an analytics issue because Tsavo Knott: I think so Sam Jones: I Mark Widman: And Sam Jones: don't Mark Widman: when Sam Jones: really Mark Widman: did you pick Sam Jones: Yeah. Mark Widman: back? We pick backed up May 1. Tsavo Knott: Exactly. And it picked back up almost like instantly like Mark Widman: That is Tsavo Knott: you know Mark Widman: really Tsavo Knott: with with natural decay of users but at the Dow you know it's like boom. Yeah. So not bad there. Um I think this one's really interesting. Um MCP tool breakdown. So roughly 54 users ripping it in cursor now which is pretty cool on a a daily basis. Um, so I mean that's at least 20 more than our company. And then I think this one's also interesting is the average MCP tool call per user per day. Uh, which is also nice. So pretty great to see that. Um, we're taking a look at this. 00:07:33 Tsavo Knott: This is looking good as well. So this is um roughly Yeah, let me see here. This is the number of users where workstream gener uh summary was generated for that day. So pretty nice to see that. Um, and then this is workstream summaries uh per user like um so we're creating roughly 30 workstream summaries per user per day which is pretty nice as well. Sam Jones: Just Tsavo Knott: Um Sam Jones: a note that the Tsavo Knott: Yep. Sam Jones: 30 summaries a day is equivalent to 10 hours Tsavo Knott: That's Sam Jones: in that Tsavo Knott: right. Sam Jones: day with with pieces OS running and the LTM running. Tsavo Knott: That's Sam Jones: So Tsavo Knott: right. Sam Jones: that's pretty cool, I think. Yeah. Tsavo Knott: That's Mack Myers: I Tsavo Knott: really Mack Myers: saw Tsavo Knott: awesome. Mack Myers: it.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "pretty nice as well. Sam Jones: Just Tsavo Knott: Um Sam Jones: a note that the Tsavo Knott: Yep. Sam Jones: 30 summaries a day is equivalent to 10 hours Tsavo Knott: That's Sam Jones: in that Tsavo Knott: right. Sam Jones: day with with pieces OS running and the LTM running. Tsavo Knott: That's Sam Jones: So Tsavo Knott: right. Sam Jones: that's pretty cool, I think. Yeah. Tsavo Knott: That's Mack Myers: I Tsavo Knott: really Mack Myers: saw Tsavo Knott: awesome. Mack Myers: it.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 13
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: And then similarly if we look at the number of workstream events processed uh is roughly 537 per user per day which is excellent as well. Um considering we might process those every you know two to five minutes. 00:08:30 Mark Widman: I uh I just sent a change log. It looks like on May 1st precisely, uh, we added a ton of new new language models or yeah, new LLMs to our, uh, to our stack specifically that users could chat with from the cloud like a lot of the Gemini and OpenAI models. Tsavo Knott: Yep. Mark Widman: So, it could be interest related like people bouncing because we don't have the latest models. Tsavo Knott: Isn't it a kill on this call? Hiro Tamada: Um, I wish he was I mean I I should have asked him to join but Mark Widman: It'd Hiro Tamada: it's fine. Mark Widman: be interesting to see what models are used for some of those LTM queries as well and whether or not there are new or existing users. Tsavo Knott: Yes, definitely. Um, yeah. So, these are just kind of like some of the northstars. The interesting thing here though, I will say, Sam, is workstream events. The number of users that had workstream events processed in that day um versus let me take a look at this. 00:09:33 Sam Jones: There's something off there, isn't there? Tsavo Knott: That would Sam Jones: Doesn't Tsavo Knott: be why Sam Jones: make sense. We've got 2,000 users on with events and then 8,000 with summaries, but worth looking into as well. These analytics, when did they go in, Mark? Like a couple of days ago. So, Mark Widman: It it's possible uh I'm sorry to get you off there, but it is yes possible to have more summaries than LTM events um because MCP, but I know Sam Jones: more Mark Widman: we don't Sam Jones: users Mark Widman: have Sam Jones: with summaries. Mark Widman: MCP users. Sam Jones: Good point. Um, yeah, but I'm thinking as well, probably nice to let these bake for for Tsavo Knott: Let Sam Jones: a Tsavo Knott: me Sam Jones: week Tsavo Knott: see. Sam Jones: or so before we Mark Widman: They went in uh a week ago earlier this week. No, they went in on would have gone Sam Jones: fast. Mark Widman: in on Tuesday. Sam Jones: Thanks. Mark Widman: Monday or Tuesday? Sorry, Tsavo Knott: We 00:10:28 Mark Widman: I'm Tsavo Knott: should look at We should just triple check this one. But this is daily active users. who had this event. So, I'm not sure this is Mark Widman: Yeah. Tsavo Knott: daily active users that had this event. Mark Widman: Yeah. Sam Jones: We we my guess here is that because the summaries are associated with a periodic and correct me if I'm wrong here Mark we're probably firing that across all users and then skipping generating summaries if there's nothing to generate.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 14
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Thanks. Mark Widman: Monday or Tuesday? Sorry, Tsavo Knott: We 00:10:28 Mark Widman: I'm Tsavo Knott: should look at We should just triple check this one. But this is daily active users. who had this event. So, I'm not sure this is Mark Widman: Yeah. Tsavo Knott: daily active users that had this event. Mark Widman: Yeah. Sam Jones: We we my guess here is that because the summaries are associated with a periodic and correct me if I'm wrong here Mark we're probably firing that across all users and then skipping generating summaries if there's nothing to generate.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 15
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So, I'm guessing maybe maybe we just need to Tsavo Knott: Check that Sam Jones: adjust where Yeah. where the where the event is. Mark Widman: Yeah, it's most likely the case. Yep, that sounds proper. Yeah, either one we Yeah, probably just want to not do summary generation, right? Tsavo Knott: or you just check if it has contents. If the work summary has contents. Mark Widman: I think it pro will probably fail. I I bet you Sam Jones: Yeah. Mark Widman: if you look at a lot of the summary generations, you're going to see a lot of failures. 00:11:28 Tsavo Knott: Oh, okay. Sam Jones: This might be as simple as just changing the line the event gets fired on. Tsavo Knott: There's not a lot of failures. Mark Widman: Damn. Mack Myers: That's pretty good. Tsavo Knott: Yeah, we just need a way to verify one of the two. Something one of these two is wrong basically. Sam Jones: I think summaries summaries for sure is wrong. I think um although I'm a I'm a I'm a pessimist on this kind of stuff. Maybe we do have 8,000 users with the LTM switched on. Tsavo Knott: Yeah. And then so for example this one um this is the median execution time Sam I know we kind of had a question about median and average um what was the reason for that Sam Jones: So, um, the mean works really well when you've got a bell curve. Um, but the way these models work, they're either going to execute or something's going to go wrong. And in the cases where things go wrong, we've got a timeout, but that's all the way up at 15 seconds. And so this the distribution will look bell curvy and then flat and then a massive spike um in the tail. 00:12:52 Sam Jones: And what that does is it just pulls the mean way off base. Tsavo Knott: That's Sam Jones: Um Tsavo Knott: right. Sam Jones: and so whenever you've got a nonbell curve distribution um with potential outliers, you'd want to use the median. Um, so the me Yeah, it's a better it's a better approximation of like the Tsavo Knott: The Sam Jones: usual Tsavo Knott: actual Sam Jones: experience for a user. Yeah. Tsavo Knott: Yeah. So including our outliers, it looks like you know we these are the users probably like in India or like kind of like remote regions where you know they're making super global requests uh to these cloud models. But the nice thing is uh these outliers like on the like time and stuff these are probably just representative of slower devices.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 16
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "or like kind of like remote regions where you know they're making super global requests uh to these cloud models. But the nice thing is uh these outliers like on the like time and stuff these are probably just representative of slower devices.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 17
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So you're saying like you know worst case scenario on like slow devices time span prediction prompt title whatever else uh even this time classifier to roughly like one second each um versus like you know the median or the mean here is excuse me the median is looking pretty pretty 00:13:57 Sam Jones: So Tsavo Knott: uh Sam Jones: the Tsavo Knott: pretty tight. So, not bad of a delta, honestly. Sam Jones: in in this case you'd want to the the average is almost not informative because you would just need one user who took an awful long time and some edge case and that will wreck the wreck the measure. So I think we're talking about this on on Monday as well. Um but if you can give me the or let me know where that data lands, we can you know Kier Kieran can take a peek at it and get some charts and we'll be able to see you know we'll plot like we'll plot the distribution and we'll be able to see what the Tsavo Knott: Yeah. Sam Jones: majority of our users are actually experiencing. Um maybe this is really nice as a this to have this data is amazing and Tsavo Knott: Yeah. Sam Jones: um and yeah it's a great starting point but to get real insights out of it we'll need to we'll need to do a bit push it a Tsavo Knott: Yeah. 00:14:49 Sam Jones: bit further. Tsavo Knott: I I thought um this one was pretty interesting. I'll just blast this super fast. But um hang on one sec. Sorry. Close. Let me just duplicate this real fast. Show you guys this. I was looking at this last night because uh I was trying to make some benchmarks for the time classifier package that I was building up. But yeah, so we can just kill that. We got the task. So Sam Jones: So Tsavo Knott: we'll just have this task up here and then Sam Jones: one extra thing, one confounding factor here to note on the time classifier particularly here is that currently there's a back off to a cloud model. So the numbers we're we'll be seeing here specifically for the span prediction are going to be way higher then Tsavo Knott: Yeah. Sam Jones: yeah it's we've got almost two distributions in the same the same chart. One where we back off which is be way longer and one where we don't. Tsavo Knott: Interesting. 00:15:47 Sam Jones: Yeah. Tsavo Knott: Mark, do we have any backoff data? Uh, like do we have any way to know if it was using the local model or the cloud model? Sam Jones: Okay. Mark Widman: Yep, there should be a property on there of cloud. Tsavo Knott: Okay. So, let's see here. Um, all right. So, I will clear this.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 18
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "which is be way longer and one where we don't. Tsavo Knott: Interesting. 00:15:47 Sam Jones: Yeah. Tsavo Knott: Mark, do we have any backoff data? Uh, like do we have any way to know if it was using the local model or the cloud model? Sam Jones: Okay. Mark Widman: Yep, there should be a property on there of cloud. Tsavo Knott: Okay. So, let's see here. Um, all right. So, I will clear this.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 19
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "But yeah, Sam, definitely worth taking a look at this where we can say, you know, we can look at the queries on all of these and we can say like, you know, of content retrieval, you know, are these like proper not or temporal, you know, proper not, whatever else. But we're actually starting to get a pretty nice data set in here. Um, Sam Jones: That's really cool. Can Tsavo Knott: for Sam Jones: we do the same on the context intention router? That would also This is great. I didn't Tsavo Knott: course. Sam Jones: realize Tsavo Knott: Yeah. Sam Jones: we Tsavo Knott: So, Sam Jones: would have this. This is amazing. 00:16:32 Tsavo Knott: yeah. Yeah. Mark and I, we spent a lot of time layering this s*** in, but see here. Hang on. Apologies. Sam Jones: And we've got a lot of this in Big Query as well, sort of tracking the whole flow, but this is just really nice to look at. Tsavo Knott: Yep. I'll fix all this s*** later, but um let me duplicate this real fast. f****** mix panel takes forever. Um all right, let's see here. So, we're going to go to Sam Jones: What's what's really interesting here? What I'm particularly interested in is are are there users who are making general queries but with the LTM switched on because that's a really nice place where you can improve the user experience. Right? If a user is asking, you know, how to fix this Python code and they're having to wait for the LTM stack to complete, that's that's not an optimal um use UI UX. Sorry. Tsavo Knott: We have an interesting amount of invalid index. Sam Jones: Oh, we patched that, didn't we, Mark? 00:18:09 Sam Jones: I saw something whilst I was away. There was Mark Widman: Um, I'm not sure not sure what that is. Tsavo Knott: A lot of a lot of timeouts. That's most of our timeout is future not complete. Timeout exception after 10 seconds. Sam Jones: weird. Let me have a look at where this um Hiro Tamada: So we Sam Jones: what we're Hiro Tamada: can Mark Widman: the Sam Jones: wrapping with this event. Hiro Tamada: we actually Mark Widman: the Hiro Tamada: get that Mark Widman: timeout the timeout of 10 seconds I would believe. Oh, wait. Is that the backbone classifier having an issue with that timeout or Sam Jones: Yes, Mark Widman: is Tsavo Knott: Yeah. Mark Widman: it Tsavo Knott: Yeah. No, this is this is the uh classified context injection. Sam Jones: that's the under the hood. I think it's the backbone classifier. Mark Widman: just Tsavo Knott: Yeah. Sam Jones: That seems that seems off in terms of oh, is this execution speed Tsavo Knott: This Sam Jones: not? Tsavo Knott: is Oh, sorry. This is uh Let me just rename this. 00:19:15 Tsavo Knott: Um Sam Jones: Yeah, that's the median of time elapsed.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 20
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "that timeout or Sam Jones: Yes, Mark Widman: is Tsavo Knott: Yeah. Mark Widman: it Tsavo Knott: Yeah. No, this is this is the uh classified context injection. Sam Jones: that's the under the hood. I think it's the backbone classifier. Mark Widman: just Tsavo Knott: Yeah. Sam Jones: That seems that seems off in terms of oh, is this execution speed Tsavo Knott: This Sam Jones: not? Tsavo Knott: is Oh, sorry. This is uh Let me just rename this. 00:19:15 Tsavo Knott: Um Sam Jones: Yeah, that's the median of time elapsed.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 21
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: this is the general I can just do total events. Nice. And then Sam Jones: Oh, Tsavo Knott: let me Sam Jones: there Tsavo Knott: go Sam Jones: we Tsavo Knott: to Sam Jones: go. Tsavo Knott: apologies. Let me go to um let's see if how the error is looking. So these are the types of errors not set which is great. So majority are not set but definitely you should look at the the invalid index on classifier label 51. Um Mark Widman: Oh, Tsavo Knott: that's Mark Widman: sorry, sorry, sorry, sorry, sorry. Yes, that I'm sorry for slow being slow on that one. Tsavo Knott: yeah Mark Widman: That Sam Jones: We Mark Widman: is Sam Jones: fixed Mark Widman: resolved Sam Jones: that, right? Mark Widman: even though it is an error. It's caught and it's used as a default. But yes, that is there is an error in the classifier. Tsavo Knott: and then Mark on this let me just blast this JSON mode here. 00:19:59 Tsavo Knott: Do you know how where the result of this goes? Mark Widman: Um, yep. It should be a little bit higher up. So, it's likely just getting caught and it's just handled um further up the stack because these are these are at the lower level in the ML facade. But I believe what we're doing is we're actually catching it in ISO server and we're just defaulting to a default. Tsavo Knott: Got it. Sam Jones: We're defaulting to running the the Mark Widman: But in Sam Jones: LTM. Mark Widman: a successful Yeah, in a successful event, we should have those properties on there. Action classifier classify label. Then we we should have a bunch of those like additional properties and stuff on there. I can I can send the granular ones too if you want for that specific Sam Jones: Nice. Mark Widman: task. Tsavo Knott: There you go. Sam Jones: uninformative unfortunately. Tsavo Knott: So the not is probably the number of errors the error ones. Sam Jones: Um, Mark Widman: So are Sam Jones: let Mark Widman: those Sam Jones: me 00:21:11 Mark Widman: the Sam Jones: take Mark Widman: number? Sam Jones: a look at Mark Widman: Yeah. Sam Jones: let me let me take a look at this um and Tsavo Knott: Okay, Sam Jones: I'll Tsavo Knott: cool. Sam Jones: I'll get Tsavo Knott: Yeah, Sam Jones: back to you. Tsavo Knott: I threw that in here and then we just pop into this one. Um, Sam Jones: because it looks like here we've got some not set as well. So I'm wondering where Mark Widman: Yeah, Sam Jones: that's coming from. Mark Widman: my guess is that Tsavo Knott: have Mark Widman: if the Tsavo Knott: a lot less knots. Mark Widman: it was likely an error, but we Sam Jones: Yes, Mark Widman: could probably Sam Jones: maybe the Mark Widman: also see a one one.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 22
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones: back to you. Tsavo Knott: I threw that in here and then we just pop into this one. Um, Sam Jones: because it looks like here we've got some not set as well. So I'm wondering where Mark Widman: Yeah, Sam Jones: that's coming from. Mark Widman: my guess is that Tsavo Knott: have Mark Widman: if the Tsavo Knott: a lot less knots. Mark Widman: it was likely an error, but we Sam Jones: Yes, Mark Widman: could probably Sam Jones: maybe the Mark Widman: also see a one one.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 23
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "We should we should likely see a one one if it failed and that property is not set and that's the proper task. Tsavo Knott: The cloud overwhelmingly says it's content retrieval. Sam Jones: is the cloud. Back up. Back off. Yeah. Tsavo Knott: That's right. Sam Jones: Yep. 00:22:02 Sam Jones: I mean Salv Tsavo Knott: Yeah, Sam Jones: to your point Tsavo Knott: not Sam Jones: earlier Tsavo Knott: bad. Sam Jones: like the um nailing these micro models is definitely our sort of P 0 at the moment and Tsavo Knott: Yeah, Sam Jones: once Tsavo Knott: P 0. Sam Jones: once we've done that we can we can take these cloud back off training wheels Tsavo Knott: Yeah, exactly. Um and then this is the only other thing is this is the time to first token median. So this is your total time. So total time to first token for folks right here um is you know roughly three or excuse me roughly five seconds almost six and then if you look at context aggregation and uh uh completion of first LLM to token yeah and then these are your average trends of time to first token. So this is the average versus this is the median. So if we change this to average. Now the average metric is the harder goal to get. You know what I'm saying? Um 00:23:09 Sam Jones: It's Tsavo Knott: but the median is helpful. Sam Jones: the again the average the mean here is I would say is non-informative because any outliers like if hero for example you've been up in the P99s and sometimes you know we've got users that take eight hours to complete something. And so a single eight hour event is going to massively massively bias our mean. Um and so because we're not doing any outlier removal here, I'd say median is as good as we get until until I get the plots. Um and then Tsavo Knott: Yep. Sam Jones: we we'll be able to we'll be able to all of the timeouts will be in a a line and we can just remove those and then then the meme becomes informative. Tsavo Knott: Yeah. Mark Widman: Yes, I do agree. Um I think that with those outliers both like um like further outside of three standard deviations outside of the mean. Um I think that that's definitely pulling. Um that being said, I do think it's still informative in a different way. uh that says especially if our average is pulling us that hard uh in in difference to the median that tells us that we could potentially have like model loading problems or we could potentially have like an uncompleted completer or we could have various edge cases. 00:24:33 Mark Widman: So I think it's informative but just in a different way. Tsavo Knott: Yeah, the Sam Jones: Oh Tsavo Knott: P75 Sam Jones: yeah, Tsavo Knott: is also Sam Jones: once Tsavo Knott: interesting.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 24
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "said, I do think it's still informative in a different way. uh that says especially if our average is pulling us that hard uh in in difference to the median that tells us that we could potentially have like model loading problems or we could potentially have like an uncompleted completer or we could have various edge cases. 00:24:33 Mark Widman: So I think it's informative but just in a different way. Tsavo Knott: Yeah, the Sam Jones: Oh Tsavo Knott: P75 Sam Jones: yeah, Tsavo Knott: is also Sam Jones: once Tsavo Knott: interesting.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 25
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones: we once we check once we've got the distributions, we'll be able to see, okay, look, these users are are Tsavo Knott: Yeah. Sam Jones: deep in the tail there. We can see if we can see any patterns between them. Maybe they're on bad systems. Maybe they're in certain parts of the globe with slow internet. Mark Widman: Yeah. Tsavo Knott: Yeah. Sam Jones: Maybe if there's variance there, then it's like if we see lots of different systems, then it's probably an us problem. Um, but yeah, I think I'm not I'm not trying to discount this. I think it's super useful. I just don't want to jump in the wrong direction. Tsavo Knott: No. And of course, Mark Widman: Is Tsavo Knott: like on our side, if this is going up, like if we just continue to look at the a consistent metric like the P75 or whatever else, if this continues, if this continues to go up, then we're doing something wrong. 00:25:27 Tsavo Knott: But if this goes down, then we're doing something right. Right? So that's kind of where this is just a binary metric, which is saying like, hey, for the way we're looking at it, is it going up or down? And our goal is to make it go down, right? Sam Jones: Yeah, there's also um I agree there's also like a potentially a wider question here which is and you know this is not necessarily the forum for it but are we are we building something that's going to like is our northstar let's make this work for everybody on all machines or is it you know we're building something that's high-spec and going to work for a specific segment of our of our user base in Tsavo Knott: I Sam Jones: a Tsavo Knott: mean, Sam Jones: similar way like you Tsavo Knott: yeah. Sam Jones: can't run Intelligj on a 8 megabyte Tsavo Knott: No, you Sam Jones: like Tsavo Knott: definitely Sam Jones: 8 gigabyte of RAM like Tsavo Knott: I think that you know I think you know for example like the beauty of Google Chrome and the engineering that they got done there was it became the default you know browser for everyone because no matter how bad your device was, it was relatively fast, right? 00:26:38 Tsavo Knott: And if we think about, you know, um like pieces for everyone, you know, our next kind of cohort is like, you know, digital professional workers, if you will. Um if we can make the installation and permissioning setup as simple as Zoom, like if we can get it to the the Zoom level. So if you know how to use Zoom, you can use pieces.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 26
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "know, our next kind of cohort is like, you know, digital professional workers, if you will. Um if we can make the installation and permissioning setup as simple as Zoom, like if we can get it to the the Zoom level. So if you know how to use Zoom, you can use pieces.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 27
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh and also you know if you are a designer or you know you're an animator or you're working on like financial data or whatever else like you know the Chris profile like he's running on a M2 MacBook Air how's that thing look you know um and go from there right so I think like you know for sure the goal is going to be a a broader audience like I don't think we have to support you know someone's MacBook from 2015 15 2017 even like you know those are pretty long periods of time ago. Um and also too if you're not investing in the device you use for work you're probably not that much of a digital professional if you will. 00:27:42 Tsavo Knott: Um, but yeah, I mean, and developers are interesting, too, because their device, so it's funny. Developers are interesting because their device is flooded with a ton of different tools. But normal people, uh, like my mom for example, she's interesting because she doesn't know how to use a computer. So all she'll just leave tons of windows open, tons of tabs open, like everything like that, right? And that's I think like you know more of the my mom is a digital professional right she's a you know clinical psychologist and whatever else and she does all that s*** she does all her research papers for her schools and stuff like that but she yeah her computer's a absolute nightmare right like her desktop's completely flooded ton of windows open you know whole nine yards and I think like that's the type of people where it's like hey you know can my brother Maxon use pieces during med school right or you know And Sam Jones: Yeah. Tsavo Knott: like that's what we're shooting for, right? Sam Jones: Yeah. I um the what I would love and would be super useful is just like a minspec. 00:28:47 Sam Jones: Um Tsavo Knott: Yeah. Sam Jones: so I not now obviously but like as a group maybe we have to for for to help us in terms of like know when we're done. It would be great to have like a couple Tsavo Knott: Yeah. Sam Jones: of minsspec machines. I'm sure M probably find find it pretty useful as well and we can just be like right if it runs on like this we're golden. Um Tsavo Knott: Yeah, Sam Jones: Yes. Tsavo Knott: but I will say the other funny part is uh you know we we had a call with the uh with the Google with Sundar's team and Google Labs went really well. We have a technical diligence call with them tonight at 6 my time. Uh and they're like, \"Yeah, we also want you guys to do research on how this could potentially run on Android.\" Right? So like, you know, you're like, \"f***.\" I mean the devices are you know what I'm saying?",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 28
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Jones: Yes. Tsavo Knott: but I will say the other funny part is uh you know we we had a call with the uh with the Google with Sundar's team and Google Labs went really well. We have a technical diligence call with them tonight at 6 my time. Uh and they're like, \"Yeah, we also want you guys to do research on how this could potentially run on Android.\" Right? So like, you know, you're like, \"f***.\" I mean the devices are you know what I'm saying?",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 29
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So it it is performance will always thing and I think like if our company's mantra is to build good ML systems that run you know in low compute environments like that's where the true IP comes in but that said like it begins at a component by component level if you will. 00:29:53 Tsavo Knott: So, you know, I think having a spec is nice for for an intermediate northstar, but no matter what, if we can get all the systems to just run as best as they can in isolation, like the culminative summation of the systems will be low as well, right? Um, so we'll we'll always have to have an eye towards when to boot these things, when to run them, how are they running, you know, so on and so forth. Um, because the the environment constraint is actually probably just going to only get harder, if you will. Sam Jones: True, Tsavo Knott: Yeah. Sam Jones: true. Tsavo Knott: Yeah. Sam Jones: There's um yeah, we get sandwiched a little bit between time to first token and environment basically, Tsavo Knott: Totally. Sam Jones: but Tsavo Knott: And the Sam Jones: we Tsavo Knott: other Sam Jones: can Tsavo Knott: thing that you got to know is we're not going to be the only one running an ML app in the next decade, right? Like, you know, everyone's going to start running ML apps on device, you know, so on and so forth. 00:30:46 Tsavo Knott: So, you know, even that in my message to the foundry local team the other day, it was like, I'd like to know where I am in the queue to use an ondevice SLM that's at the Windows operating system level, right? So, we Sam Jones: Thank Tsavo Knott: can Sam Jones: you. Tsavo Knott: show the user, hey, it's not taking a long time because it's our app. It's taking a long time because five other apps are requesting a, you know, an SLM to process this data, right? So, like that's another consideration where we generally Sam Jones: Hold Tsavo Knott: have to just make ours as fast as f****** possible. Yeah. Sam Jones: on. Tsavo Knott: Yep. Cool. Um, good chat team. Thanks for checking in on the data. Uh, I got a call with Chris later today. Um, but yeah, on our side, big big big sprints. Uh, we need to have a crazy month in June here. Um, and we're gonna we're going to keep keep doing the stuff on the the growth side. 00:31:37 Tsavo Knott: Um, I think generally word of mouth is starting to be pretty positive for us. You know, people who do make it in and and are enjoying it pretty nice. But, you know, Sam, we still want to get to that, you know, it just works type of type of benchmark. Just get those nano models locked in, stuff like that. Um, and we'll go from there. Yeah. LTM queries per user per day. That's the northstar. Awesome.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 30
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "crazy month in June here. Um, and we're gonna we're going to keep keep doing the stuff on the the growth side. 00:31:37 Tsavo Knott: Um, I think generally word of mouth is starting to be pretty positive for us. You know, people who do make it in and and are enjoying it pretty nice. But, you know, Sam, we still want to get to that, you know, it just works type of type of benchmark. Just get those nano models locked in, stuff like that. Um, and we'll go from there. Yeah. LTM queries per user per day. That's the northstar. Awesome.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 31
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh, any other questions for the group? Smith, anything on your side. Smit Patel: No. Um only thing is hero um I know we have a few of these working groups around um like analytics day on retention all that I think it might be maybe we could just combine it into one even if it needs a longer meeting. Um like Mack Myers: What? Smit Patel: for example Nikil wasn't able to join. I'm not sure why he didn't join. I maybe there was some miscommunication. I want to make sure that you know he doesn't miss the meetings. Um, so maybe just keep one and like let's make make it a point to have it at the same time if possible so that way people are not confused if it's happening or not. Tsavo Knott: Yeah, I think like a engineering weekly equivalent like analytics weekly Smit Patel: Yeah, something like Tsavo Knott: on Smit Patel: that. Tsavo Knott: Fridays, Smit Patel: That's totally fine. Tsavo Knott: Friday mornings. Smit Patel: Yeah, we'll all, you know, make make it a point to show up. Tsavo Knott: Yep, that'd be excellent. Hiro Tamada: Okay, looks Tsavo Knott: Fantastic. Hiro Tamada: good. Tsavo Knott: a bit. So Sam Mark Mack. If you guys could give me a little summary of where you guys are at, I'll throw that into slide for you guys. And then yeah, any demos you guys want to bring would be awesome. We're gonna do a pretty demo heavy. All hands today for folks Smit Patel: Cool. Mack Myers: Cool. Smit Patel: All Tsavo Knott: Excellent. Smit Patel: right. Thanks, bye. Tsavo Knott: Thanks you. But Transcription ended after 00:33:28 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "1OXCtV4shhcTkbrJwqYyD5S2tMCVkJVIZ6kXOWc88cNg",
    "chunk_index": 32
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 6, 2025 Pieces All Hands (Demos) Invited Team Tsavo Knott Molly Kate Jubril jackross210@gmail.com Nikhil L Hanna Stechenko Jack Ross Antreas Antoniou Nolan Taft Attachments Pieces All Hands (Demos) Meeting records Transcript Recording Summary The meeting covered the upcoming 12.0 release with abuse prevention, the paywalled Pieces Pro plan, usability improvements, installer stability, and database migration as announced by Tsavo Knott and Mark Widman. Mark Widman also demoed the Pieces Pro checkout and discussed paywall enforcement. Sam Parks presented the revamped markdown experience and custom components enabling workstream summary editing, while Nolan Taft showcased the new documentation website with SEO and admin features, rapidly developed as highlighted by Tsavo Knott. Bishoy Hany presented the refactored CLI with new features, Rutvik Tak detailed performance optimizations in Flutter apps, and Smit Patel discussed company-wide AI adoption for increased automation, with Tsavo Knott further elaborating on AI's potential and sharing ML analytics showing positive user engagement. Details * 12.0 Release Overview Tsavo Knott outlined the upcoming 12.0 release, highlighting abuse prevention measures that will introduce breaking changes to O provider enums, but aim to prevent future enum-related breaking changes. The release will also feature the first paywalled feature, Pieces Pro plan, which will gate access to Claude 4 models and potentially other features like the number of summaries or daily queries (00:00:00). Additionally, usability improvements are being made to the co-pilot, nano models are being retrained with Onyx runtime upgrades, and users will gain the ability to edit summaries (00:00:57). * Installer Stability and Database Migration Tsavo Knott announced the upcoming release of ultra-stable installers across Mac OS, Linux, and Windows, simplifying the installation process by offering a single desktop app installer (00:01:53). Furthermore, the database location on Windows is being moved to improve day-one retention, reduce Windows Defender issues, and future-proof against Windows' potential changes to user documents folders. Mark Widman confirmed that the database migration was another key update (00:02:53). * Pieces Pro Checkout Implementation Mark Widman demoed the Pieces Pro checkout page within Pisces OS, showcasing the user flow for subscribing and managing their plan (00:03:51). The demo included switching between monthly and yearly billing, entering payment details, and simulating successful transactions and plan updates (00:04:49). Mark Widman highlighted the contributions of Hero and Brian to this implementation (00:07:21). * Paywall Enforcement and Edge Cases Mark Widman discussed the enforcement of paywalls, ensuring that unauthenticated users cannot access paywalled features like Claude 4 (00:09:27). They also detailed handling edge cases such as cancelled or expired plans, plan updates, and preventing malicious users from exploiting paid features by monitoring user check-in activity within a 72-hour period (00:10:28). The initial paywall MVP will focus on Claude 4 to ensure the infrastructure is robust for future expansion (00:11:34). * Revamped Markdown Experience Sam Parks presented the significant improvements to the markdown experience in Pieces, showcasing the ability to render and copy/paste markdown tables and bulleted lists with their formatting intact (00:12:26). This enhancement addresses previous issues where copied markdown lost its structure and richness.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "detailed handling edge cases such as cancelled or expired plans, plan updates, and preventing malicious users from exploiting paid features by monitoring user check-in activity within a 72-hour period (00:10:28). The initial paywall MVP will focus on Claude 4 to ensure the infrastructure is robust for future expansion (00:11:34). * Revamped Markdown Experience Sam Parks presented the significant improvements to the markdown experience in Pieces, showcasing the ability to render and copy/paste markdown tables and bulleted lists with their formatting intact (00:12:26). This enhancement addresses previous issues where copied markdown lost its structure and richness.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott emphasized the fundamental importance of this improvement for usability and workflows (00:15:37). * Custom Markdown Components and Workstream Summaries Sam Parks further demonstrated the new custom markdown components that enhance the user experience and leverage long-term memory (00:17:18). Mack Myers added that this markdown update will pave the way for users to edit workstream summaries as rich text while maintaining the underlying markdown integrity (00:18:41). Tsavo Knott explained the plan to create an endpoint to save co-pilot responses as workstream summaries with interactive elements like checklists preserved in markdown (00:19:42). * Workstream Summary Editing and Copying Sam Parks showed the new markdown rendering in workstream summaries, demonstrating the ability to retain styling when copying and pasting (00:20:37). Tsavo Knott expressed excitement about the upcoming world-class editing experience that will support both direct markdown editing and rich text editing (00:21:36). * New Documentation Website Development Nolan Taft presented the entirely new documentation website built to replace the sunsetting Hashnode platform (00:21:36). The new site offers a customizable landing page and maintains a similar document style to Hashnode (00:22:37). Key features include GitHub authentication, a built-in browser-based editor for content and navigation management, real-time updates via Superbase, and WYSIWYG editing capabilities (00:23:28). * Documentation SEO and Administrative Features Nolan Taft detailed the comprehensive SEO options integrated into the new documentation platform, addressing a major limitation of Hashnode (00:25:14). The platform also includes an admin page for managing the Pieces documentation bot (which handles PRs), repository linking, a custom sync button, user management, and access codes for editor sign-ups (00:26:05). Tsavo Knott suggested password-protecting the login page for added security (00:27:54). * Rapid Development of Documentation Platform Tsavo Knott highlighted the rapid five-day development of the new documentation platform, transitioning from no-code Hashnode to a custom solution after Hashnode announced its sunsetting and other platforms didn't meet their needs. Nolan Taft explained the research and development process, opting for a combination of pre-compiled and custom compiler components for flexibility (00:28:33). Tsavo Knott praised the team's versatility in moving from low-code to high-code environments and the resulting blazing-fast, SEO-friendly website (00:30:28). * CLI Refactor and New Features Bishoy Hany showcased the significant refactor of the Pieces CLI, including comprehensive documentation and examples for all help commands (00:33:10). They demonstrated the new MCP setup process with improved UI elements like loading indicators and permission requests. Bishoy Hany also presented new MCP commands like `surf` and `stdio`, replacing the HTTPS config, and the ability to provide specific queries (00:34:22). Tsavo Knott commended the rapid progress and the inclusion of features like drop-downs and feedback loops (00:36:16). * Performance Optimization in Flutter Apps Rutvik Tak presented research and development efforts focused on improving performance in the Pieces desktop app and other Flutter applications, particularly on lower-end machines. They demonstrated UI pipeline monitoring to identify jank and frame drops, especially in views with extensive content (00:38:40). Rutvik Tak showcased techniques for granular widget re-rendering and individual state management to avoid unnecessary rebuilds, which is crucial for performance-intensive elements like code syntax highlighting (00:40:36).",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "ability to provide specific queries (00:34:22). Tsavo Knott commended the rapid progress and the inclusion of features like drop-downs and feedback loops (00:36:16). * Performance Optimization in Flutter Apps Rutvik Tak presented research and development efforts focused on improving performance in the Pieces desktop app and other Flutter applications, particularly on lower-end machines. They demonstrated UI pipeline monitoring to identify jank and frame drops, especially in views with extensive content (00:38:40). Rutvik Tak showcased techniques for granular widget re-rendering and individual state management to avoid unnecessary rebuilds, which is crucial for performance-intensive elements like code syntax highlighting (00:40:36).",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* Differential Rendering and List Performance Rutvik Tak illustrated performance improvements in list views by tracking individual widget rebuilds and using state controllers to prevent full list re-renders when items are added or modified (00:44:42). They also demonstrated a Flutter mixin to prevent off-screen widgets from being disposed of and rebuilt during scrolling, which is beneficial for complex elements. Tsavo Knott connected these efforts to the concept of differential rendering, aiming for significant performance gains (00:47:21). Mack Myers emphasized the critical nature of these optimizations at scale given the amount of data flowing through Pieces OS (00:49:29). * AI Adoption Across the Company Smit Patel discussed the company-wide initiative to increase AI adoption and automation in every role, aiming to boost output (00:51:28). They mentioned ongoing projects like rebuilding the homepage with AI assistance, significantly reducing the typical timeframe. Smit Patel highlighted the importance of \"dogfooding\" their AI technology and shared a resource for assessing individual AI usage (00:52:30). Tsavo Knott emphasized the empowering aspect of AI, enabling individuals to take on diverse tasks and leading to a convergence of engineering roles (00:53:44). * AI-Powered Automation and ML Analytics Tsavo Knott described the potential for AI to automate tasks like generating change logs from meeting notes and providing relevant documentation for support issues. They also shared analytics from the ML team, showcasing the performance benchmarks (median speed) of various models in production, including context classification, summarization, and prompt moderation (00:54:46). The analytics platform allows for inspecting the data used to train and benchmark these models, facilitating continuous improvement (00:55:44). Tsavo Knott noted the positive trend in user engagement, with a high number of daily workstream events and summaries per user, indicating strong retention (00:57:47). Suggested next steps * Tsavo Knott will ensure Bishoy Hany gets a Claude Pro plan. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript Jun 6, 2025 Pieces All Hands (Demos) - Transcript 00:00:00 Tsavo Knott: telemetry, excellent for, you know, kind of doing communications with our users, um, just understanding the funnel, whatever else. Um, so yeah, and also just preventing abuse. But that will be, uh, a breaking change where we'll have some new O provider enums, but also hopefully past that, given Rob's work and Mark's work, uh, we should not have breaking changes tied to enums anymore. So that's kind of number one. Uh, number two, we'll see a demo of this a little bit later, but we're going to have our first paywalled feature, which will be awesome. So, the pieces pro plan, um, we'll figure out the final price. We're thinking like, you know, somewhere 16, $18.99, you know, just under whatever the kind of average pro plans are out there, but we think that, uh, pieces is going to continue to be a great place for, you know, a $20 subscription to have access to all the best models.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So that's kind of number one. Uh, number two, we'll see a demo of this a little bit later, but we're going to have our first paywalled feature, which will be awesome. So, the pieces pro plan, um, we'll figure out the final price. We're thinking like, you know, somewhere 16, $18.99, you know, just under whatever the kind of average pro plans are out there, but we think that, uh, pieces is going to continue to be a great place for, you know, a $20 subscription to have access to all the best models.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh, we also making some really nice fundamental upgrades. uh when it comes to usability to the co-pilot, we'll see a demo on that soon. 00:00:57 Tsavo Knott: But uh Claude 4 and Cloud4 SA and Cloud4 Opus will be going out. They will be paywalled under the pro plan. Um this will be because it's a net new model, it'll be paywalled for everyone and we'll continue to figure out things to paywall such as like number of summaries or you know number of queries per day or conversations. Uh but we're just going to start with the model itself. We're going to kind of do some experimentation and see how that goes. Um, so also very exciting there. Uh, going to be pretty tremendous. We will have a couple of updates to our nano models as well. So we kind of noticed, hey, you know, the performance is not exactly where we want it to be. So we're retraining some of that stuff. Uh, we'll also be serving them in a new Onyx runtime upgrade. Should see some nice hardware acceleration on that side. Um, and then there's a whole bunch of stuff kind of behind the scenes. Ideally, uh, you also have the ability to edit summaries now. 00:01:53 Tsavo Knott: So, pretty pretty awesome stuff. Mac, I don't know. Uh, yeah, we got the Gemini notetaker on, but definitely if you're doing anything on growth side or or anything on um, you know, a team where it's like, hey, this release is going to be important. This stuff is is key. Uh the final thing for the release is I know we've been saying it for months but we've got the Giga Chad level ultra stable ultra tested uh installers. So I think seven installers to start I believe across Mac OS Linux and Windows Rob myself uh we spent the last like I don't know Rob probably like three four months going down that that pipeline Rob I know you did a lot of the heavy lifting towards the end there but I mean the attention to detail is unbelievable. So finally, I think we're feeling confident enough to say, \"Hey, the only app you're going to install off the website is the desktop app.\" And from the rest of the pipeline, it'll be completely handled. Uh, so no more having to install pieces OS and and the desktop app separately. 00:02:53 Tsavo Knott: So those are the big things. Mark me, am I am I missing anything? Mark Widman: Uh, I think you hit everything. The only other one would be the database migration. Tsavo Knott: Yeah. Yeah. Kind of. That's one nuance for folks. Uh we are moving the location of the database on Windows. Um so it also should help improve day one retention, reduce like Windows Defender issues, reduce permission requirements, things like that.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So those are the big things. Mark me, am I am I missing anything? Mark Widman: Uh, I think you hit everything. The only other one would be the database migration. Tsavo Knott: Yeah. Yeah. Kind of. That's one nuance for folks. Uh we are moving the location of the database on Windows. Um so it also should help improve day one retention, reduce like Windows Defender issues, reduce permission requirements, things like that.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "U and it'll also futureproof us a bit against whatever Windows is going to do to embed your documents folder or to uh to move it up to the cloud with Windows u one drive. So yeah, that'll be a nice nice change as well. Cool. Um, so yeah, on that side, I think we'll start out with some demos, which would be awesome. If there's no questions on the 12.0 release, uh, if there are, feel free to, you know, hit us up or ask on this forum, you know, but yeah, it's going to be a sprint roughly, call it eight days from now. 00:03:51 Tsavo Knott: We're going to try and get that thing out, which would be excellent. Um, I know a lot of people have demos across the board. Uh, any takers on who wants to go first? I do have a list on my side, but let's just want to see if there's any brave souls out there. Mark Widman: I can go first. I Tsavo Knott: All Mark Widman: don't Tsavo Knott: right, Mark Widman: mind. Tsavo Knott: Mark. Send it. Mark Widman: Alrighty. Um, I'm gonna take the wheel here. Also, apologies everyone. I am a bit under the weather still. Uh, but I'm going to make it through. Um, so what are we looking at here? Uh, basically I have Pisces OS running in debug. Uh, I've got it running. Um, I've got uh I've got a staging Flutter app that basically what it what it's going to do here, its only goal is to kick out a checkout page. However, how this looks in the app, um, it'll go through its own separate flow within the desktop app that triggers that checkout. 00:04:49 Mark Widman: So, basically all this is going to do here is trigger the checkout with my user and it uh it popped over to my other browser so I had to drag it over here. And here we go. So, here is the the pieces checkout page and we'll adjust some of the colors and and all that sort of fun stuff. I know Mac is on that. Um, and you can switch over to a yearly mode and so on. And the prices aren't uh nailed down, but that's very easy stuff on our side. Um, and then all I'll do here is I'll go ahead and add some of these details. Cool. I'll put in um a just a credit card that they give us uh to simulate a successful transaction. And then what we should see here blah blah blah. We should see some sort of a successful event. But I did miss I missed the second part where there's a little bit of an edge case right now where if there's two streams listening uh we're not going to get the successful event. 00:06:10 Mark Widman: So we'll we'll fix that on our side.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "put in um a just a credit card that they give us uh to simulate a successful transaction. And then what we should see here blah blah blah. We should see some sort of a successful event. But I did miss I missed the second part where there's a little bit of an edge case right now where if there's two streams listening uh we're not going to get the successful event. 00:06:10 Mark Widman: So we'll we'll fix that on our side.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "But the expectation here is that when this completes, we'll get an event on uh from OS server that'll then propagate and it'll trigger a user refresh, which I will simulate right now by just refreshing pieces OS. And all of this happens in real time. So it shouldn't require a user to have to sign in and sign out. Um, and then we can see that we were able to refresh our user. Um, we were able to add all the subscriptions they had. Um, and then we can also verify that with their local user object here. So, we've got their subscriptions. We've got a UID for them. Um, and then we can see subscription and it should be this. Um, and yeah, here's the monthly plan. Um, and then the last thing I have to show you. And I have this kind of set up as a testing right now, but what this is going to happen is it'll actually launch our second part of things. 00:07:21 Mark Widman: So, after a user has already completed a checkout, they need the ability to go ahead and like cancel their plan or update their plan or update their credit card or um change from a yearly to a monthly and so on. So, we'll see that we have that redirect triggered here. Uh and then a user will only see one plan. However, I'm kind of hacking my way through things and just in like a testing environment. Um, so yeah, here are all the different subscriptions here and we can see that next due is um on this date. We've got our taxes. We can cancel um we can update our payment method and so on. Um and that is the endtoend pipeline um of payments and that's all ready to go in pieces OS. There's a couple uh additional things, various edge cases, but Tsavo Knott: Awesome. Mark Widman: yeah, there we go. Huge huge shout out to uh Hero and Brian who's not on the call that did uh a lot of the heavy lifting there. 00:08:29 Mark Widman: Uh and it made it easy on my side to just hook up the pipes. We're good to go. Tsavo Knott: It's going to be good. I think uh we'll be able to vibe code that checkout page, the styles and stuff pretty quick. Probably five minutes. Uh but I think it's going to be great. And then yeah, I think by probably late next week, we'll start to see what this stuff looks like inside the desktop app. So the payw wall experience around the models, clicking the button, um going through the checkout flow, the whole nine yards. But yeah, getting that thing super concrete at the database level and the OS server level is kind of goal number one there. Yeah, sweet. Good stuff, Mark. Any questions from the team on that? I know it's a little bit technical because we're looking at the backend side, but um pretty great. Pretty great there.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "great. And then yeah, I think by probably late next week, we'll start to see what this stuff looks like inside the desktop app. So the payw wall experience around the models, clicking the button, um going through the checkout flow, the whole nine yards. But yeah, getting that thing super concrete at the database level and the OS server level is kind of goal number one there. Yeah, sweet. Good stuff, Mark. Any questions from the team on that? I know it's a little bit technical because we're looking at the backend side, but um pretty great. Pretty great there.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Antreas Antoniou: I like the colors. Sam Jones: Um, are we going to are we going to be launching this with with with a sort of specific played plan? 00:09:27 Sam Jones: So alongside like Cloud4 support with is that the idea Tsavo Knott: That's right. It's just going to be, you know, kind of like the early, you know, uh pieces pro, right? Pieces pro plan. And the only thing it's going to like basically gate is the clawed model inside the desktop app. Um so yeah, we'll probably roll out uh yeah, especially because our our enthropic quotas are pretty crazy. Um you know, and and we get rate limited a lot and whatnot. So I think if you want to use enthropic inside of pieces, um yeah, you'll you'll have to upgrade. Sweet. Um cool. Yeah. Mark, anything else to add there? Mark Widman: Um, that is pretty much it. Uh, there's only a couple uh final things and then it should be ready to go for testing. Um, basically just layering in some of those payw walls. So, for instance, not allowing a unauthenticated user to use Quad and then you have to have the proper plans and all that fun stuff. 00:10:28 Mark Widman: Um, a couple little edge cases with whether users cancelled or their plan expires or they update Tsavo Knott: Yeah. Mark Widman: a plan and it's all funky. And then also too another important thing is that hey if a malicious user tries to sign in and then sign Antreas Antoniou: Sorry. Mark Widman: out or uh sign in and then uh basically what they could potentially do is Tsavo Knott: Heat. Antreas Antoniou: Sorry. Mark Widman: uh like disconnect from the network or connect to their own network where they limit pieces from making these like refresh. we have like what's called a last checked in or a last refreshed of that specific user where that user needs to go ahead and and check in in a 72-hour period or you know we could change that of course um or else what we have to do is we do not let them use any of the paid features uh via a payw wall. Uh Tsavo Knott: Yeah. Mark Widman: that's another little detail, a ton of little uh details just kind of like sprinkled throughout the whole flow to make sure that like a malicious user can't come in and use these paid features and all that sort of stuff. 00:11:34 Mark Widman: But it'll be a really good um kind of MVP uh at least for Cloud 4 to make sure all the pipe pipes are good to go, everything's looking great. Um Tsavo Knott: Yeah. Mark Widman: that's like the risk the the risks are very low um with like hey if if some of these pipes fail or if something fails in the pipeline no worries um low risk here so that we can get this V1 rolled out. Tsavo Knott: Yep. Mark Widman: That way Tsavo Knott: Awesome.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "and use these paid features and all that sort of stuff. 00:11:34 Mark Widman: But it'll be a really good um kind of MVP uh at least for Cloud 4 to make sure all the pipe pipes are good to go, everything's looking great. Um Tsavo Knott: Yeah. Mark Widman: that's like the risk the the risks are very low um with like hey if if some of these pipes fail or if something fails in the pipeline no worries um low risk here so that we can get this V1 rolled out. Tsavo Knott: Yep. Mark Widman: That way Tsavo Knott: Awesome.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 13
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Mark Widman: when we do start to layer in more and more and more on top of this infrastructure we have full confidence that everything is good to go. Tsavo Knott: Love it. Um, yeah, I think it's going to be great. We'll also layer that in at the the endpoint level too, you know, in the interceptor for the Cloud 4 stuff. But yeah, I think it's going to be awesome. Uh, sweet. Thanks, Mark. Well, uh, we got some more demos. I know Nolan, you got a big one. 00:12:26 Tsavo Knott: Like a really big one. I know, uh, Sam, you got a big one. I know Bashroyy's got a big Sam Parks: I Tsavo Knott: Who wants to go? Sam Parks: I can go Tsavo Knott: All right. Sam Parks: we can go from back end more to front end stuff. Um so pretty much what I've been working on is kind of revamping our um um markdown experience. So wait, close your eyes because I don't want to show this off yet. Okay. So, the way I'm going to illustrate what I've been doing is by just asking um pieces uh a couple of questions in our co-pilot chat. Um kind of incorporating some long-term memory context. So, first question is, could you generate a table format with all the people I worked with last week and what I worked on with them? Um, so I'm going to send the chat and then so this is like the the current version of markdown. So the new version and then I'll I'll quickly switch over to the other view so you guys don't see um so you'll see the old and then you'll see the new. 00:13:31 Sam Parks: Uh the reason I'm doing that is for some reason the production version of pieces isn't working for me locally but that's okay. Um, so I'll send this chat and it will um load in once the markdown is rendered. So let's give it just a sec. And so what you'll see here is what you would currently see in the production app um of pieces. Tsavo Knott: that you have two instances of pieces desktop running. Is that right? Sam Parks: Yeah. Yeah. Exactly. So this is the production version, right? Um, and so you see here, okay, you know, I wanted a table to like compare and be able to like actually understand, you know, who I worked with. And so you can, I mean, this is a bit kind of hard to parse and it's not really doing a great job of giving me an understanding. So now we can see what our new markdown rendering version can do. it it actually understands what a markdown table is and gives the user um a much easier thing to work with and understand. 00:14:33 Sam Parks: Um yeah, so that that's one one example. So now we have tables. Um and this is just one new component that we'll um be able to work with.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 14
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "know, who I worked with. And so you can, I mean, this is a bit kind of hard to parse and it's not really doing a great job of giving me an understanding. So now we can see what our new markdown rendering version can do. it it actually understands what a markdown table is and gives the user um a much easier thing to work with and understand. 00:14:33 Sam Parks: Um yeah, so that that's one one example. So now we have tables. Um and this is just one new component that we'll um be able to work with.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 15
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um so I'll do the next thing. So let's do list of people. Okay. So now my next question is is can you generate a bulleted list of people I worked with last week. And so this this looks pretty similar to what we currently have now. Um, but the interesting part is when you try and copy um and paste what you've worked on. So before if you tried to copy and paste um you would have known that Tsavo Knott: Well, yes. Sam, Sam Parks: you Tsavo Knott: sorry Sam Parks: want Tsavo Knott: to Sam Parks: me Tsavo Knott: interrupt. Sam Parks: to show Tsavo Knott: Yeah, Sam Parks: Yeah. Tsavo Knott: show the Sam Parks: Yeah. Go ahead. Tsavo Knott: version. Sam Parks: Yeah, Tsavo Knott: Yeah. Sam Parks: I'll show the old Tsavo Knott: Yeah. Sam Parks: Yeah, Tsavo Knott: Yeah. Sam Parks: that's all right. 00:15:37 Sam Parks: Cool. All right. So, if I copy everything in here and then I go to my notes and then I paste it in. Well, here, let me do a new because sometimes it gets kind of confused. You can see it's all just kind of together. It Tsavo Knott: Yeah. Sam Parks: doesn't retain any of the richness of the markdown that you're actually being that that's being displayed. So, now I'll go to the new version. So now Tsavo Knott: Absolutely. Sam Parks: we can copy and paste and it retains all of the formatting and all the bullet points and all the boldness and everything. So that's that was I know it looks very simple but this was this was probably the hardest part of of uh of this project for sure. So yeah, I'm pretty proud of that. Tsavo Knott: I mean it's a fundamental right like selecting copying and pasting whatever else. I think like if we think about our northstar on the product side of queries per user per day, like our jobs now are copying and pasting all day long, right? 00:16:36 Tsavo Knott: I want to take this summary, I want to copy and paste it right over to Ghat, easy money, right? And so, um, I think copying as, you know, markdown, copying as rich text, like these are fundamentals that just make the usability, you know, go up so dramatically, right? Um, and I'm I'm personally extremely pumped about this. Yeah. Antreas Antoniou: Yeah. I Sam Parks: And Antreas Antoniou: mean, some Sam Parks: then Antreas Antoniou: of the some Sam Parks: yeah, Antreas Antoniou: of the bigger providers like can't do that. Tsavo Knott: Yeah, I know. Yeah, exactly. They uh they also struggle with this. Sam Parks: then I Antreas Antoniou: So, Sam Parks: had Antreas Antoniou: it must be hard. Tsavo Knott: In your Sam Parks: Well, Tsavo Knott: second, Sam Parks: well, you Tsavo Knott: you'll want to control Z probably. Sam Parks: Oh, yeah. Yeah, Tsavo Knott: Yeah, I gotcha. Sam Parks: this Nathan Courtney: Okay. Sam Parks: one. Tsavo Knott: Yep.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 16
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Parks: And Antreas Antoniou: mean, some Sam Parks: then Antreas Antoniou: of the some Sam Parks: yeah, Antreas Antoniou: of the bigger providers like can't do that. Tsavo Knott: Yeah, I know. Yeah, exactly. They uh they also struggle with this. Sam Parks: then I Antreas Antoniou: So, Sam Parks: had Antreas Antoniou: it must be hard. Tsavo Knott: In your Sam Parks: Well, Tsavo Knott: second, Sam Parks: well, you Tsavo Knott: you'll want to control Z probably. Sam Parks: Oh, yeah. Yeah, Tsavo Knott: Yeah, I gotcha. Sam Parks: this Nathan Courtney: Okay. Sam Parks: one. Tsavo Knott: Yep.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 17
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Nathan Courtney: Okay. Sam Parks: Uh, it's okay. I mean, honestly, that those are the two bigger ones. 00:17:18 Sam Parks: I also have here I could just I could just come up with something to illustrate the last one work. So, let's see. So this is this should just illustrate just another example of custom components that we can use that will just provide the user a better experience um and highlights our our um long-term memory. Uh so like I'm using all the the information that I used last week and I can you can imagine this being pretty useful for a user. Obviously there's some formatting stuff but like I can actually interact with these you know um so yeah Tsavo Knott: in Sam Parks: and Tsavo Knott: the Sam Parks: in the current uh it's just yeah Tsavo Knott: Yeah. Yeah. Not ideal. Uh we are almost to the finish line on this. Sam, I know doing this on Mac OS, Linux, and Windows is difficult. Um I know we are not doing anything with image generation yet but I know it also supports image copying, video copying like whole bunch Sam Parks: Yeah. Tsavo Knott: of stuff uh which 00:18:41 Sam Parks: Yeah. Tsavo Knott: is tremendous. Yeah. Sam Parks: Yeah. So from a design perspective, you know, we have we have full creative uh freedom here. Like we can do we can like I know CHBT like they're they have kind of more custom markdown renderings as well. So like I'm assuming they're you know embedding certain patterns in their markdown that their um renderer understands and we can do very similar things to like highlight you know, stuff with long-term memory or just, you know, working with AIS in general. So, it's it's a great I think new feature to have. Yeah. Tsavo Knott: tremendous. Mack Myers: I'll Tsavo Knott: Um, Mack Myers: ask Tsavo Knott: yeah. Mack Myers: just one last thing to add is this update for all those who have been asking this update will also help pave the way for being able to edit a workstream summary. Tsavo Knott: Yep. Mack Myers: So very quickly we'll be able to turn around and hopefully for that 12.0.0 release. Uh users will be able to update those workstream summaries but not necessarily have to update it with the markdown syntax but they can update it as rich text. 00:19:42 Mack Myers: So they can highlight text, bold it and so on. Uh, and it will maintain the integrity of all that raw markdown Sam Parks: Yeah. Mack Myers: under the Sam Parks: Add images, you know, all that stuff. Tsavo Knott: Yep. Yeah, it'll be pretty cool in our workstream summaries like uh so there's two things. Number one is we are working on an endpoint to take a co-pilot response and save it as a workstream summary.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 18
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Myers: So they can highlight text, bold it and so on. Uh, and it will maintain the integrity of all that raw markdown Sam Parks: Yeah. Mack Myers: under the Sam Parks: Add images, you know, all that stuff. Tsavo Knott: Yep. Yeah, it'll be pretty cool in our workstream summaries like uh so there's two things. Number one is we are working on an endpoint to take a co-pilot response and save it as a workstream summary.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 19
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "kind of like how you can save a code snippet, but you can imagine there, you know, I save a checklist as a workstream summary, right? And then I have all my workstream summaries. I could just filter by outstanding to-do items, right? And that's just like all on the UI side, you know, things that are not completed in the checklist markdown. Uh I know we have that next steps and action items and to-do stuff down at the bottom of our summaries. That's another great location for interactive checkboxes. And the clever thing about this is that the state of the checklist is actually preserved in markdown, right? 00:20:37 Tsavo Knott: As opposed to a net new data object in the database, right? So it's almost two birds, one stone there uh for us. So pretty pretty cool stuff. Sam, do you have any of the summary stuff to show um on the selection and Sam Parks: I Tsavo Knott: whatnot? Sam Parks: yeah I mean I have it it's very similar to co-pilot right now. I mean so I can just show how it looks and stuff like that. So you can see here this is the new version. Um we retaining all of the styling. Um and yeah so it it kind of interacts the same the same way. So I can retain, copy and and paste the the same rich text. And um there's still um a couple small things we need to handle like um you can see we've lost the ability to copy like the little copy icon next to a link and stuff like that, but that's those are small things. So yeah, this is this is the new markdown as well in in the workstream summaries. 00:21:36 Sam Parks: Yeah. Tsavo Knott: gonna be awesome. Yeah, super Sam Parks: Yeah. Tsavo Knott: super excited. And and I know that there is a world-class editing experience behind this as well. Uh it's going to be tremendous. Sam Parks: Yeah, Tsavo Knott: So yeah. Yeah. Editing the markdown directly, editing it as rich text, you know, um whole nine yards. It's going to be cool. So yeah, great stuff, Sam. Awesome. Awesome work there. Sam Parks: of course. Tsavo Knott: All right, who's who's up on deck? Nolan Taft: I can uh I can do it now. Tsavo Knott: All right, Nolan. Nolan Taft: So, uh let me figure out what screen I'm on. One second. It's not able to find my browser. Just entire screen. All right. Can you guys see? Tsavo Knott: Yes, sir. Nolan Taft: All right. So, we've been building um basically an entire documentation website since neither of the um really none of the sources that we were looking at had what we wanted. 00:22:37 Nolan Taft: Um so, this would be the landing page. Tsavo Knott: super fast. Give a little context as to why we had to do this.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 20
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "I'm on. One second. It's not able to find my browser. Just entire screen. All right. Can you guys see? Tsavo Knott: Yes, sir. Nolan Taft: All right. So, we've been building um basically an entire documentation website since neither of the um really none of the sources that we were looking at had what we wanted. 00:22:37 Nolan Taft: Um so, this would be the landing page. Tsavo Knott: super fast. Give a little context as to why we had to do this.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 21
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Nolan Taft: Um so, Mintify they they had kind of more complex Tsavo Knott: Well, Nolan Taft: uh navigation structure. Tsavo Knott: even further back with Hashnode. Yeah, that's what Nolan Taft: Oh, Tsavo Knott: I Yeah. Nolan Taft: yeah. Okay. Tsavo Knott: Yeah. Nolan Taft: So, uh, Hashnot's sun setting. So, they're shutting down in three months. So, they're stopping, um, they're no longer building onto the platform. So, we lost like analytics and we're losing a ton of features day by day. So, Tsavo Knott: Yeah. Nolan Taft: it's very quickly we have to transfer over to a new platform. Um, and that's what we built this up to be. So, if we actually go to read the docs, it has this nice landing page that we were never allowed to have in Hash Node. But if we go to like a documentation, we'll go down to uh let's just check out sub not jupitter lab sublime. 00:23:28 Nolan Taft: It is almost the exact same style of hash node, but it allows us to really take full control of really what we want the editor or the the docs view to look like. Still a work in progress. So there are a lot of things that like stylistically that need to be updated. Um but I'm really happy with how far it's come. And one of the best things that we've been able to build is um first I have to authenticate. So we have authentication through GitHub. Um and then once I authenticate it'll shoot me back to the main page, but I can go to slashedit and that didn't work uh edit and it takes me into a uh built-in editor that works within the browser. So from here I've been I've been really trying to make it like user friendly, but it's like you you fix one thing, it breaks 10 others. Um, but right now I have navigation working. So in here you're able to reorganize the navigation entirely. You're able to go through and change uh nav titles. 00:24:24 Nolan Taft: So if I just add title to this and then shoot back to the um the doc real quick, it should say doc or core dependencies title. Um and it updates in real time with a superbase uh database. So fix that real quick. Same thing works with uh n reorganization. So, I can drag and drop it at any stage and reorganize. And I can rename any page and it'll update within the uh database as well. If we go to content editor, this has probably been the biggest overhaul and it still needs a lot of work, but we've gotten it to a pretty nice state right now. Um, so I can go through and, you know, click any of the files that I want to edit. It shows me markdown on the left side and then it shows me um the rendered preview on the right side. I can go to full preview.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 22
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "stage and reorganize. And I can rename any page and it'll update within the uh database as well. If we go to content editor, this has probably been the biggest overhaul and it still needs a lot of work, but we've gotten it to a pretty nice state right now. Um, so I can go through and, you know, click any of the files that I want to edit. It shows me markdown on the left side and then it shows me um the rendered preview on the right side. I can go to full preview.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 23
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "I can go to full edit or I go to w y ssiwg. Tsavo Knott: way. Nolan Taft: Um, Tsavo Knott: Yeah. 00:25:14 Nolan Taft: and this is a a work in progress. I kind of just uh got this out last night and haven't been able to work on it too much, but it will enable us to be able to click on a section that we want to edit and uh edit it in line. I just have to work on the compilation of it. One of the greatest features though is that I can click this plus and it will quickly add uh any section that I need down there. It's kind of how we had fragments within uh Hashnote. Um, and then I'm able to create PR, which will create a new branch on GitHub where our documentation is stored and uh create a PR to try and merge it into the current documentation. So, that's working great. And then this one's more for like Hannah because we need a lot of SEO and Hashnode really did not give us any SEO. So, I was able to get uh basically every SEO option you would you would want set up. Um, so we have like our basic SEO page. 00:26:05 Nolan Taft: We could do page title. We have our social page which has a ton of options. Um, we have our technical page that'll handle like SEI and everything like that. Um, she's also able to go through and do custom JSON and uh just schema.org. And then we also have some advanced meta tags. Um, and this also goes through so like if I just make whatever and create a PR. Um, I do have an issue with it kind of erasing the other front matter. So, I have to fix that real quick, but you'll see when we go over creates a nice summary of what's happened. And then if we go to files changed, you also kind of see that it automatically adds in some defaults there. Um, I have not updated the Twitter site, but yeah, that's how that works. And then the really the final thing is the uh the admin page and let's just go into here, install the pieces documentation bot that I set up. Um, and that'll that's what's making the PRs and reading from the um from the GitHub in the first place. 00:27:02 Nolan Taft: Um, so it'll only read what you give it access to. And then you can go through your repositories that it's linked to and select which repository you actually want to use. One of the biggest issues we had with HashNote is it wouldn't update in real time sometimes. So I just went ahead and added a custom sync button. Um, we have user management in here as well. So if I wanted to get rid of my other account for being an admin, go ahead and do that.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 24
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Taft: Um, so it'll only read what you give it access to. And then you can go through your repositories that it's linked to and select which repository you actually want to use. One of the biggest issues we had with HashNote is it wouldn't update in real time sometimes. So I just went ahead and added a custom sync button. Um, we have user management in here as well. So if I wanted to get rid of my other account for being an admin, go ahead and do that.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 25
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um, and then we have access codes, which basically authorizes somebody to um, sign up as an editor. So, if somebody signs up right now using the GitHub login, there's really no way I can block them from signing up, but they don't get any roles. So, they won't be able to access editor or admin. Um, and so the only way that they can get that is either going back to O and authenticating with a an access code or signing up off the get-go with an access code. It'll automatically give them editor. 00:27:54 Nolan Taft: And Tsavo Knott: Yeah, Nolan Taft: so yeah. Tsavo Knott: that access code also expires. But uh Nolan, simple Nolan Taft: Yeah. Tsavo Knott: uh simple one for you. You should just um password protect the login page. So Nolan Taft: Yeah, Tsavo Knott: yeah. Nolan Taft: that's kind of what I have. Let me sign out real quick. Similar to what I have. I just uh kind of for the sign up to be able to come in editor, you have to enter the access code. So I should just get rid of the sign in. But yeah. Tsavo Knott: Yeah. Or you just password protect this whole page where before you even get to these options, you have to have the like a key, right? Like an Nolan Taft: Yeah. Tsavo Knott: API key basically. Yeah. Nolan Taft: Yeah, Tsavo Knott: That'll Nolan Taft: that would Tsavo Knott: be Nolan Taft: make sense. Tsavo Knott: another another Nolan Taft: Yeah. Tsavo Knott: layer of uh of protection there. Yeah. Nolan Taft: Okay. Okay. 00:28:33 Nolan Taft: Yeah. Yeah. Tsavo Knott: But Nolan Taft: But yeah, Tsavo Knott: uh yeah, Nolan Taft: that's Tsavo Knott: I mean Nolan, do you want to speak a little bit towards uh since last Thursday when we had our kumbaya uh and saying like we're gonna abort, you know, mint lefy and and the sprint on that? Um I you guys built this in five days. I know you guys were working over the weekend or whatnot, but um do you want to just speak a little bit towards the journey of like you know checking out the other documentation platforms, checking out uh the tools you were you were looking on at on this and then you know the the huddle up that we had Nolan Taft: Yeah, I mean for the past few days there's been a lot of R&D to kind of see how those those platforms handle uh markdown generation. Uh I think with Mintify they really just went with like a pre-ompiled or a pre-built compiler and then just added some custom features to it. We went uh entirely custom compiler but we also use uh like react markdown and everything. 00:29:24 Nolan Taft: Um and that allows us to use those custom components that we need.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 26
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "few days there's been a lot of R&D to kind of see how those those platforms handle uh markdown generation. Uh I think with Mintify they really just went with like a pre-ompiled or a pre-built compiler and then just added some custom features to it. We went uh entirely custom compiler but we also use uh like react markdown and everything. 00:29:24 Nolan Taft: Um and that allows us to use those custom components that we need.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 27
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh and then I know HashNote had their entirely custom compiler but that one it ran into a lot of issues which is why we chose to go with some pre-ompiled and then some. Um and then yeah it's just been a lot of uh working on the compiler. The authentication hasn't been bad. Um and then uh kind of transferring over from hash node and mintify we found that uh building your own platform kind of gives you a lot more customiz I mean obviously it gives you a lot more customization and it's it's coming out to be exactly what we wanted has some has some more work ahead of it but it really is being thrown together to be exactly what we've been we've been needing for a documentation site. Tsavo Knott: Yeah, it's it's tremendous. And uh you know your guys journey went from like you know a super no code type documentation experience with hash node then hash node said hey by the way this docs platform that we released two months ago uh and had you guys be an early adopter on we're now suns setting it. 00:30:28 Tsavo Knott: So that you know put us on a scramble mode. Um, Nolan Taft: Yeah. Tsavo Knott: then you guys went down the path of like looking at Mintify, Docsaurus, like all the other different platforms. Then, you know, we kind of had to huddle up and we were like, well, we're getting we just can't get what we want. So, we said, hey, want you guys to take two, three hours and try and rebuild uh a shell in lovable and using cloud code uh the CLI um as well. So, and of course all this stuff through GitHub, you know, fully synced, whatever. And Nolan, I mean, I know you and Judson, you know, mostly do like low code stuff, but you went from a low code to a high code environment in a matter of days, right? And built this entire system like off, you know, dashboards, editing, rendering, styling, the whole system, thinking about every single component. Um, and then on top of that, you know, the rendering performance of the site because every page is pre-ompiled and and statically built. 00:31:21 Tsavo Knott: Uh, it's blazing fast. So, I don't know if you want to share the preview link for folks, but it is ridiculously fast. Um, and it's excellent for SEO. Yeah, Nolan Taft: Yeah, Tsavo Knott: they did. Nolan Taft: I can share it. Tsavo Knott: Yeah, they Nolan Taft: It Tsavo Knott: did build. Nolan Taft: definitely uh I'm sorry. It's a It's definitely a little rougher on the edges, so bear with us. But it's uh there's the demo link. Tsavo Knott: There you go. Read the docs. Nice little ghost loader icon, too, like on your sidenav. Like I mean the the details here are looking pretty darn great.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 28
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "excellent for SEO. Yeah, Nolan Taft: Yeah, Tsavo Knott: they did. Nolan Taft: I can share it. Tsavo Knott: Yeah, they Nolan Taft: It Tsavo Knott: did build. Nolan Taft: definitely uh I'm sorry. It's a It's definitely a little rougher on the edges, so bear with us. But it's uh there's the demo link. Tsavo Knott: There you go. Read the docs. Nice little ghost loader icon, too, like on your sidenav. Like I mean the the details here are looking pretty darn great.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 29
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um but yeah, I think the polish will happen pretty nice and I think give it another week, you know, past your first five days of actually trying to do this. Uh you guys are coming up to speed quick. So very good. Any questions on some of this stuff across the company? I mean, what what do y'all think? Antreas Antoniou: Ah, crispy. 00:32:15 Tsavo Knott: Krispy Antreas Antoniou: Looks Sam Jones: Super impressive. Yeah. Tsavo Knott: s impressive. You guys just went to 10x engineering uh overnight and basically rebuilt hash nodes proprietary platform. Uh so congrats, good job. And just super impressed in your guys's, you know, versatility in like saying like, hey, we can't get this done with lovable. Let's clone the repo. Let's throw cloud code at it, fix a problem, push it up, sync it with GitHub, you know, and then back to lovable, right? So I think really really awesome stuff there. Um well, Mack Myers: Do you Tsavo Knott: great. Mack Myers: guys Tsavo Knott: Oh yeah. Mack Myers: the the repo that it's associated with? Nolan Taft: Yeah, I'll send it to you over DM. Mack Myers: Nice. Tsavo Knott: Yep. Mack Myers: Thank you. Antreas Antoniou: Uh also small comments I think we're missing cursor from the ids but Yeah. Tsavo Knott: Yeah, we we'll get the whole thing migrated over. Uh the launch date target for this is probably like a week after the 12.0 release. 00:33:10 Tsavo Knott: So roughly 10 to 20 days from now um max. But yeah, five days, a lot of progress. You got the the base in and now it's like polishing which would be great. Mack Myers: Good stuff, Antreas Antoniou: Is it Mack Myers: guys. Tsavo Knott: All right, Bishoy, I know you've got a whole bunch of stuff too. Uh you've basically, you know, uh vibe coded but not not no vibes at all, but basically refactor the entire CLI, beautiful UI, everything like that coming up. I would love for you to share some of this stuff with folks and you are running at lightning speed. Bishoy Hany: All right. So let's begin. So uh first I changed most of the help command. All the help command will have docs for it. Every help command and some examples like create you have some examples. Uh that's one thing. Second thing is MCP stuff. So we have a we get here MCP help for it. So let's begin by setting up MCP for clone maybe. 00:34:22 Bishoy Hany: So pieces MCP setup. Oh yeah. This is MCP setup. Okay. Uh, close desktop. Let me hide this. So, it asks you to open your LTM. Now, permissions. Oh, I missed the permission. Tsavo Knott: Yep. Just four finger swipe up and you'll find it again. Bishoy Hany: Let me do it again. So, yes, you get the accessibility. It's Tsavo Knott: Love Bishoy Hany: config. Tsavo Knott: the loading indicators. It's just nice. Bishoy Hany: Uh I'm okay. So quit pieces is restoring.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 30
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "get here MCP help for it. So let's begin by setting up MCP for clone maybe. 00:34:22 Bishoy Hany: So pieces MCP setup. Oh yeah. This is MCP setup. Okay. Uh, close desktop. Let me hide this. So, it asks you to open your LTM. Now, permissions. Oh, I missed the permission. Tsavo Knott: Yep. Just four finger swipe up and you'll find it again. Bishoy Hany: Let me do it again. So, yes, you get the accessibility. It's Tsavo Knott: Love Bishoy Hany: config. Tsavo Knott: the loading indicators. It's just nice. Bishoy Hany: Uh I'm okay. So quit pieces is restoring.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 31
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: All permissions enabled. Bishoy Hany: And yeah, we can just open CL Tsavo Knott: Sure has. Yeah, Vishroy's been cooking. Bishoy Hany: what I was working on yesterday maybe. Yeah, I think because I'm on free planet will tell me that I ran out of token, but yeah, it did the work already. Yeah, I know. I hit already the maximum lens, but anyways, it did the work. We can try something else. Maybe MCP setup for Yeah, maybe surf. 00:36:16 Bishoy Hany: That one was new. I just added it. Yeah, here it added the config. I can do S stdio as well. Wind surf. Tsavo Knott: Nice. You replaced your HTTPS Bishoy Hany: Yeah. Tsavo Knott: config. MCP server is available. There we go. Two tools. Sam Parks: This is sick. Tsavo Knott: Yep. Looking good. Maybe give it a more specific uh query too if you want. Bishoy Hany: Yeah, we Tsavo Knott: Vure. Bishoy Hany: can do that. And yeah, here we go. Tsavo Knott: Nice. Awesome. Awesome. Awesome stuff. Fishoy. Yeah, good stuff there, my guy. I mean, I know you've also kind of refactored. I know you're blasting through that, but uh basically like the drop downs, the up down arrows, the loading indicators, the feedback loops, launching permissions, everything like that. I mean, you've covered a lot of the cases there. Um, did we lose Bashoy? I'm not sure. Oh, there he's back. 00:37:46 Tsavo Knott: Nice. Good work. Really good work. That's all all we wanted to say. Bishoy Hany: Thank Tsavo Knott: Uh, Bishoy Hany: you. Tsavo Knott: but yeah, great great stuff there. And, uh, Bashroy, definitely hit me up so we can get you a Claude Pro plan uh, to make sure you're set there. Yeah, it'll it'll be it'll make for much better demos. Cool. Bishoy Hany: Okay. Tsavo Knott: Um, yeah. So, that's that's the that's kind of like the gambit on the demo side of things. Um, you know, let's just kind of get into Well, am I missing any other demos? I know we just did a open call for demos across the company. Um, but anything else demo-wise? Rutvik Tak: Yeah, I mean like uh there's few things on mind like those things like mostly research based related to rendering like very technical Tsavo Knott: Let's see it. Let's Rutvik Tak: but Tsavo Knott: see it. Rutvik Tak: uh yeah I can share that. Yeah. Tsavo Knott: Hell yeah. Ruffic 00:38:40 Rutvik Tak: All right. Can you guys see my screen? Antreas Antoniou: Yes. Rutvik Tak: All right. Most of this stuff is like very technical. So just like let me know like if I'm throwing lot of technical jargon at you guys. All right. So, uh some of the work that I've been doing this past days is mostly like evaluating the uh performance improvements and areas that we can explore within the app to kind of improve the performance of the desktop app or other flutter apps that uh we have.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 32
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "can share that. Yeah. Tsavo Knott: Hell yeah. Ruffic 00:38:40 Rutvik Tak: All right. Can you guys see my screen? Antreas Antoniou: Yes. Rutvik Tak: All right. Most of this stuff is like very technical. So just like let me know like if I'm throwing lot of technical jargon at you guys. All right. So, uh some of the work that I've been doing this past days is mostly like evaluating the uh performance improvements and areas that we can explore within the app to kind of improve the performance of the desktop app or other flutter apps that uh we have.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 33
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um mostly this is a problem on lower-end machines like uh so I got the desktop app running right now. It's a profile build of the desktop act, not the release one, but it kind of matches the what the performance we can expect in a release. And and on top here, I just got this like uh two pipelines, basically a UI pipeline that tells us how performant each frame of the application is being rendered. Usually, this is something that we want to render each frame under like 16 milliseconds. 00:39:39 Rutvik Tak: if it goes anything above that it's uh kind of uh you might experience a jank in the UI like where it freezes for a millisecond or two. So right now as you can see I'm running the desktop application on like an Apple M2 like M2 chip with 24 gigs of RAM but uh still I'm getting a lot of uh like this jank uh what you would call uh if I'm going through a Tsavo Knott: drop Rutvik Tak: chat Tsavo Knott: frames. Rutvik Tak: with lots Tsavo Knott: Yeah. Rutvik Tak: of content. Yeah. Tsavo Knott: Yep. Rutvik Tak: So, and this is on M2. So, you would expect a bigger difference on the lower-end machines like M1 or people with even a lower-end hardware. So, this is an area that we want to tackle like as we move forward with you know uh showing lots of uh content within a particular view within charts like rendering different types of content. Tsavo Knott: Yep. Rutvik Tak: So, I've been just trying to explore few ways we could like reduce this performance gap and improving those areas. 00:40:36 Rutvik Tak: So I got another example app running here that kind of explores some of those areas. So first example is basically a list. Um now this also explores some reward stuff but uh I'm not going to go in there because uh we could achieve the same thing without rear port. But yeah, so this is like a normal list you would get in an application like we have certain components, they have certain parts of it and right now this is like the uh regular like this comes down to a lot of flutter stuff now. So uh people who might not be familiar with flutter this might be a bit uh overwhelming but Tsavo Knott: So Rutvik Tak: uh Tsavo Knott: Vic real fast. Basically the colors that change represent Rutvik Tak: Right. Tsavo Knott: the elements in this view. And when you mutate one of the elements, like you check a checkbox, if a lot of colors change, that means that you have low performance, right? You're rerendering too many things. So Rutvik Tak: Exactly. Tsavo Knott: that's that's what I I want to make sure everyone kind of understands here. 00:41:36 Tsavo Knott: Yeah. Rutvik Tak: Right. Yeah.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 34
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Knott: Vic real fast. Basically the colors that change represent Rutvik Tak: Right. Tsavo Knott: the elements in this view. And when you mutate one of the elements, like you check a checkbox, if a lot of colors change, that means that you have low performance, right? You're rerendering too many things. So Rutvik Tak: Exactly. Tsavo Knott: that's that's what I I want to make sure everyone kind of understands here. 00:41:36 Tsavo Knott: Yeah. Rutvik Tak: Right. Yeah.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 35
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So, usually uh if we are trying to be performant, we shouldn't be like rerendering everything uh when a certain part of the UI changes. Like right now here the only thing that is changing is the checkbox but everything else is changing it colors that means everything else is rebuilding itself. So any business logic in that widget also gets executed and Tsavo Knott: Mhm. Rutvik Tak: that usually impacts the performance as well like if that uh logic is expensive to compute. So Tsavo Knott: Yep. Rutvik Tak: this is with a regular list view but uh if we change a few things in uh in here like let's say instead of uh just using a list view builder if we replace a few things with uh Tsavo Knott: the new system. Yep. Rutvik Tak: yeah so there's couple of things going on in here now as you can see each of the check boxes or the status uh this uh labels they also have this uh boundaries around them. So that means they will uh render like their uh basically their paint cycle is uh separated from rest of the widget. 00:42:41 Rutvik Tak: And uh one thing we are also doing is the state of this particular items is now being managed individually uh by this notifiers. So each item is connected with a particular notifier that controls the state. So we don't affect the entire state of the list items in rerendering everything. So if I now change the uh text box as you can see like only this particular item changes it colors like the text box and the list. We don't rerender everything uh in the list view. So yeah, I mean this is something that might be helpful uh in a copilot chart where code syntax highlighting is something very expensive to compute and we don't want to do that uh if even a small little thing in the UI changes like as you can see in this demo like most of the drop in frames is coming from the syntax highlighted code which Tsavo Knott: Yep. Rutvik Tak: we compute every time the widget results. Sam Parks: rough. Not to steal your thunder, but I actually fixed that in in the in the upgrade. 00:43:45 Sam Parks: So, we're not running the highlighter on every build, but it's still good to call out for sure. Tsavo Knott: Yeah. Rutvik Tak: Right. Tsavo Knott: And Rutvik Tak: Yeah. Tsavo Knott: and granted like this is a list view, right? So if you think about the list items, right? How much is rerendering in just a list? It's tons Rutvik Tak: Yes. Tsavo Knott: of of of drop frames and Sam Parks: Mhm. Tsavo Knott: then 60 fps performance, right? So, you know, across the board, um, this is very important. This is a big push that that we're working on to make the entire product significantly faster. This also matters even more in in Flutter web apps, right?",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 36
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Right. Tsavo Knott: And Rutvik Tak: Yeah. Tsavo Knott: and granted like this is a list view, right? So if you think about the list items, right? How much is rerendering in just a list? It's tons Rutvik Tak: Yes. Tsavo Knott: of of of drop frames and Sam Parks: Mhm. Tsavo Knott: then 60 fps performance, right? So, you know, across the board, um, this is very important. This is a big push that that we're working on to make the entire product significantly faster. This also matters even more in in Flutter web apps, right?",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 37
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So, all of our plugins, all of our popovers, everything like that, this actually is a lot more apparent uh, believe it or not. Rutvik Tak: Yeah. And like it's not only the code syntax highlighting that is contributing to the jank as you can see there can be other parts of the UI as well. So this kind of like granular rdering of uh widgets or the parts of the UI is going to help us there as well. 00:44:42 Tsavo Knott: Yep. Rutvik Tak: Now yeah so that was about uh that is one part of the problem and so I got another part here so this is basically uh uh one sec I'll just have to comment out some stuff all right so this is just another examples a list with a few items in it and usually Usually a normal operation in a list is that we add items to it. Oh, wait. There might be something I Tsavo Knott: Yeah. Rutvik Tak: might have to do. Yeah. Not that. All right. Uh, this is what I wanted to show. This is for the letter Tsavo Knott: Heat. Rutvik Tak: All right. So, usually like when you're adding items to the list, uh normally the flutterity is basically like rebuilding everything within the list. And this is not going to be performed when we have like hundreds of items in the list view being shown in the on the screen. We don't want to like rerender everything and recomputee everything that uh item did before. 00:46:07 Rutvik Tak: So it's an easy problem to solve. It's basically uh we track the rebuilds of each individual widgets uh with a separate uh like a state controller you would say. So if I like uh for a second comment this out. This is more like the performant uh rebuild and uh say So instead of like rebuilding everything uh now this uh list item builder it basically listens to a particular state controller of that item and we don't have to rerender everything that whenever we add a new item to the list like as you can see only the item that are being shifted down and the item that is being added rebuilds but everything beside that uh particular remains consistent. Yeah. Tsavo Knott: Yep. Awesome. And you can see your hover effects, too. When you hover over things, it it only affects those items as opposed to the entire list as well, which is Rutvik Tak: Right. Tsavo Knott: excellent. Yeah. Rutvik Tak: And one last thing is just uh the usually in a flutter list the items rebuild themselves whenever you scroll. 00:47:21 Rutvik Tak: uh in this example it's not doing that because I have added a particular like there's this flutter mixing that you can add to widgets that basically tells flutter to not uh dispose of any widgets that were offscreen. So Tsavo Knott: Yep.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 38
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "opposed to the entire list as well, which is Rutvik Tak: Right. Tsavo Knott: excellent. Yeah. Rutvik Tak: And one last thing is just uh the usually in a flutter list the items rebuild themselves whenever you scroll. 00:47:21 Rutvik Tak: uh in this example it's not doing that because I have added a particular like there's this flutter mixing that you can add to widgets that basically tells flutter to not uh dispose of any widgets that were offscreen. So Tsavo Knott: Yep.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 39
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Rutvik Tak: you b in like in the basic sense flutter like throws off any widgets that goes off screen and usually rebuilding this widget is not very expensive but in our case like a code syntax uh block that is expensive. So we basically tell flatter to not do that and yeah we get some performance improvements there in a very uh long conversation list. Tsavo Knott: Yep. Excellent stuff. I think uh you know the details matter and one of the reasons that we put this project in motion is because obviously we have users come in and say hey you know the desktop app is kind of glitchy you know whatever else so on and so forth but this is uh actually a concept that we worked on uh a eight years ago maybe even earlier and the whole thing that you just saw here is differential rendering except applied from the work we did way way long ago uh for like some of the Chrome and web component stuff into flutter. 00:48:30 Tsavo Knott: Uh which actually refic this update is looking really really tremendous here. Yeah. Rutvik Tak: Yeah. So these are just few things. So I mean few like uh these are basically some patterns or principles that you want to follow uh Tsavo Knott: Yeah. Rutvik Tak: to have a good performance. Yeah. Tsavo Knott: Yeah. And I Rutvik Tak: All right. Tsavo Knott: can just cap it off with uh the verification here of like what we're actually going for. So this was from a talk that I gave at Google like eight years ago. And this is the differential rendering that we're showing in a very simple concept. But if I update like a parent, you can see the counts here, whatever else like you can see things updating. And then you can say, hey, I want to update this child. And you always have this parent rerendering, right? So this is normal kind of like naive implementation of differential rendering. But then if you look at controlled uh true implementation of differential rendering, everything renders once and then the child differentially renders without propagating rerenders up the tree. 00:49:29 Tsavo Knott: So this is not a new concept, but we're actually just saying how do we do exactly what we did back in the day to get, you know, those deep deep performance gains in a limited compute environment, but apply it to Flutter, right? And so, uh, we scouted this the last week and Ruffic, it's looking like some really good stuff here. Yeah. Mack Myers: Hell yeah. Tsavo Knott: Cool. Um, Mac, any anything to add to that? Mack Myers: No, it's just, you know, I know some people maybe not fully following, but just this at scale is really really critical just Tsavo Knott: Yeah.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 40
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "but apply it to Flutter, right? And so, uh, we scouted this the last week and Ruffic, it's looking like some really good stuff here. Yeah. Mack Myers: Hell yeah. Tsavo Knott: Cool. Um, Mac, any anything to add to that? Mack Myers: No, it's just, you know, I know some people maybe not fully following, but just this at scale is really really critical just Tsavo Knott: Yeah.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 41
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Mack Myers: because there's so much information and like believe it or not there is so much data flowing through pieces OS and at any given moment that data could change the desktop app or whatever app it is is going to get a reaction and uh how we handle that reaction from the UI perspective yeah it impacts the experience all at large. So if Tsavo Knott: Yeah. Mack Myers: we can minimize rerendering of specific trees by a factor of 10, 20, whatever it is, the the application is going to feel smooth. 00:50:31 Mack Myers: It's going to feel way faster and snappier at at all points. So very exciting. Tsavo Knott: Yeah. And that's also very important for systems that are designed to rerender automatically, right? So the real-time feed, the suggestions, everything like that. That's a pushbased system. Uh where you know, pieces OS is saying, \"Hey, what should we show the user right now?\" and you have a list of suggestions that's just an expensive list, right? It's a deep list of relationships. Um, how do we make sure that that rendering is butter smooth, right? Um, so excellent stuff there. But yeah, I think across the board there's some really really good work going on. Uh, I think, you know, product side is accelerating uh exponentially, especially because we're adopting so many, you know, tools and and processes. Um, but I'm very excited for the 12.0 release. I think it's going to be a a great step in the right direction. Um, and I know there's a whole bunch of goodness probably on the next all hands from the ML team as well. 00:51:28 Tsavo Knott: So, going to be pretty tremendous. Um, yeah, I think that's all I really have. I mean, we could do some updates. Uh, Sam, if you want to give some, Mark and Mac, but we can also say, hey, you know, we'll call it demo day. Mack Myers: Mine are kind of boring. They're mostly invisible if you want to talk Windows database paths or some small enhancements to the power menu, but nothing crazy. Smit Patel: Yeah. So, I think we should do all hands next week and we can have more updates and there can be some stuff from growth as well. Tsavo Knott: Perfect. Smit Patel: Um, but I think just a high level to SA's point, we, you know, across the company are trying to make sure that, you know, I mean, we're an AI AI startup, right? I mean and there's no excuse for um us to not be using AI in every single role across the organization. Um so on the growth side, you know, we've taken it up upon ourselves um in the month of June for every single um person on the team to start adopting AI and automate um you know, as many parts of the job as possible um and just increase the output.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 42
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "are trying to make sure that, you know, I mean, we're an AI AI startup, right? I mean and there's no excuse for um us to not be using AI in every single role across the organization. Um so on the growth side, you know, we've taken it up upon ourselves um in the month of June for every single um person on the team to start adopting AI and automate um you know, as many parts of the job as possible um and just increase the output.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 43
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "00:52:30 Smit Patel: You know, I think we have a few things already in the works like for example, we're going to rebuild our uh homepage. Um and that's going to happen you know within less than a week which usually would have taken many weeks. So just as an example but I think more to come there next week or the week after. Um but I think I'm super excited to see all the stuff um that you know folks are already doing um internally because I think sometimes it's u people forget to dog food uh you know the stuff that we're preaching. So I think AI is just like baseline now. Um I there was a really good tweet yesterday by the CEO of Zapier. I'll share it in the general channel. I shared it with the growth team, but it just like does a great job of outlining like the different um ways that you can kind of see in your individual role like where you stand in terms of your um you know your usage of AI and like you know what is like basic looks like what does advance look like and I think it's just like a good metric for all of us to just start you know thinking about it because I think fundamentally I think uh every company every organization the way everyone uh everything is being run is disrupted every single function's disrupted and like in the last 6 months like just the way that 00:53:44 Smit Patel: anyone manages, the way anyone leads, the way we Sam Jones: Hi. Smit Patel: build products, market products, sell products, everything is shifted. So like we you know almost have to take a step back and reanalyze how we do things in every single area of the company. So yeah, super excited with all this stuff. Tsavo Knott: Yeah, I'll also say the other beautiful component of the AI uh kind of era that we're entering into is that anyone can do anything. So I Smit Patel: Yep. Tsavo Knott: can, hey Sam, can you go refactor the the checkout page and and make it, you know, styled with black and white logos, you know, whatever else, and Sam can do that in a day, right? And so, you know, it's like, you know, same with Nolan, same with Judson, like everyone across the company is able to do really anything. And so, you're going to see a convergence of engineering roles to where it's like everyone can become a Swiss Army knife extremely quickly, right? I think that's that's beautiful. But the other unique benefit that we have is once you've get once you set up these systems, think about like docs and support and everything like that. 00:54:46 Tsavo Knott: You know, we can have GitHub actions that say, hey, let's take what's, you know, going on in this all hands and prep a change log for, you know, a PR that has, you know, documentation updates, right?",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 44
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "And so, you're going to see a convergence of engineering roles to where it's like everyone can become a Swiss Army knife extremely quickly, right? I think that's that's beautiful. But the other unique benefit that we have is once you've get once you set up these systems, think about like docs and support and everything like that. 00:54:46 Tsavo Knott: You know, we can have GitHub actions that say, hey, let's take what's, you know, going on in this all hands and prep a change log for, you know, a PR that has, you know, documentation updates, right?",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 45
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Or, hey, you know, we have a support issue. Let's fire it off to, you know, a little function that says, here's the links from the doc sites that are relevant to this support issue. So it all becomes much more automated, much more interconnected. Um, and that's really what we're what we're starting to get into. Um, so pretty interesting stuff. Yeah, I'll say one last thing. Shout out to the ML team because I know they didn't have a ton of demos, but they are shipping so much. Uh, I'd like to just share this. We went over the analytics this morning. Um, but in our uh ML kind of analytics, you can see we've got all of these models out there in the wild and they are all benchmarking. So what you're seeing here is the median speed in milliseconds for every single model. 00:55:44 Tsavo Knott: So uh context classification lightning fast uh but ironically has the slowest cold start. So we'll have to see maybe Mark that that might be slightly off but we'll take a look. uh sources, time classifier, prompt moderation, tag predictor, title summary, is personal agent all the way up to cloud models uh for generating summaries. So you know nice to see these models out there performing well and then you can say hey like what are these models classifying things as and you can see the work um where you know we've got total events from the last I don't know these analytics went out last Friday or actually Monday this week. So you can see, you know, content retrieval, scheduling, current status, general, uh, and then non-temporal. So pretty nice to see the results of these. And then on every single one, we can actually take a look at our data set. And you can say, you know, view the events. Um, and on this, you can pop in and you can see if these events load. We've got a nice data set to benchmark these models. 00:56:47 Tsavo Knott: So you can look at the query right here. this person published in an interesting script error, right? It's probably asking about that. Or this person put in uh you know, I saw a oneline object, can't remember the syntax. Uh I gave the original model width uh and the rest was handled for me. It was something like context update. This is a user, right? They're asking, you know, what what did I see? Um so pretty cool to see this stuff out there. And then from this perspective you can see it properly classified it as content retrieval and now we can take all these user queries benchmark them on our new uh new models and so on and so forth. So the flywheel is beginning right to where we can measure these things out there in the wild see how they're doing improve them.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 46
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "asking, you know, what what did I see? Um so pretty cool to see this stuff out there. And then from this perspective you can see it properly classified it as content retrieval and now we can take all these user queries benchmark them on our new uh new models and so on and so forth. So the flywheel is beginning right to where we can measure these things out there in the wild see how they're doing improve them.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 47
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um and I think at large what all this means is you know a month from now two months from now we might have an inflection point where we start to go more and more viral right the word of mouth you know the the retention so on and so forth. 00:57:47 Tsavo Knott: Uh another cool thing I'll show from the analytics people might like this is this is the number of workstream events that are generated uh per user per day. So on average about 53 uh7 workstream events per user and then these are the workstream summaries around 30 workstream summaries per user per day. And Sam gave a little fun fact that means that they had pieces on and running for over 10 hours in that day. Um creating memories for them forming those memories so on and so forth. So, I think uh I think it's, you know, that's a nice retention mode, too, because if you delete pieces, you delete tons and tons of memories and uh I think people are willing to pay for their memories. So, yeah. Cool. Any other things top level questions for the company? Anything at all? Okay. Well, we'll let it let it roll here. Two minutes over. All right, folks. Have a great Friday. Thanks for joining. Great demo day. Smit Patel: Thank Tsavo Knott: Pumped. Smit Patel: you, but Rutvik Tak: All right, you know? Transcription ended after 00:59:00 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "1uBcocsAloWMIWxbXY5zsUoWQaPLeyN1YIgzNwlJ_A0I",
    "chunk_index": 48
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 3, 2025 Nikhil / Hiro Invited Hiro Tamada Nikhil L Attachments Nikhil / Hiro Summary Hiro Tamada canceled a working group meeting due to the team's workload following a product release, while Nikhil L discussed new instructions from Sabosu for the growth team emphasizing efficiency and AI adoption, alongside their surprising nature and potential impact. Nikhil L also presented retention trends, proposed improvement strategies, and highlighted concerns about a significant drop-off in users between installation and first usage, suggesting a need for cross-team collaboration and a clearer growth strategy. Hiro Tamada shared an AI model for predicting user retention and discussed its potential application in optimizing ad spending, while offering support to Nikhil L on various initiatives. Details * Working Group Cancellation Hiro Tamada canceled a working group meeting, citing the recent product release and the likely busyness of the team. Hiro Tamada felt it would be unfair to ask everyone to participate given their workload. * New Growth Team Instructions Nikhil L reported that the growth team had a meeting with Sabosu who provided new instructions focusing on efficiency, KPI-driven work, and the adoption of AI in workflows. Sabosu emphasized the company's identity as an AI company and the need for the marketing team to utilize AI tools for efficiency, with June set as a review month and potential further departures if these changes are not implemented. Hiro Tamada clarified that \"marketing\" refers to the entire growth team. * Growth Team's Reaction to AI Push Nikhil L noted that the sudden emphasis on AI was surprising and potentially challenging for non-technical members of the marketing team who might require some coding knowledge for automation. Nikhil L speculated that Savo's increased involvement with the growth team is due to dissatisfaction with current user growth. Nikhil L found the timing of these instructions, following a period without such directives and a recent layoff, to be unexpected, although logically sound. * Event Outcome and Data Focus Nikhil L criticized the recent branding event, stating that the six weeks of team effort had not yielded any results beyond the fact that it didn't cost any money directly, representing a significant opportunity cost in terms of salaries. Nikhil L expressed satisfaction that the focus has now shifted towards data-driven approaches. * Retention Trends and Onboarding Nikhil L shared retention charts, indicating that day one retention has improved with the new onboarding process. The trend for Mac OS users was better than Windows users, aligning with the idea of targeting users who want the core offering. Day seven, 30, and 90-day retention also showed slight upward trends. * Strategies for Retention Improvement Nikhil L suggested that while retention is generally fine, day one retention could be further improved by enhancing onboarding, and longer-term retention (day 7, 30, 90) could benefit from growth tactics like targeted notifications based on user event triggers. Nikhil L planned to work with Mac on a project to implement these event-triggered notifications. * Retention Chart Definitions Hiro Tamada inquired about the strictness of the windowing for the retention charts.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "than Windows users, aligning with the idea of targeting users who want the core offering. Day seven, 30, and 90-day retention also showed slight upward trends. * Strategies for Retention Improvement Nikhil L suggested that while retention is generally fine, day one retention could be further improved by enhancing onboarding, and longer-term retention (day 7, 30, 90) could benefit from growth tactics like targeted notifications based on user event triggers. Nikhil L planned to work with Mac on a project to implement these event-triggered notifications. * Retention Chart Definitions Hiro Tamada inquired about the strictness of the windowing for the retention charts.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Nikhil L confirmed they were checking exact day retention. Hiro Tamada found the definitions acceptable, noting that while definitions are sometimes loosened for investor presentations, the current day 30 retention was manageable. * Project on Notification System Nikhil L informed Hiro Tamada about their upcoming project to implement a notification system triggered by user events to improve retention. Nikhil L intends to analyze historical trends and compare them after the notification project's implementation. They distinguished between general marketing broadcasts and product notifications triggered by user activity. * Retention and Product Evolution Nikhil L acknowledged that while current retention is improving, it's not at the levels seen a year ago. Nikhil L suggested that the shift in product focus towards LTM2 from storing snippets and copilot might be a contributing factor. Hiro Tamada added that the increasing heaviness of the application and its resource requirements might also affect retention, potentially explaining the lower Windows retention. * AI Model for Retention Prediction Hiro Tamada shared an AI classification model built using Vertex AI that predicts 30-day user retention based on metadata like country, CPU cores, and generation. The model identifies country, course, and generation as highly influential factors in user retention. Hiro Tamada suggested targeting specific countries and CPU types based on the model's findings. * Model Details and Cost Hiro Tamada explained that the AI model's feature importance indicates influential parameters but doesn't specify exact rules like which countries have better retention. For such specific breakdowns, BigQuery analysis is still needed. Hiro Tamada estimated the cost of training one model to be between $20 and $100, depending on data size and complexity, and mentioned they have Vertex credits for experimentation. * Ease of Model Training Hiro Tamada assured Nikhil L that setting up and training models in Vertex AI is relatively straightforward using BigQuery data sets and automated pipelines. Hiro Tamada highlighted the ability to exclude irrelevant features like OS ID to prevent skewing the model. Hiro Tamada suggested researching transformation logic for categorical data. * Experimentation with Google Analytics Data Nikhil L expressed interest in experimenting with the AI model using a small 20GB dataset from Google Analytics. Hiro Tamada encouraged this and offered assistance with any permission issues. * Restarting Search Ads Nikhil L mentioned that while all ads were currently stopped, they were planning to restart with search-based ads due to their cost-effectiveness and contextual relevance. Nikhil L aimed to identify high-intent, low-CPC keywords, contrasting this approach with Luca's previous large-scale display ad spending. * Predicting Retained Users for Ad Optimization Hiro Tamada proposed using the retention prediction model to identify users likely to be retained based on their initial interaction (ISR) and then feeding this information back to Google Ads to optimize for similar users. By sending a filtered, higher-probability set of ISRs, the aim is to acquire more valuable users. Nikhil L understood the concept of optimizing for a specific subset of users but acknowledged that the current low volume of first ISRs might make this approach challenging.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "with Luca's previous large-scale display ad spending. * Predicting Retained Users for Ad Optimization Hiro Tamada proposed using the retention prediction model to identify users likely to be retained based on their initial interaction (ISR) and then feeding this information back to Google Ads to optimize for similar users. By sending a filtered, higher-probability set of ISRs, the aim is to acquire more valuable users. Nikhil L understood the concept of optimizing for a specific subset of users but acknowledged that the current low volume of first ISRs might make this approach challenging.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* Drop-off in First ISR Events Nikhil L raised concerns about a significant drop-off (around 15%) between OSID generation (post-installation) and the first ISR event (first product usage). Nikhil L shared a chart showing a historical trend of this drop-off, which appeared to worsen after October 2024, coinciding with growth team onboarding and product changes. Hiro Tamada found this data very interesting. * Investigating the Drop-off Nikhil L suggested that the drop-off between installation and first usage is a product issue and not solely a marketing concern. Nikhil L noted that the OSID generation timing varies across different installation methods. Hiro Tamada speculated that testing cycles might cause some noise in the data with temporary spikes in OSIDs. Nikhil L argued that testing wouldn't explain the sharp and sustained dip. * Multiple Leaks in the User Pipeline Nikhil L summarized that there are significant leaks at multiple stages: from download to installation, from installation to first usage (50% drop-off), and then a further 60% reduction from first usage to 30-day retention. Nikhil L emphasized that increasing top-funnel acquisition without addressing these leaks would be inefficient. * Need for Cross-Team Collaboration Nikhil L suggested involving Savo and Nathan to discuss and address the identified issues collaboratively between the growth and product teams. Hiro Tamada agreed to this approach. * Current Lack of Clear Growth Strategy Nikhil L explained that despite receiving instructions on how to work more efficiently and use AI, the growth team currently lacks a clear strategic direction and defined KPIs from leadership. As a result, there are no concrete campaign strategies or projects planned for increasing conversions at this time. * Nikhil's Needs and Offers of Support Nikhil L stated they have access to the necessary data and primarily need Hiro Tamada's help in analyzing trends and providing visibility to the product and engineering teams . Nikhil L felt capable of handling marketing, analytics, and coding tasks . Hiro Tamada offered ongoing support and encouraged Nikhil L to reach out with any needs . Suggested next steps * Nikhil L will collaborate with Mac to improve day 30 and day 90 retention by using product event triggers for targeted user notifications. * Nikhil L will create a small Google Analytics data set (around 20 GB) to experiment with Vertex AI for user retention prediction. * Nikhil L will restart advertising with search-based ads for specific keywords on a small budget. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey.",
    "source_id": "1838vi29t08TL_FcDYw4xRTDnNjrXUAEEVudvZQpMr_s",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 3, 2025 Paddle Payments Sync Invited Hiro Tamada Smit Patel Robert Vrooman Bishoy Hany Brian Powell Sam Parks Mack Myers Nikhil L Mark Widman Tsavo Knott Attachments Paddle Payments Sync Summary Attendees Brian Powell, Hiro Tamada, Robert Vrooman, Mark Widman, and Mack Myers discussed the upcoming June 12th release focusing on the signing requirement and initial payroll. Key topics included the sign-in process, gating higher models based on authentication and payment plans, handling non-desktop app users, and production release considerations. Participants also addressed payment test cases, past due subscriptions, user object updates, Paddle account issues, payment plan endpoints, and authentication security, identifying DNS setup and Paddle account access for Mark Widman as current blockers. Details * Meeting Start and Attendees The meeting began with Brian Powell, Hiro Tamada, and Robert Vrooman waiting for Mark Widman and anticipating Mack Myers's arrival. Mark Widman joined shortly after and confirmed Mack Myers would also be joining soon. Mack Myers then joined to listen in on the progress. * Release Target and Infrastructure Hiro Tamada stated the goal is to have the signing requirement and initial payroll by table ready for the June 12th release. Mark Widman confirmed this and mentioned that the infrastructure should ideally be fully built into the flow within Pieces OS by Friday or Monday at the latest. * Sign-in Requirement and Plugins Hiro Tamada inquired about the requirements for sign-in from PFD, Pieces OS, and other plugins. Mark Widman clarified that sign-in will only be required on the desktop app for new users during onboarding and will not initially require changes to Pieces OS or most plugins. Mack Myers supported this plan, noting it should primarily be UI-based for now. * Gating Higher Models and Payment Plans Hiro Tamada questioned if plugins could still access higher models. Mark Widman clarified that access to higher models will be gated based on both authentication and the user's payment plan, with insufficient conditions resulting in an error. Mack Myers detailed how they plan to handle authentication and payment checks on their side, suggesting specific error codes for each scenario. * Handling Non-Desktop App Users Robert Vrooman raised the point about users who might install the extension and Pieces OS without using the desktop app. Mark Widman responded that the authentication gate would be layered in on their side, and access to these models would likely be through a copilot applet with a UI gate. Mack Myers added that this logic would also need to be added to Sublime and CLI, especially for models like Claude 4. * Production Release and Testing Hiro Tamada proposed regrouping on Friday to check the status and asked Brian Powell to create a working group. Brian Powell mentioned being off on Friday but could be available if needed. Robert Vrooman inquired about plugin updates for the Pieces OS 12.0.0 release, and Mack Myers explained it would require updated SDKs and min/max versions for all plugins, but the payments and auth changes themselves shouldn't need net new plugin work immediately.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "this logic would also need to be added to Sublime and CLI, especially for models like Claude 4. * Production Release and Testing Hiro Tamada proposed regrouping on Friday to check the status and asked Brian Powell to create a working group. Brian Powell mentioned being off on Friday but could be available if needed. Robert Vrooman inquired about plugin updates for the Pieces OS 12.0.0 release, and Mack Myers explained it would require updated SDKs and min/max versions for all plugins, but the payments and auth changes themselves shouldn't need net new plugin work immediately.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "* Payment Test Cases and Environment Hiro Tamada requested Brian Powell list out test cases for payments, covering scenarios from sign-in to cancellation, suggesting testing in production. Brian Powell clarified that they only have a staging environment set up currently and offered to send documentation with fake cards for testing, suggesting a separate document for test cases as requested by Mark Widman. * Handling Past Due Subscriptions Mark Widman inquired about handling past due subscriptions. Brian Powell explained that Paddle provides webhooks for past due subscriptions, along with transaction completion, updates, and cancellations, which trigger updates to the user object in their system. * User Object Updates and Endpoints Mark Widman asked if all Paddle webhooks also update the user object on their side. Brian Powell confirmed this and mentioned firing off a user update event via websocket. Mark Widman requested capturing the Paddle-related endpoints. * Verifying Subscription Status Robert Vrooman questioned if their side uses the locally stored user subscription expiration date to query Paddle. Brian Powell clarified that the expiration date comes from their database and that Mark Widman's system would periodically pull the user object to verify. Hiro Tamada added that the backend can always verify the user object and subscription status upon each request. * Production Environment Setup and Blockers Hiro Tamada asked about any blockers for spinning up the production environment in Paddle. Brian Powell mentioned needing to merge Paddle updates into staging before issuing a production PR. Hiro Tamada identified the DNS setup as a current blocker. Mark Widman reported being currently blocked on Paddle due to their user not being attached, preventing testing. * Paddle Account Issues and Resolution Mark Widman detailed issues with their Paddle account, including being invited but not showing up and having a different seller ID upon signing in. Brian Powell offered to ask Paddle to delete Mark Widman's existing account. Brian Powell also noted Hiro Tamada had been invited to the production account and already had access to the sandbox. * Payment Plan Endpoints Mark Widman asked Brian Powell whether to fetch payment plans from the user object or have a specific endpoint. Mark Widman then recommended exposing endpoints for everything related to plans, including getting a specific plan and listing all available plans. * Server-Side Needs and Authentication Security Mark Widman requested the team to fill out the server-side needs from Pieces OS in the provided document. Mark Widman raised a question about preventing users from sharing authentication credentials to bypass payment plans, noting Dcope's single-machine sign-in as a good temporary measure. * Production URLs and Dcope Project ID Mark Widman inquired about the readiness of staging URLs for user team service and websocket. Brian Powell confirmed staging URLs were good but noted the websocket and checkout were not yet in production. Mark Widman also mentioned needing the new Dcope project ID and the production URLs. * User Updated Event Data Brian Powell described the data included in the \"user updated\" websocket event, such as user ID, event ID, Paddle ID, subscription ID, and expiration timestamps. * Local vs.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "sharing authentication credentials to bypass payment plans, noting Dcope's single-machine sign-in as a good temporary measure. * Production URLs and Dcope Project ID Mark Widman inquired about the readiness of staging URLs for user team service and websocket. Brian Powell confirmed staging URLs were good but noted the websocket and checkout were not yet in production. Mark Widman also mentioned needing the new Dcope project ID and the production URLs. * User Updated Event Data Brian Powell described the data included in the \"user updated\" websocket event, such as user ID, event ID, Paddle ID, subscription ID, and expiration timestamps. * Local vs.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Verified Expiration Time Mark Widman discussed the need to maintain both a locally stored expiration time for UI purposes and a separate, server-verified expiration time to prevent malicious user modifications. Hiro Tamada agreed on the importance of preventing user overrides, especially for future features. * Handling Disconnected Users Mark Widman considered the scenario of users being disconnected from the internet and failing verification, suggesting reverting to the persisted \"last verified\" and \"expires at\" values, potentially hashed or encrypted in the database. * Cloud Verification and Local Access Mark Widman noted that for cloud requests, verification could primarily happen on the cloud side, but local access to features would require stricter local checks. * Client-Side Communication for Check-ins Mark Widman raised the need for a way to send requests to the client to prompt a user check-in if their payment status is invalid. Hiro Tamada agreed this was important for real-time updates to the user. * Communication with Growth Team Hiro Tamada emphasized the need to communicate with the growth team regarding gated models, clear communication about which models are gated, and how users can access them, including purchasing subscriptions. * Client Endpoints and Verification Mark Widman stated that there will be client endpoints for verifying payments and listening to a socket stream for verification requests. Additionally, they mentioned another asynchronous endpoint for the desktop app to trigger manual user verification. This endpoint will handle the completion of the verification process and indicate success or failure. * Paddle Identity Verification Hiro Tamada noted that they need to complete identity verification with Paddle soon. Mark Widman asked Hiro Tamada to confirm if it's the same Paddle project as Brian Powell, and Brian Powell confirmed that it is. Hiro Tamada was then asked to invite Mark Widman to the project. * Issue with Account Invitation Brian Powell shared that Emily from Paddle indicated deleting an account is complex and involves their engineering team. In the meantime, Paddle sent an invitation to Mark plus Paddle at pieces, which Brian Powell relayed to Mark Widman. Mark Widman strongly objected to using this email, insisting on using their \"@pieces.app\" address for login and account association. Hiro Tamada suggested scheduling a meeting with Paddle to resolve this issue quickly, and Brian Powell confirmed they also requested the deletion of Mark Widman's other account. * Problems with Signing Up Mark Widman agreed to try signing up with the provided \"Mark plus paddle at pieces.app\" email. However, Mark Widman reported that signing up with this email created a new account. Brian Powell noted that the system shows Mark Widman as invited but not active. Mark Widman shared a screenshot showing a new account with their email and a new seller ID. Mark Widman observed the Pieces logo appearing during the signup process, speculating it might be pulled from the domain. Ultimately, Mark Widman concluded that this signup method was not working. * Next Steps and Project Staging Hiro Tamada announced they would be joining a call with Savo but would post meeting notes and action items later.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Widman reported that signing up with this email created a new account. Brian Powell noted that the system shows Mark Widman as invited but not active. Mark Widman shared a screenshot showing a new account with their email and a new seller ID. Mark Widman observed the Pieces logo appearing during the signup process, speculating it might be pulled from the domain. Ultimately, Mark Widman concluded that this signup method was not working. * Next Steps and Project Staging Hiro Tamada announced they would be joining a call with Savo but would post meeting notes and action items later.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Brian Powell sent Mark Widman the project staging information. Brian Powell agreed to keep Mark Widman updated on when a call with Paddle gets scheduled. Suggested next steps * Brian Powell will inform Mark Widman when Paddle schedules a call. * Hiro Tamada will post all the meeting notes and action items. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey.",
    "source_id": "1TlKgK3cz6wYaGVisCywuulJCCGf7nS3uXN_BzltDCEk",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes Jun 6, 2025 wg-day1-retention Invited Smit Patel Tsavo Knott Sam Jones Nikhil L Mack Myers Mark Widman Hiro Tamada Attachments wg-day1-retention Meeting records Transcript Summary Mark Widman, Tsavo Knott, Mack Myers, and Sam Jones discussed desktop app onboarding, bootstrapping funnel metrics, and the Northstar KPI of average messages per day, linking improvements to ongoing development. They also addressed a dip in nano model quality attributed to analytics events and data, discrepancies in workstream events and summaries, and the importance of using median over average for execution time. Tsavo Knott, Sam Jones, and Mark Widman covered topics including new language model impacts, invalid index errors, JSON mode data, time to first token metrics, target user base system requirements, on-device SLM considerations, and Smit Patel proposed consolidating analytics working groups. Details * Desktop App Onboarding and ISRs Mark Widman and Tsavo Knott discussed the process of users going from off to on onboarding for the desktop app and the generation of Internal Support Requests (ISRs). Tsavo Knott mentioned that the desktop app will become the only download, installing pieces OS and guaranteeing a connection on first boot (00:00:00). Mack Myers shared a board showing the drop-off rate between booting the desktop app and reaching the \"start forming memories\" screen, attributing potential reasons to privacy opt-outs or users changing their minds. Mack Myers suggested analyzing the conversion rate within the memory formation flow to identify drop-offs and errors (00:01:13), and Sam Jones noted that Miguel has related dashboards (00:02:21). * Desktop App Bootstrapping Funnel Tsavo Knott emphasized the importance of tracking a funnel for new desktop app users, specifically how many successfully boot for the first time, ensure core dependencies, sign in, and complete onboarding (00:02:21). Mack Myers confirmed that they will have this data available (00:03:29). * Northstar KPI: Average Messages Per Day Tsavo Knott highlighted the average number of messages per day as a key Northstar KPI, focusing on increasing the number of chats using Long-Term Memory (LTM). They believe that ongoing work on workstream summary, co-pilot, table rendering, and latte rendering will improve queries per user per day. Tsavo Knott also mentioned the potential positive impact of time to first token improvements and pre-warming (00:03:29). * Quality of Nano Models and Analytics Tsavo Knott and Sam Jones discussed a dip in the quality of nano models, which Sam Jones attributed to a misattributed analytics event and potential data corruption issues. Sam Jones clarified that the data corruption was likely earlier in the year and that the current metrics are LTM-specific. They also touched upon the transition from Quadrant to cache base in February (00:04:51). The data showed a period in April with a dip, possibly due to an unknown issue, but it seems to be recovering (00:05:58). * User Growth and Tool Usage Tsavo Knott noted a significant number of daily active users utilizing the MCP tool in Cursor, which is more than their company size. They also highlighted the positive average MCP tool calls per user per day (00:06:41).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "was likely earlier in the year and that the current metrics are LTM-specific. They also touched upon the transition from Quadrant to cache base in February (00:04:51). The data showed a period in April with a dip, possibly due to an unknown issue, but it seems to be recovering (00:05:58). * User Growth and Tool Usage Tsavo Knott noted a significant number of daily active users utilizing the MCP tool in Cursor, which is more than their company size. They also highlighted the positive average MCP tool calls per user per day (00:06:41).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Additionally, Tsavo Knott presented data on the number of users with generated workstream summaries and the average number of summaries per user per day, which Sam Jones equated to a significant amount of processing time. The number of workstream events processed per user per day was also reported as excellent (00:07:33). * Impact of New Language Models Mark Widman mentioned the addition of new language models on May 1st, including Gemini and OpenAI models, which users can access from the cloud. Tsavo Knott suggested this could be related to user bounce if users are looking for the latest models. They also discussed the models used for LTM queries and whether they are new or existing users (00:08:30). * Workstream Events and Summaries Discrepancy Tsavo Knott and Sam Jones identified a discrepancy between the number of users with workstream events processed and the number with summaries, with more users having summaries (00:08:30). Mark Widman clarified that it's possible to have more summaries than LTM events due to MCP but acknowledged the point about more users with summaries. Sam Jones suggested letting the new analytics data stabilize for a week before further analysis (00:09:33). They hypothesized that summaries might be generated across all users, with generation skipped if there's nothing to summarize. Mark Widman and Sam Jones discussed potential reasons for the discrepancy, including the timing of the event firing and the possibility of summary generation failures (00:10:28). * Median vs. Average Execution Time Tsavo Knott and Sam Jones discussed the use of median versus average for measuring execution time of models. Sam Jones explained that the median is a better metric due to the non-bell curve distribution and potential for outliers caused by timeouts or slow connections, which can skew the average (00:11:28). They agreed that the median provides a more accurate representation of the typical user experience (00:12:52). Mark Widman concurred, noting that while the average can highlight potential issues like model loading problems, the median is more reliable for general performance assessment until outlier analysis can be done (00:23:09). * Time Classifier Package Benchmarks Tsavo Knott mentioned work on benchmarks for the time classifier package. Sam Jones pointed out a confounding factor: the current back-off to a cloud model for span prediction, which results in higher execution times (00:14:49). Mark Widman confirmed the availability of data to distinguish between local and cloud model usage (00:15:47). * Analysis of Query Types and Context Intention Router Tsavo Knott noted the accumulation of a valuable dataset on query types (proper not, temporal, etc.) for content retrieval. Sam Jones expressed enthusiasm and inquired if the same analysis could be done for the context intention router (00:15:47). Mark Widman confirmed this capability, mentioning the effort invested in setting up this tracking (00:16:32). * General Queries with LTM On and Invalid Index Errors Sam Jones raised the issue of users making general queries with LTM switched on, which could negatively impact user experience due to longer processing times. Tsavo Knott reported an interesting number of invalid index errors (00:16:32).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "accumulation of a valuable dataset on query types (proper not, temporal, etc.) for content retrieval. Sam Jones expressed enthusiasm and inquired if the same analysis could be done for the context intention router (00:15:47). Mark Widman confirmed this capability, mentioning the effort invested in setting up this tracking (00:16:32). * General Queries with LTM On and Invalid Index Errors Sam Jones raised the issue of users making general queries with LTM switched on, which could negatively impact user experience due to longer processing times. Tsavo Knott reported an interesting number of invalid index errors (00:16:32).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones recalled a recent patch related to this, but Mark Widman was initially unsure. Tsavo Knott also noted a number of timeout errors (00:18:09). Mark Widman later clarified that the invalid index error is resolved, with the system catching it and using a default (00:19:15). * JSON Mode Data and Classifier Labels Tsavo Knott inquired about the destination of the results from the JSON mode. Mark Widman explained that the errors are likely caught and handled at a higher level (ISO server), defaulting to a standard behavior like running the LTM. In successful events, specific properties related to the action classifier and labels should be present. Sam Jones noted that the \"not set\" result was uninformative (00:19:59). They agreed to investigate the source of the \"not set\" values, as there were fewer in one specific view. The cloud model overwhelmingly indicated \"content retrieval\" as the task (00:21:11). * Importance of Micro Models and Cloud Backoff Sam Jones reiterated that refining the micro models is a top priority (P0), as this will eventually allow the removal of the cloud backoff. Tsavo Knott agreed (00:22:02). * Time to First Token Metrics Tsavo Knott presented data on the median time to first token, total time, and trends for context aggregation and completion of the first LLM token. They highlighted the difference between the median and average, with the average being more susceptible to outliers (00:22:02). Sam Jones reiterated that the average (mean) is currently not very informative due to outliers, such as users with very long completion times. They suggested that once timeout data is plotted and outliers can be removed, the mean will become more useful. Mark Widman concurred, stating that while outliers skew the average, the average can still indicate potential underlying issues (00:23:09). The P75 metric was also noted as interesting for identifying patterns among users with longer processing times. Tsavo Knott emphasized that the trend of metrics like P75 is a key indicator of whether performance is improving or worsening (00:24:33). * Target User Base and Minimum System Requirements Sam Jones raised a broader question about whether the goal is to build a system that works for everyone or a high-spec system for a specific user segment. Tsavo Knott believes the aim is a broader audience, similar to how Google Chrome became universally adopted due to its performance on various devices (00:25:27). They suggested aiming for an installation and permissioning process as simple as Zoom. While not intending to support very old devices, the focus is on digital professional workers and ensuring the software works well on their typical hardware (00:26:38). Sam Jones suggested establishing minimum system specifications to help define when the performance goals are met (00:27:42). Tsavo Knott mentioned positive discussions with Google Labs, including potential research into running the software on Android, highlighting the ongoing challenge of performance in diverse environments. They emphasized the company's focus on building efficient ML systems for low-compute environments (00:28:47).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "intending to support very old devices, the focus is on digital professional workers and ensuring the software works well on their typical hardware (00:26:38). Sam Jones suggested establishing minimum system specifications to help define when the performance goals are met (00:27:42). Tsavo Knott mentioned positive discussions with Google Labs, including potential research into running the software on Android, highlighting the ongoing challenge of performance in diverse environments. They emphasized the company's focus on building efficient ML systems for low-compute environments (00:28:47).",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott believes that optimizing individual components will contribute to overall better performance, given the increasing constraints of computing environments and the likelihood of more ML applications running on devices (00:29:53). * On-Device SLM and Performance Transparency Tsavo Knott expressed interest in knowing their application's position in the queue for using on-device Small Language Models (SLMs) at the Windows operating system level. This would allow them to inform users if slow performance is due to system-level resource contention rather than the application itself. They reiterated the need to make their application as fast as possible (00:30:46). * Upcoming Sprint and Word of Mouth Tsavo Knott summarized the meeting, noting positive word of mouth but emphasizing the need to achieve a state where the application \"just works\" by refining the nano models (00:30:46). The Northstar KPI remains LTM queries per user per day (00:31:37). * Consolidation of Analytics Working Groups Smit Patel suggested consolidating the various analytics working groups (e.g., analytics day, retention) into a single, potentially longer, meeting to improve attendance and avoid miscommunications (00:31:37). Tsavo Knott agreed with the idea of an \"analytics weekly\" meeting, potentially on Friday mornings . * Summaries for All Hands Meeting Tsavo Knott requested Mark Widman, Sam Jones, and Mack Myers to provide a brief summary of their current status for the upcoming demo-heavy all-hands meeting . Suggested next steps * Mark Widman will provide data on the usage of local vs. cloud models for backoff and the granular properties for the action classifier classify label task to Tsavo Knott. * Hiro Tamada will explore combining analytics, data retention, and related working groups into a recurring meeting. * Sam Jones, Mark Widman, and Mack Myers will provide a status summary to Tsavo Knott for the all-hands meeting slides. * The group will create a funnel tracking desktop app boots, core dependency checks, sign-ins, and onboarding after the 12.0 release. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript Jun 6, 2025 wg-day1-retention - Transcript 00:00:00 Mark Widman: regardless um whether they have any connecting apps and so on, if they go from off on onboarding to on onboarding specifically with regard to the desktop app, they're going to get another ISR. Tsavo Knott: Yeah. So that's why here I'm thinking like if we did that chart by onboarding true uh or some type of like Yeah. Onboarding true is particularly an interesting one because it's yeah it's that that first ISR where you know you have a connection and you know like that user went through. I'd love to see that uh ratio if you will. Hiro Tamada: Mhm. Tsavo Knott: Yeah. Hiro Tamada: Yeah. Tsavo Knott: But by the way, like I said, all of the stuff will change because the desktop app is going to be the only app you download now.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "uh or some type of like Yeah. Onboarding true is particularly an interesting one because it's yeah it's that that first ISR where you know you have a connection and you know like that user went through. I'd love to see that uh ratio if you will. Hiro Tamada: Mhm. Tsavo Knott: Yeah. Hiro Tamada: Yeah. Tsavo Knott: But by the way, like I said, all of the stuff will change because the desktop app is going to be the only app you download now.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "And it's going to install a piece OS, which means that like the guaranteed you're going to have a connection the first time it boots up, right? Mack Myers: Um, Hiro Tamada: Yeah. Mack Myers: can I share this too? Tsavo Knott: Yep. Mack Myers: Just making sure this is decent. This is uh this is a board I have that's more desktop app oriented 00:01:13 Hiro Tamada: Heat. Mack Myers: uh with some of the new onboarding steps. It doesn't go into like the start forming memories, but this is just like consider this the number of people who boot the desktop app and then get to the start forming memories screen um and the percentage of such. This drop off right here, it could be due to a couple of things. The first thing is that it could be users who opted in to get rid of privacy. So, checked out of the turn telemetry off. Um, it could be people that, to your point, Sam, they got in the app, they're like, \"Ah, maybe I don't want this.\" They could have fallen off. But, as you can see from this screen to these other screens, it's pretty much, you know, a near one:1 ratio. Um, Sam Jones: This is awesome. Mack Myers: so it's looking pretty good. And then the next phase of this would be you know here I don't know if Nquille or yourself ever did anything related to like the start forming memories onboarding tour with all those uh events that we sent over but it would also be interesting either through mix panel or you know big query if we were to put together a table that kind of maps out that flow and sees how users are converting in that start forming 00:02:21 Mack Myers: memories like that memory memories formation flow um to are users completing it? Are they dropping off? Are they getting to 30 memories? You know, are we experiencing errors? Stuff like that. Tsavo Knott: Yep. Mack Myers: Um to really measure how that's going. Tsavo Knott: Yeah. Sam Jones: Mark, Hiro Tamada: Miguel has Sam Jones: could Hiro Tamada: all the dashboards around that should be Sam Jones: could Mack Myers: Nice. Sam Jones: we have a look at the the 30-day and the three month just to see what the trend was through? Mack Myers: Um yeah, it's kind of Sam Jones: Okay. Mack Myers: similar. Um, and I am filtering it by 4.1.0 4.1.12 and 3 because Sam Jones: Perfect. Mack Myers: this mainly existed after 4.1. Tsavo Knott: I mean the fact that that's less than 10% is not not too bad. Um I think you know after this 12.0 going to release mech.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "similar. Um, and I am filtering it by 4.1.0 4.1.12 and 3 because Sam Jones: Perfect. Mack Myers: this mainly existed after 4.1. Tsavo Knott: I mean the fact that that's less than 10% is not not too bad. Um I think you know after this 12.0 going to release mech.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "We're going to want a version of this which is like desktop app, you know, boots for the first time, ensure core dependencies, you know, like how how many people make it through that and then they get into the sign in, how many people get through the signin and then how many people get through, you know, the onboarding stuff. 00:03:29 Mack Myers: Yep. We will exactly have all that stuff. Tsavo Knott: Yeah, that'll be the nice the a really nice funnel. Mack Myers: Yep. Tsavo Knott: Yeah, nice. Uh, okay. Cool. Um, let me just share my screen here as well. So, two things. Number one, um, I think so a Northstar KPI on our side is just, uh, average number of messages per day, right? So like trying to get around here like uh this is like 17 for non uh non-copilot chats um or something like that. And then you know down here this is LTM uh chats. So 5 79 something like that. Um I think you know again this is our northstar. It's like can we get these number of chats uh that use LTM up? But nonetheless, I think all the selection work we're doing inside the workstream summary and the co-pilot, the fixes for the table rendering, the latte rendering, I think overall it's going to improve this queries uh per user per day significantly. I also think that uh the time to first token stuff that we're doing and the pre-wararming um I don't know if that's gone in yet or not, but when you click on that input calling that pre-warm endo endpoint or the preparation endpoint, I think that'll help this out just be a better experience. 00:04:51 Tsavo Knott: And then of course Sam, the quality of the the nano models themselves. I think that's important. Um we had some type of dip in here. I can't remember what exactly Sam Jones: Yeah, Tsavo Knott: it was. Sam Jones: it was it it was a it was a couple of things. So one one of the analytics events was being misattributed to a separate pipeline um as far as I remember and then there was I think that correlated with potentially like some of the issues we were having around um uh data corruption. Um I could be wrong. Tsavo Knott: Yeah, I think the data corruption stuff was probably earlier in the year, but we would have never even made it to this point of time if the data corruption happened because Sam Jones: Um Tsavo Knott: remember these Sam Jones: yeah. Tsavo Knott: are these are LTM specific queries. The data corruption stuff is more so in the the down wow like at large across everyone. Sam Jones: Yeah, true. And at that time we were using Quadrant, right? 00:05:58 Sam Jones: Well, when did we switch from Quadrant to catch base? Tsavo Knott: Yeah, that was like February. Sam Jones: That was February. Tsavo Knott: Yeah. Sam Jones: Yeah. Mack Myers: Thank you.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "would have never even made it to this point of time if the data corruption happened because Sam Jones: Um Tsavo Knott: remember these Sam Jones: yeah. Tsavo Knott: are these are LTM specific queries. The data corruption stuff is more so in the the down wow like at large across everyone. Sam Jones: Yeah, true. And at that time we were using Quadrant, right? 00:05:58 Sam Jones: Well, when did we switch from Quadrant to catch base? Tsavo Knott: Yeah, that was like February. Sam Jones: That was February. Tsavo Knott: Yeah. Sam Jones: Yeah. Mack Myers: Thank you.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: So, Sam Jones: Okay, Tsavo Knott: this this Sam Jones: my Tsavo Knott: is that Sam Jones: bad. Tsavo Knott: April period of time. Sam Jones: I don't know. I saw that, too. I assumed there was some Yeah, I don't Tsavo Knott: It Sam Jones: know. Tsavo Knott: looks Sam Jones: I Tsavo Knott: like Sam Jones: don't know Tsavo Knott: it Sam Jones: what Tsavo Knott: looks like it's Sam Jones: that Tsavo Knott: coming back up. Um and then of course like this stuff will you know follow like I think around January or something like that somewhere in this region we did uh a product hunt. I can't remember what all the the dry I think we probably picked up a good couple thousand people from the ads campaigns we were doing over the holidays but Sam Jones: Yeah, there was like two weeks where nobody used the WP. It looks like 00:06:41 Tsavo Knott: yeah yeah Sam Jones: if you look down the D there, it just created I'm not I suspect that's an analytics issue because Tsavo Knott: I think so Sam Jones: I Mark Widman: And Sam Jones: don't Mark Widman: when Sam Jones: really Mark Widman: did you pick Sam Jones: Yeah. Mark Widman: back? We pick backed up May 1. Tsavo Knott: Exactly. And it picked back up almost like instantly like Mark Widman: That is Tsavo Knott: you know Mark Widman: really Tsavo Knott: with with natural decay of users but at the Dow you know it's like boom. Yeah. So not bad there. Um I think this one's really interesting. Um MCP tool breakdown. So roughly 54 users ripping it in cursor now which is pretty cool on a a daily basis. Um, so I mean that's at least 20 more than our company. And then I think this one's also interesting is the average MCP tool call per user per day. Uh, which is also nice. So pretty great to see that. Um, we're taking a look at this. 00:07:33 Tsavo Knott: This is looking good as well. So this is um roughly Yeah, let me see here. This is the number of users where workstream gener uh summary was generated for that day. So pretty nice to see that. Um, and then this is workstream summaries uh per user like um so we're creating roughly 30 workstream summaries per user per day which is pretty nice as well. Sam Jones: Just Tsavo Knott: Um Sam Jones: a note that the Tsavo Knott: Yep. Sam Jones: 30 summaries a day is equivalent to 10 hours Tsavo Knott: That's Sam Jones: in that Tsavo Knott: right. Sam Jones: day with with pieces OS running and the LTM running. Tsavo Knott: That's Sam Jones: So Tsavo Knott: right. Sam Jones: that's pretty cool, I think. Yeah. Tsavo Knott: That's Mack Myers: I Tsavo Knott: really Mack Myers: saw Tsavo Knott: awesome. Mack Myers: it.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "pretty nice as well. Sam Jones: Just Tsavo Knott: Um Sam Jones: a note that the Tsavo Knott: Yep. Sam Jones: 30 summaries a day is equivalent to 10 hours Tsavo Knott: That's Sam Jones: in that Tsavo Knott: right. Sam Jones: day with with pieces OS running and the LTM running. Tsavo Knott: That's Sam Jones: So Tsavo Knott: right. Sam Jones: that's pretty cool, I think. Yeah. Tsavo Knott: That's Mack Myers: I Tsavo Knott: really Mack Myers: saw Tsavo Knott: awesome. Mack Myers: it.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 13
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: And then similarly if we look at the number of workstream events processed uh is roughly 537 per user per day which is excellent as well. Um considering we might process those every you know two to five minutes. 00:08:30 Mark Widman: I uh I just sent a change log. It looks like on May 1st precisely, uh, we added a ton of new new language models or yeah, new LLMs to our, uh, to our stack specifically that users could chat with from the cloud like a lot of the Gemini and OpenAI models. Tsavo Knott: Yep. Mark Widman: So, it could be interest related like people bouncing because we don't have the latest models. Tsavo Knott: Isn't it a kill on this call? Hiro Tamada: Um, I wish he was I mean I I should have asked him to join but Mark Widman: It'd Hiro Tamada: it's fine. Mark Widman: be interesting to see what models are used for some of those LTM queries as well and whether or not there are new or existing users. Tsavo Knott: Yes, definitely. Um, yeah. So, these are just kind of like some of the northstars. The interesting thing here though, I will say, Sam, is workstream events. The number of users that had workstream events processed in that day um versus let me take a look at this. 00:09:33 Sam Jones: There's something off there, isn't there? Tsavo Knott: That would Sam Jones: Doesn't Tsavo Knott: be why Sam Jones: make sense. We've got 2,000 users on with events and then 8,000 with summaries, but worth looking into as well. These analytics, when did they go in, Mark? Like a couple of days ago. So, Mark Widman: It it's possible uh I'm sorry to get you off there, but it is yes possible to have more summaries than LTM events um because MCP, but I know Sam Jones: more Mark Widman: we don't Sam Jones: users Mark Widman: have Sam Jones: with summaries. Mark Widman: MCP users. Sam Jones: Good point. Um, yeah, but I'm thinking as well, probably nice to let these bake for for Tsavo Knott: Let Sam Jones: a Tsavo Knott: me Sam Jones: week Tsavo Knott: see. Sam Jones: or so before we Mark Widman: They went in uh a week ago earlier this week. No, they went in on would have gone Sam Jones: fast. Mark Widman: in on Tuesday. Sam Jones: Thanks. Mark Widman: Monday or Tuesday? Sorry, Tsavo Knott: We 00:10:28 Mark Widman: I'm Tsavo Knott: should look at We should just triple check this one. But this is daily active users. who had this event. So, I'm not sure this is Mark Widman: Yeah. Tsavo Knott: daily active users that had this event. Mark Widman: Yeah. Sam Jones: We we my guess here is that because the summaries are associated with a periodic and correct me if I'm wrong here Mark we're probably firing that across all users and then skipping generating summaries if there's nothing to generate.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 14
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Thanks. Mark Widman: Monday or Tuesday? Sorry, Tsavo Knott: We 00:10:28 Mark Widman: I'm Tsavo Knott: should look at We should just triple check this one. But this is daily active users. who had this event. So, I'm not sure this is Mark Widman: Yeah. Tsavo Knott: daily active users that had this event. Mark Widman: Yeah. Sam Jones: We we my guess here is that because the summaries are associated with a periodic and correct me if I'm wrong here Mark we're probably firing that across all users and then skipping generating summaries if there's nothing to generate.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 15
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So, I'm guessing maybe maybe we just need to Tsavo Knott: Check that Sam Jones: adjust where Yeah. where the where the event is. Mark Widman: Yeah, it's most likely the case. Yep, that sounds proper. Yeah, either one we Yeah, probably just want to not do summary generation, right? Tsavo Knott: or you just check if it has contents. If the work summary has contents. Mark Widman: I think it pro will probably fail. I I bet you Sam Jones: Yeah. Mark Widman: if you look at a lot of the summary generations, you're going to see a lot of failures. 00:11:28 Tsavo Knott: Oh, okay. Sam Jones: This might be as simple as just changing the line the event gets fired on. Tsavo Knott: There's not a lot of failures. Mark Widman: Damn. Mack Myers: That's pretty good. Tsavo Knott: Yeah, we just need a way to verify one of the two. Something one of these two is wrong basically. Sam Jones: I think summaries summaries for sure is wrong. I think um although I'm a I'm a I'm a pessimist on this kind of stuff. Maybe we do have 8,000 users with the LTM switched on. Tsavo Knott: Yeah. And then so for example this one um this is the median execution time Sam I know we kind of had a question about median and average um what was the reason for that Sam Jones: So, um, the mean works really well when you've got a bell curve. Um, but the way these models work, they're either going to execute or something's going to go wrong. And in the cases where things go wrong, we've got a timeout, but that's all the way up at 15 seconds. And so this the distribution will look bell curvy and then flat and then a massive spike um in the tail. 00:12:52 Sam Jones: And what that does is it just pulls the mean way off base. Tsavo Knott: That's Sam Jones: Um Tsavo Knott: right. Sam Jones: and so whenever you've got a nonbell curve distribution um with potential outliers, you'd want to use the median. Um, so the me Yeah, it's a better it's a better approximation of like the Tsavo Knott: The Sam Jones: usual Tsavo Knott: actual Sam Jones: experience for a user. Yeah. Tsavo Knott: Yeah. So including our outliers, it looks like you know we these are the users probably like in India or like kind of like remote regions where you know they're making super global requests uh to these cloud models. But the nice thing is uh these outliers like on the like time and stuff these are probably just representative of slower devices.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 16
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "or like kind of like remote regions where you know they're making super global requests uh to these cloud models. But the nice thing is uh these outliers like on the like time and stuff these are probably just representative of slower devices.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 17
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So you're saying like you know worst case scenario on like slow devices time span prediction prompt title whatever else uh even this time classifier to roughly like one second each um versus like you know the median or the mean here is excuse me the median is looking pretty pretty 00:13:57 Sam Jones: So Tsavo Knott: uh Sam Jones: the Tsavo Knott: pretty tight. So, not bad of a delta, honestly. Sam Jones: in in this case you'd want to the the average is almost not informative because you would just need one user who took an awful long time and some edge case and that will wreck the wreck the measure. So I think we're talking about this on on Monday as well. Um but if you can give me the or let me know where that data lands, we can you know Kier Kieran can take a peek at it and get some charts and we'll be able to see you know we'll plot like we'll plot the distribution and we'll be able to see what the Tsavo Knott: Yeah. Sam Jones: majority of our users are actually experiencing. Um maybe this is really nice as a this to have this data is amazing and Tsavo Knott: Yeah. Sam Jones: um and yeah it's a great starting point but to get real insights out of it we'll need to we'll need to do a bit push it a Tsavo Knott: Yeah. 00:14:49 Sam Jones: bit further. Tsavo Knott: I I thought um this one was pretty interesting. I'll just blast this super fast. But um hang on one sec. Sorry. Close. Let me just duplicate this real fast. Show you guys this. I was looking at this last night because uh I was trying to make some benchmarks for the time classifier package that I was building up. But yeah, so we can just kill that. We got the task. So Sam Jones: So Tsavo Knott: we'll just have this task up here and then Sam Jones: one extra thing, one confounding factor here to note on the time classifier particularly here is that currently there's a back off to a cloud model. So the numbers we're we'll be seeing here specifically for the span prediction are going to be way higher then Tsavo Knott: Yeah. Sam Jones: yeah it's we've got almost two distributions in the same the same chart. One where we back off which is be way longer and one where we don't. Tsavo Knott: Interesting. 00:15:47 Sam Jones: Yeah. Tsavo Knott: Mark, do we have any backoff data? Uh, like do we have any way to know if it was using the local model or the cloud model? Sam Jones: Okay. Mark Widman: Yep, there should be a property on there of cloud. Tsavo Knott: Okay. So, let's see here. Um, all right. So, I will clear this.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 18
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "which is be way longer and one where we don't. Tsavo Knott: Interesting. 00:15:47 Sam Jones: Yeah. Tsavo Knott: Mark, do we have any backoff data? Uh, like do we have any way to know if it was using the local model or the cloud model? Sam Jones: Okay. Mark Widman: Yep, there should be a property on there of cloud. Tsavo Knott: Okay. So, let's see here. Um, all right. So, I will clear this.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 19
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "But yeah, Sam, definitely worth taking a look at this where we can say, you know, we can look at the queries on all of these and we can say like, you know, of content retrieval, you know, are these like proper not or temporal, you know, proper not, whatever else. But we're actually starting to get a pretty nice data set in here. Um, Sam Jones: That's really cool. Can Tsavo Knott: for Sam Jones: we do the same on the context intention router? That would also This is great. I didn't Tsavo Knott: course. Sam Jones: realize Tsavo Knott: Yeah. Sam Jones: we Tsavo Knott: So, Sam Jones: would have this. This is amazing. 00:16:32 Tsavo Knott: yeah. Yeah. Mark and I, we spent a lot of time layering this s*** in, but see here. Hang on. Apologies. Sam Jones: And we've got a lot of this in Big Query as well, sort of tracking the whole flow, but this is just really nice to look at. Tsavo Knott: Yep. I'll fix all this s*** later, but um let me duplicate this real fast. f****** mix panel takes forever. Um all right, let's see here. So, we're going to go to Sam Jones: What's what's really interesting here? What I'm particularly interested in is are are there users who are making general queries but with the LTM switched on because that's a really nice place where you can improve the user experience. Right? If a user is asking, you know, how to fix this Python code and they're having to wait for the LTM stack to complete, that's that's not an optimal um use UI UX. Sorry. Tsavo Knott: We have an interesting amount of invalid index. Sam Jones: Oh, we patched that, didn't we, Mark? 00:18:09 Sam Jones: I saw something whilst I was away. There was Mark Widman: Um, I'm not sure not sure what that is. Tsavo Knott: A lot of a lot of timeouts. That's most of our timeout is future not complete. Timeout exception after 10 seconds. Sam Jones: weird. Let me have a look at where this um Hiro Tamada: So we Sam Jones: what we're Hiro Tamada: can Mark Widman: the Sam Jones: wrapping with this event. Hiro Tamada: we actually Mark Widman: the Hiro Tamada: get that Mark Widman: timeout the timeout of 10 seconds I would believe. Oh, wait. Is that the backbone classifier having an issue with that timeout or Sam Jones: Yes, Mark Widman: is Tsavo Knott: Yeah. Mark Widman: it Tsavo Knott: Yeah. No, this is this is the uh classified context injection. Sam Jones: that's the under the hood. I think it's the backbone classifier. Mark Widman: just Tsavo Knott: Yeah. Sam Jones: That seems that seems off in terms of oh, is this execution speed Tsavo Knott: This Sam Jones: not? Tsavo Knott: is Oh, sorry. This is uh Let me just rename this. 00:19:15 Tsavo Knott: Um Sam Jones: Yeah, that's the median of time elapsed.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 20
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "that timeout or Sam Jones: Yes, Mark Widman: is Tsavo Knott: Yeah. Mark Widman: it Tsavo Knott: Yeah. No, this is this is the uh classified context injection. Sam Jones: that's the under the hood. I think it's the backbone classifier. Mark Widman: just Tsavo Knott: Yeah. Sam Jones: That seems that seems off in terms of oh, is this execution speed Tsavo Knott: This Sam Jones: not? Tsavo Knott: is Oh, sorry. This is uh Let me just rename this. 00:19:15 Tsavo Knott: Um Sam Jones: Yeah, that's the median of time elapsed.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 21
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Tsavo Knott: this is the general I can just do total events. Nice. And then Sam Jones: Oh, Tsavo Knott: let me Sam Jones: there Tsavo Knott: go Sam Jones: we Tsavo Knott: to Sam Jones: go. Tsavo Knott: apologies. Let me go to um let's see if how the error is looking. So these are the types of errors not set which is great. So majority are not set but definitely you should look at the the invalid index on classifier label 51. Um Mark Widman: Oh, Tsavo Knott: that's Mark Widman: sorry, sorry, sorry, sorry, sorry. Yes, that I'm sorry for slow being slow on that one. Tsavo Knott: yeah Mark Widman: That Sam Jones: We Mark Widman: is Sam Jones: fixed Mark Widman: resolved Sam Jones: that, right? Mark Widman: even though it is an error. It's caught and it's used as a default. But yes, that is there is an error in the classifier. Tsavo Knott: and then Mark on this let me just blast this JSON mode here. 00:19:59 Tsavo Knott: Do you know how where the result of this goes? Mark Widman: Um, yep. It should be a little bit higher up. So, it's likely just getting caught and it's just handled um further up the stack because these are these are at the lower level in the ML facade. But I believe what we're doing is we're actually catching it in ISO server and we're just defaulting to a default. Tsavo Knott: Got it. Sam Jones: We're defaulting to running the the Mark Widman: But in Sam Jones: LTM. Mark Widman: a successful Yeah, in a successful event, we should have those properties on there. Action classifier classify label. Then we we should have a bunch of those like additional properties and stuff on there. I can I can send the granular ones too if you want for that specific Sam Jones: Nice. Mark Widman: task. Tsavo Knott: There you go. Sam Jones: uninformative unfortunately. Tsavo Knott: So the not is probably the number of errors the error ones. Sam Jones: Um, Mark Widman: So are Sam Jones: let Mark Widman: those Sam Jones: me 00:21:11 Mark Widman: the Sam Jones: take Mark Widman: number? Sam Jones: a look at Mark Widman: Yeah. Sam Jones: let me let me take a look at this um and Tsavo Knott: Okay, Sam Jones: I'll Tsavo Knott: cool. Sam Jones: I'll get Tsavo Knott: Yeah, Sam Jones: back to you. Tsavo Knott: I threw that in here and then we just pop into this one. Um, Sam Jones: because it looks like here we've got some not set as well. So I'm wondering where Mark Widman: Yeah, Sam Jones: that's coming from. Mark Widman: my guess is that Tsavo Knott: have Mark Widman: if the Tsavo Knott: a lot less knots. Mark Widman: it was likely an error, but we Sam Jones: Yes, Mark Widman: could probably Sam Jones: maybe the Mark Widman: also see a one one.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 22
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones: back to you. Tsavo Knott: I threw that in here and then we just pop into this one. Um, Sam Jones: because it looks like here we've got some not set as well. So I'm wondering where Mark Widman: Yeah, Sam Jones: that's coming from. Mark Widman: my guess is that Tsavo Knott: have Mark Widman: if the Tsavo Knott: a lot less knots. Mark Widman: it was likely an error, but we Sam Jones: Yes, Mark Widman: could probably Sam Jones: maybe the Mark Widman: also see a one one.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 23
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "We should we should likely see a one one if it failed and that property is not set and that's the proper task. Tsavo Knott: The cloud overwhelmingly says it's content retrieval. Sam Jones: is the cloud. Back up. Back off. Yeah. Tsavo Knott: That's right. Sam Jones: Yep. 00:22:02 Sam Jones: I mean Salv Tsavo Knott: Yeah, Sam Jones: to your point Tsavo Knott: not Sam Jones: earlier Tsavo Knott: bad. Sam Jones: like the um nailing these micro models is definitely our sort of P 0 at the moment and Tsavo Knott: Yeah, Sam Jones: once Tsavo Knott: P 0. Sam Jones: once we've done that we can we can take these cloud back off training wheels Tsavo Knott: Yeah, exactly. Um and then this is the only other thing is this is the time to first token median. So this is your total time. So total time to first token for folks right here um is you know roughly three or excuse me roughly five seconds almost six and then if you look at context aggregation and uh uh completion of first LLM to token yeah and then these are your average trends of time to first token. So this is the average versus this is the median. So if we change this to average. Now the average metric is the harder goal to get. You know what I'm saying? Um 00:23:09 Sam Jones: It's Tsavo Knott: but the median is helpful. Sam Jones: the again the average the mean here is I would say is non-informative because any outliers like if hero for example you've been up in the P99s and sometimes you know we've got users that take eight hours to complete something. And so a single eight hour event is going to massively massively bias our mean. Um and so because we're not doing any outlier removal here, I'd say median is as good as we get until until I get the plots. Um and then Tsavo Knott: Yep. Sam Jones: we we'll be able to we'll be able to all of the timeouts will be in a a line and we can just remove those and then then the meme becomes informative. Tsavo Knott: Yeah. Mark Widman: Yes, I do agree. Um I think that with those outliers both like um like further outside of three standard deviations outside of the mean. Um I think that that's definitely pulling. Um that being said, I do think it's still informative in a different way. uh that says especially if our average is pulling us that hard uh in in difference to the median that tells us that we could potentially have like model loading problems or we could potentially have like an uncompleted completer or we could have various edge cases. 00:24:33 Mark Widman: So I think it's informative but just in a different way. Tsavo Knott: Yeah, the Sam Jones: Oh Tsavo Knott: P75 Sam Jones: yeah, Tsavo Knott: is also Sam Jones: once Tsavo Knott: interesting.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 24
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "said, I do think it's still informative in a different way. uh that says especially if our average is pulling us that hard uh in in difference to the median that tells us that we could potentially have like model loading problems or we could potentially have like an uncompleted completer or we could have various edge cases. 00:24:33 Mark Widman: So I think it's informative but just in a different way. Tsavo Knott: Yeah, the Sam Jones: Oh Tsavo Knott: P75 Sam Jones: yeah, Tsavo Knott: is also Sam Jones: once Tsavo Knott: interesting.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 25
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Sam Jones: we once we check once we've got the distributions, we'll be able to see, okay, look, these users are are Tsavo Knott: Yeah. Sam Jones: deep in the tail there. We can see if we can see any patterns between them. Maybe they're on bad systems. Maybe they're in certain parts of the globe with slow internet. Mark Widman: Yeah. Tsavo Knott: Yeah. Sam Jones: Maybe if there's variance there, then it's like if we see lots of different systems, then it's probably an us problem. Um, but yeah, I think I'm not I'm not trying to discount this. I think it's super useful. I just don't want to jump in the wrong direction. Tsavo Knott: No. And of course, Mark Widman: Is Tsavo Knott: like on our side, if this is going up, like if we just continue to look at the a consistent metric like the P75 or whatever else, if this continues, if this continues to go up, then we're doing something wrong. 00:25:27 Tsavo Knott: But if this goes down, then we're doing something right. Right? So that's kind of where this is just a binary metric, which is saying like, hey, for the way we're looking at it, is it going up or down? And our goal is to make it go down, right? Sam Jones: Yeah, there's also um I agree there's also like a potentially a wider question here which is and you know this is not necessarily the forum for it but are we are we building something that's going to like is our northstar let's make this work for everybody on all machines or is it you know we're building something that's high-spec and going to work for a specific segment of our of our user base in Tsavo Knott: I Sam Jones: a Tsavo Knott: mean, Sam Jones: similar way like you Tsavo Knott: yeah. Sam Jones: can't run Intelligj on a 8 megabyte Tsavo Knott: No, you Sam Jones: like Tsavo Knott: definitely Sam Jones: 8 gigabyte of RAM like Tsavo Knott: I think that you know I think you know for example like the beauty of Google Chrome and the engineering that they got done there was it became the default you know browser for everyone because no matter how bad your device was, it was relatively fast, right? 00:26:38 Tsavo Knott: And if we think about, you know, um like pieces for everyone, you know, our next kind of cohort is like, you know, digital professional workers, if you will. Um if we can make the installation and permissioning setup as simple as Zoom, like if we can get it to the the Zoom level. So if you know how to use Zoom, you can use pieces.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 26
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "know, our next kind of cohort is like, you know, digital professional workers, if you will. Um if we can make the installation and permissioning setup as simple as Zoom, like if we can get it to the the Zoom level. So if you know how to use Zoom, you can use pieces.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 27
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh and also you know if you are a designer or you know you're an animator or you're working on like financial data or whatever else like you know the Chris profile like he's running on a M2 MacBook Air how's that thing look you know um and go from there right so I think like you know for sure the goal is going to be a a broader audience like I don't think we have to support you know someone's MacBook from 2015 15 2017 even like you know those are pretty long periods of time ago. Um and also too if you're not investing in the device you use for work you're probably not that much of a digital professional if you will. 00:27:42 Tsavo Knott: Um, but yeah, I mean, and developers are interesting, too, because their device, so it's funny. Developers are interesting because their device is flooded with a ton of different tools. But normal people, uh, like my mom for example, she's interesting because she doesn't know how to use a computer. So all she'll just leave tons of windows open, tons of tabs open, like everything like that, right? And that's I think like you know more of the my mom is a digital professional right she's a you know clinical psychologist and whatever else and she does all that s*** she does all her research papers for her schools and stuff like that but she yeah her computer's a absolute nightmare right like her desktop's completely flooded ton of windows open you know whole nine yards and I think like that's the type of people where it's like hey you know can my brother Maxon use pieces during med school right or you know And Sam Jones: Yeah. Tsavo Knott: like that's what we're shooting for, right? Sam Jones: Yeah. I um the what I would love and would be super useful is just like a minspec. 00:28:47 Sam Jones: Um Tsavo Knott: Yeah. Sam Jones: so I not now obviously but like as a group maybe we have to for for to help us in terms of like know when we're done. It would be great to have like a couple Tsavo Knott: Yeah. Sam Jones: of minsspec machines. I'm sure M probably find find it pretty useful as well and we can just be like right if it runs on like this we're golden. Um Tsavo Knott: Yeah, Sam Jones: Yes. Tsavo Knott: but I will say the other funny part is uh you know we we had a call with the uh with the Google with Sundar's team and Google Labs went really well. We have a technical diligence call with them tonight at 6 my time. Uh and they're like, \"Yeah, we also want you guys to do research on how this could potentially run on Android.\" Right? So like, you know, you're like, \"f***.\" I mean the devices are you know what I'm saying?",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 28
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Jones: Yes. Tsavo Knott: but I will say the other funny part is uh you know we we had a call with the uh with the Google with Sundar's team and Google Labs went really well. We have a technical diligence call with them tonight at 6 my time. Uh and they're like, \"Yeah, we also want you guys to do research on how this could potentially run on Android.\" Right? So like, you know, you're like, \"f***.\" I mean the devices are you know what I'm saying?",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 29
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So it it is performance will always thing and I think like if our company's mantra is to build good ML systems that run you know in low compute environments like that's where the true IP comes in but that said like it begins at a component by component level if you will. 00:29:53 Tsavo Knott: So, you know, I think having a spec is nice for for an intermediate northstar, but no matter what, if we can get all the systems to just run as best as they can in isolation, like the culminative summation of the systems will be low as well, right? Um, so we'll we'll always have to have an eye towards when to boot these things, when to run them, how are they running, you know, so on and so forth. Um, because the the environment constraint is actually probably just going to only get harder, if you will. Sam Jones: True, Tsavo Knott: Yeah. Sam Jones: true. Tsavo Knott: Yeah. Sam Jones: There's um yeah, we get sandwiched a little bit between time to first token and environment basically, Tsavo Knott: Totally. Sam Jones: but Tsavo Knott: And the Sam Jones: we Tsavo Knott: other Sam Jones: can Tsavo Knott: thing that you got to know is we're not going to be the only one running an ML app in the next decade, right? Like, you know, everyone's going to start running ML apps on device, you know, so on and so forth. 00:30:46 Tsavo Knott: So, you know, even that in my message to the foundry local team the other day, it was like, I'd like to know where I am in the queue to use an ondevice SLM that's at the Windows operating system level, right? So, we Sam Jones: Thank Tsavo Knott: can Sam Jones: you. Tsavo Knott: show the user, hey, it's not taking a long time because it's our app. It's taking a long time because five other apps are requesting a, you know, an SLM to process this data, right? So, like that's another consideration where we generally Sam Jones: Hold Tsavo Knott: have to just make ours as fast as f****** possible. Yeah. Sam Jones: on. Tsavo Knott: Yep. Cool. Um, good chat team. Thanks for checking in on the data. Uh, I got a call with Chris later today. Um, but yeah, on our side, big big big sprints. Uh, we need to have a crazy month in June here. Um, and we're gonna we're going to keep keep doing the stuff on the the growth side. 00:31:37 Tsavo Knott: Um, I think generally word of mouth is starting to be pretty positive for us. You know, people who do make it in and and are enjoying it pretty nice. But, you know, Sam, we still want to get to that, you know, it just works type of type of benchmark. Just get those nano models locked in, stuff like that. Um, and we'll go from there. Yeah. LTM queries per user per day. That's the northstar. Awesome.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 30
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "crazy month in June here. Um, and we're gonna we're going to keep keep doing the stuff on the the growth side. 00:31:37 Tsavo Knott: Um, I think generally word of mouth is starting to be pretty positive for us. You know, people who do make it in and and are enjoying it pretty nice. But, you know, Sam, we still want to get to that, you know, it just works type of type of benchmark. Just get those nano models locked in, stuff like that. Um, and we'll go from there. Yeah. LTM queries per user per day. That's the northstar. Awesome.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 31
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh, any other questions for the group? Smith, anything on your side. Smit Patel: No. Um only thing is hero um I know we have a few of these working groups around um like analytics day on retention all that I think it might be maybe we could just combine it into one even if it needs a longer meeting. Um like Mack Myers: What? Smit Patel: for example Nikil wasn't able to join. I'm not sure why he didn't join. I maybe there was some miscommunication. I want to make sure that you know he doesn't miss the meetings. Um, so maybe just keep one and like let's make make it a point to have it at the same time if possible so that way people are not confused if it's happening or not. Tsavo Knott: Yeah, I think like a engineering weekly equivalent like analytics weekly Smit Patel: Yeah, something like Tsavo Knott: on Smit Patel: that. Tsavo Knott: Fridays, Smit Patel: That's totally fine. Tsavo Knott: Friday mornings. Smit Patel: Yeah, we'll all, you know, make make it a point to show up. Tsavo Knott: Yep, that'd be excellent. Hiro Tamada: Okay, looks Tsavo Knott: Fantastic. Hiro Tamada: good. Tsavo Knott: a bit. So Sam Mark Mack. If you guys could give me a little summary of where you guys are at, I'll throw that into slide for you guys. And then yeah, any demos you guys want to bring would be awesome. We're gonna do a pretty demo heavy. All hands today for folks Smit Patel: Cool. Mack Myers: Cool. Smit Patel: All Tsavo Knott: Excellent. Smit Patel: right. Thanks, bye. Tsavo Knott: Thanks you. But Transcription ended after 00:33:28 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "1W94pT-_JQ4fcfuFgq2TWOqvNbQolXv8PQQoJ_Z4u9gA",
    "chunk_index": 32
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Ôªøüìù Notes May 5, 2025 Understanding Events Trigger Schedule Invited Hiro Tamada Mack Myers Nikhil L Attachments Understanding Events Trigger Schedule New Workstream Activity Onboarding Analytics Events Meeting records Transcript Recording Summary Mack Myers presented detailed event tracking for the new user onboarding flow, focusing on LTM activation, memory formation process, and success/failure metrics based on event patterns and interval data. The system tracks various events, including algorithm version, and uses this data to assess user progress and identify areas for improvement. The updated system is projected to release within 24-48 hours. Details * Onboarding Event Tracking Mack Myers presented the event tracking for the new user onboarding flow (00:00:00). They explained that the initial events focus on the \"Start Forming Memories\" button and subsequent actions, such as LTM activation attempts and user responses to failures (00:01:29). They also noted that success events were not initially tracked for LTM activation, but they would be added (00:05:42). * Error and Success Events The discussion included tracking of various events, including those related to LTM activation failures, retry attempts, and user requests for help (00:02:28). Mack Myers also highlighted the importance of tracking whether users successfully activate LTM and generate 30 memories (00:35:44), and acknowledged the lack of tracking for app closure (00:04:28). They proposed adding a success event for LTM activation to address this gap (00:06:52). * Memory Formation Process Mack Myers described the three triggers for starting the memory formation process: a 15-second timer, an unfocus event, and the formation of a memory event (00:07:48). They explained that only one of these events will trigger the memory formation, and which one triggers reveals insights into user behavior (00:08:57). The process of memory formation is tracked through several events, such as \"formation in progress\" (00:09:54), and includes checkpoints at 2 and 8 minutes to check user progress (00:13:45). * Interval Group Events The system tracks five-minute intervals to assess the health of the memory formation process. These intervals are indicated by events such as \"formation five-minute interval group\" (00:15:57), with data including the number of events and events per minute (00:17:49). Mack Myers explained how they use this data to classify intervals as successful or failed, influencing the overall assessment of user success or failure in memory formation (00:18:51). * Success and Failure Metrics Mack Myers detailed how the system determines success or failure based on several factors, including the total number of events generated within the 35-minute timeframe and the pattern of successful and failed intervals (00:18:51). They clarified that less than 10 events in 35 minutes indicates failure (00:20:05), whereas more than 10 events with a pattern indicating continued activity lead to a success classification. Mack Myers emphasized the use of interval patterns (represented by O's and X's) to distinguish between likely system errors and user inactivity (00:21:34). * Algorithm Version Tracking To facilitate analysis across different algorithm versions, Mack Myers described incorporating algorithm version information into the events. They indicated a plan to add an explicit algorithm version number to improve analysis (00:22:37).",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 0
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "the pattern of successful and failed intervals (00:18:51). They clarified that less than 10 events in 35 minutes indicates failure (00:20:05), whereas more than 10 events with a pattern indicating continued activity lead to a success classification. Mack Myers emphasized the use of interval patterns (represented by O's and X's) to distinguish between likely system errors and user inactivity (00:21:34). * Algorithm Version Tracking To facilitate analysis across different algorithm versions, Mack Myers described incorporating algorithm version information into the events. They indicated a plan to add an explicit algorithm version number to improve analysis (00:22:37).",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 1
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "The aim is to make it easier to differentiate user cohorts using different algorithm versions (00:23:41). * Additional Events and Post-Onboarding Flow Mack Myers mentioned that the welcome and authentication pages already have event tracking, which they would share later (00:36:51). They presented data on the post-onboarding flow, tracking user interactions with the power menu and co-pilot (00:32:50). The final event in the flow, indicating successful transition to the co-pilot, acts as a key indicator of successful user flow (00:35:44). * Timeline and Conclusion Mack Myers stated a projected timeline of 24-48 hours for the release of the updated system to general access (00:37:44). The primary high-level conclusions to be drawn from the data will focus on the rate of successful LTM activation and the number of users successfully forming 30 memories (00:35:44). They also highlighted the \"I need help\" button clicks as a key indicator of users experiencing issues (00:26:19). Suggested next steps * Mack Myers will add a success event for LTM activation and double-check the events for the transition from LTM to co-pilot. * Mack Myers will ensure the power menu has an event and that co-pilot button clicks are tracked. * Mack Myers will list the events from the welcome page and the authentication page. You should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes Please provide feedback about using Gemini to take notes in a short survey. üìñ Transcript May 5, 2025 Understanding Events Trigger Schedule - Transcript 00:00:00 Mack Myers: Sweet. And then this. And then let's just I don't know where I'm at there, but I'll just grab the sling latest staging build. We'll run through it live. See how it works. It's not f*****. Okay. So, so this stuff didn't none of the events on that page have anything to do with this sort of part of the journey. This stuff is all it all exists. It's kind of like desktop onboarding, toggle light theme, desktop onboarding, toggle dark theme. We already have those events. I'm happy to resurface them if you guys need. Same thing with sharing crash data, getting started. Um, Nikhil L: Mhm. Mack Myers: this page is still undergoing. We're we're we're moving in the direction of like a more normal loginup feel. Um, but these events also don't change. You know, it's, you know, sign up, successful sign up, stuff like that. Again, I can surface those if you need, but where the events on that document start to begin is right here. 00:01:29 Mack Myers: And so this button and this button, these are going to be the only two buttons available on screen for a new user. This is going to be disabled and this is going to be disabled. And so I'll tell you what corresponds. Uh let's see here. So basically this button right here and I've got to take a look and see I maybe don't have tracking on this one. This one will have tracking and this will have tracking. This start forming memories button.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 2
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "you need, but where the events on that document start to begin is right here. 00:01:29 Mack Myers: And so this button and this button, these are going to be the only two buttons available on screen for a new user. This is going to be disabled and this is going to be disabled. And so I'll tell you what corresponds. Uh let's see here. So basically this button right here and I've got to take a look and see I maybe don't have tracking on this one. This one will have tracking and this will have tracking. This start forming memories button.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 3
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "When Nikhil L: Mhm. Mack Myers: a user clicks that it's going to fire this event onboarding workstream activity start forming memories button. Nikhil L: Okay. Mack Myers: So that's like the very first essential like entry point into the flow. Nikhil L: Okay. Mack Myers: And so uh that's that event. And then there's a couple things that can happen when I click this button. So if Nikhil L: Mhm. Mack Myers: I'm on Windows, what's going to happen is it's going to jump immediately to this LTM activation state where the dialogue Nikhil L: Okay. 00:02:28 Mack Myers: that pops up is going to try and automatically activate LTM. And these are sort of like fail cases. I'm not sending an event when it succeeds, which I totally could do, but I'm not currently doing that. I'm only sending events if they if there's problems. And so if if there's a problem, the user will have the ability to retry the connection or retry the activation of LTM. And that's these buttons. So if they click retry and it fails, you're going to get a failed event. If they get a retry, if they click retry and it succeeds, you're going to get this retry success event. If Nikhil L: Okay. Mack Myers: they are if they find themselves in a situation where they've tried to retry more than two times, they're going to get presented with these options which are their sort of like out essentially. It's I need help which is basically them essentially telling us they're trying Nikhil L: What Mack Myers: this Nikhil L: the Mack Myers: thing's not working. They need help. 00:03:26 Mack Myers: Great. It'll kick them out to a support page where they can get in touch. Create GitHub issue. Very similar thing. slightly different psychologically is just you know I want to go create a GitHub issue and something's still wrong failure explore pieces copilot button it's very possible Nikhil L: It's Mack Myers: that Nikhil L: not Mack Myers: the same user could click this they could click this as well this is basically you're not going to be able to get activated with LTM because something on your system is preventing it but you still want to be able to explore other features of the app go check out the co-pilot and in this case they'll they'll basically jump they'll skip a lot of this stuff because they won't get it and then they'll go into um they'll basically hit something like this the onboarding power menu introduction continue button they'll go open the power menu potentially uh check out like we don't the only important thing to note there is that we want to keep a track of how many users are failing to get up and running with LTM I think that's like the key data point There 00:04:28 Nikhil L: Okay. Okay. one one question here.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 4
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "because they won't get it and then they'll go into um they'll basically hit something like this the onboarding power menu introduction continue button they'll go open the power menu potentially uh check out like we don't the only important thing to note there is that we want to keep a track of how many users are failing to get up and running with LTM I think that's like the key data point There 00:04:28 Nikhil L: Okay. Okay. one one question here.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 5
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh so we are not tracking the success event and we are like assuming by default the success will happen but uh in case it doesn't happen we have this failed event but let's say user is stuck between these two in any h edge cases. So is there any way to notify us through event or something or telemetry or whatever? Mack Myers: for for which case exactly? Nikhil L: Uh I mean there could be some HPS right so let's say if there perpetual retry some happening on the user device it's not success and it's not failure or something. All Hiro Tamada: Basically Nikhil L: right. Hiro Tamada: like are um are there case that like user just drop off but there's no failure like is there can we distinguish doing like user just like not going through the event versus um there's was any failure Mack Myers: Um I mean like maybe uh the Nikhil L: Yes. Mack Myers: Only way for them to drop off at this point right here would be for them to they'd have to quit the app. 00:05:42 Hiro Tamada: You can. Mack Myers: Uh, which I don't exactly have like a hook to like know that the user quit the app. Um, does that make sense? I mean I Yeah, because Hiro Tamada: Yeah. Mack Myers: I I don't give them like a close button or anything like that. It's just like if this thing fails, they could they could quit. They could not click any button and they could quit. Um if it's Yeah, if it succeeds, it's just going to take them to the next page. But yeah, I otherwise it's like maybe maybe if pieces OS like crashes, which again I I don't exactly I wouldn't exactly know about here. Um, so Hiro Tamada: Um Mack Myers: it's kind of kind of tricky like those those little cases you're talking about. Hiro Tamada: I if then it's not a big lift I think like having success event will be nice then I think like just Mack Myers: I can add a success event. For what it's worth, these are also a proxy for a success event because if a 00:06:52 Hiro Tamada: Okay. Mack Myers: user gets in here, I know it's probably easier just to measure the one event, but like if they get into any of these, we know that they had success activating LTM. Hiro Tamada: Okay. Mack Myers: Uh, so let me just make a note because I think it's probably a good point to try and add a success here. Success LTM activation success. Yeah, we can do that. That's no problem. You guys want me to keep going? Any other thoughts or questions before I keep going? Hiro Tamada: I think. Yeah, Nikhil L: No Hiro Tamada: let's keep Nikhil L: is Hiro Tamada: going. Nikhil L: good. Mack Myers: Nice.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 6
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "LTM. Hiro Tamada: Okay. Mack Myers: Uh, so let me just make a note because I think it's probably a good point to try and add a success here. Success LTM activation success. Yeah, we can do that. That's no problem. You guys want me to keep going? Any other thoughts or questions before I keep going? Hiro Tamada: I think. Yeah, Nikhil L: No Hiro Tamada: let's keep Nikhil L: is Hiro Tamada: going. Nikhil L: good. Mack Myers: Nice.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 7
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um, so these events basically, so what's going to happen is I'm going to click this and it's going to happen like pretty quickly where you might see a little screen that's like verifying LTM2 and then it's going to hit this. Did you see it? So it verified LTM2. LTM2 at this point is officially on. And now they're here. 00:07:48 Mack Myers: Pieces is ready to form memories. And that's where you start to get into these couple of events. So there's three timers that are happening. And we just hit one. So what happens there is let me quit this. So in that what in that flow where you just saw when I land on that dialogue in that state there's three timers that are essentially keeping track of what the user is doing in order for us to be notified to start this whole process of forming memories. So the first timer is uh a just a general 15-second timer. So if the user's on that page and just looking at the screen for 15 seconds reading it, after 15 seconds we're going to start forming. The other timer is an unfocus event. So if they leave the desktop app and go to any other app and the desktop app no longer has focus, that will trigger the start for forming memories. The third one is if they have an event that's formed. So if for some reason they've been like looking at the app and there's some sort of an event that's like a memory that's formed. 00:08:57 Mack Myers: If that happens then we will start. So it's a race. Whichever one of these happens first will trigger the the formation of the memories to start its loop. Does that make sense? So then this so like depending on which one wins this is actually like an interesting little point of data. They kind of reveal slightly different things. So, like if the timer is the start, maybe our messaging was a little too long, maybe it was a little unclear, they didn't know exactly what to do. If it was an unfocus that was a start, we kind of get like, okay, they kind of understand what to do. Uh, they left the desktop app, they went about their work, it made sense. If there's an event that was the start, I think for what it's worth, I don't think we're going to see this really ever. It's possible, but if that is the case, it'd be kind of weird. So, I don't really have a good explanation of like what that would translate to, but we'll just keep an eye on it. 00:09:54 Mack Myers: So, this will tell us what the trigger was. And then this will tell us that the the loop started. So, now the user's in this loop where behind the scenes pieces LTM is running and we've asked the user to go and do work so that we can start forming long-term memories.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 8
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "to see this really ever. It's possible, but if that is the case, it'd be kind of weird. So, I don't really have a good explanation of like what that would translate to, but we'll just keep an eye on it. 00:09:54 Mack Myers: So, this will tell us what the trigger was. And then this will tell us that the the loop started. So, now the user's in this loop where behind the scenes pieces LTM is running and we've asked the user to go and do work so that we can start forming long-term memories.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 9
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "And so, that's when we start to hit this formation in progress situation. And this Nikhil L: One Mack Myers: is Nikhil L: one Mack Myers: like Nikhil L: question sorry Mack Myers: Yep. Nikhil L: one one question for the previous one. So Mack Myers: Yep. Nikhil L: out of those three top events only one will be activated for a single user right. Mack Myers: Correct. Nikhil L: Got it. And and then the fourth one will start the memory creation event formation Mack Myers: Yep. Nikhil L: event. Mack Myers: So a healthy a healthy situation would be every user has two. They have one of these three and then this one. Nikhil L: Understood. Mack Myers: Yep. Nikhil L: Okay. Okay. Mack Myers: Yep. Uh, anything else before I keep going? 00:10:49 Mack Myers: Nice. Good thing we're recording it because I know I'm going fast. Uh, but Yep. So, the formation. So, let me just show you guys again real quick. You guys started to see the formation, but I want you to see it again. Is we'll like get into it. This is the sort of meat of the whole the whole experience here. Okay. So, I'm going to remove focus. Notice how it started after I remove focus. So, so now we're in the process of forming memories. So, behind the scenes, we're just in like a recursive loop. And that loop has checkpoints. And the whole intention behind this loop is that we're going to set a timer in place for to generate their first 30 long-term memories. And that's the ultimate goal is generate 30 memories. This successfully completed event essentially means that the user uh the user generated their first 30 summaries within 35 minutes successfully. That's basically what that means. And so these other things are indicators of health failures the pace at which they're generating memories. 00:12:27 Mack Myers: uh problems with the underlying system I can go through them you know individually and so on but at different markers certain things will happen and so uh let's start these are error events so event summarization AOT error so like that's an interesting one hero and what I'll tell you that translates into is this so formed from Google Chrome around analyzing onboarding analytics events this summary right here. Every time an event gets generated or like a memory gets generated and you know the desktop app picks up on that, we're going to basically take that latest event on our snapshot and send it to the AOT and the AOT is just going to give us like a little summary of what what was the user doing during that time period. And this event indicates that that AOT call had an error. Hiro Tamada: Okay, that makes sense. Mack Myers: So that's that one, the event snapshot error.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 10
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "picks up on that, we're going to basically take that latest event on our snapshot and send it to the AOT and the AOT is just going to give us like a little summary of what what was the user doing during that time period. And this event indicates that that AOT call had an error. Hiro Tamada: Okay, that makes sense. Mack Myers: So that's that one, the event snapshot error.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 11
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So every five seconds, this thing is going to call pieces OS to get an up-to-date snapshot of the user's events, which events long-term memories, that's what I'm those are the same thing in this context. 00:13:45 Mack Myers: But that event will indicate that there's an error with the snapshot. really shouldn't be the case, but potentially there's some data that got corrupted or who knows like if there was some reason that snapshot failed, we'll send that event. The next thing is this um no events at two minutes. So no events at two minutes and then no events at 8 minutes. These are two like key kind of checkpoint markers that we have in place to see is this user is this user having success with this or not? And so we could basically say, you know, you you'll see that I just from going back and forth between this one page, I've generated three memories in in that two minutes. If they've generated zero in that two minutes, there's a couple things. Either one, they could have walked away from their computer and we're not capturing it. Two, there's a problem generating the memories and forming the memories, so they're not getting saved properly or something like that or erroring out in the back end. uh the users they're not quite getting it quite yet. 00:14:49 Mack Myers: Now we what we do at that that milestone is we just add a little tip up here that's like don't forget you need to go and do work in order for us to form memories. So we give them like a little nudge and then the eight minute interval at at eight minutes if they still have zero summaries we show a support state. So we're like something's wrong here. they've either left their computer, uh they're getting errors behind the scenes that we're unaware of, something's wrong. If they hit that, we're going to basically remind them how memories are formed by going to different apps, context switching, uh scrolling on different web pages, stuff like that. Um, and we're also going to give them the opportunity to hit support. And so, uh, yeah, that's where some of these, um, yeah, this idling UI, that's where these two buttons come into play where give it more time button. So, one of the buttons on the screen is like, I I'm here, you know, give it more time. I I think it's working. 00:15:57 Mack Myers: It's just going slow. I haven't been doing a lot or maybe I've been away from my computer. Give it more time. idling launch support is I've been doing what you're telling me to do. Something's wrong. I need support. Um, and so those would be two indicators of they need help. Does that make sense? Hiro Tamada: Yeah. Yeah, that makes sense. Mack Myers: This five minute interval group is a is probably one of the more like rich data events. There's like a variety of data that I send over.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 12
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "more time. I I think it's working. 00:15:57 Mack Myers: It's just going slow. I haven't been doing a lot or maybe I've been away from my computer. Give it more time. idling launch support is I've been doing what you're telling me to do. Something's wrong. I need support. Um, and so those would be two indicators of they need help. Does that make sense? Hiro Tamada: Yeah. Yeah, that makes sense. Mack Myers: This five minute interval group is a is probably one of the more like rich data events. There's like a variety of data that I send over.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 13
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Let me actually send you guys this. Yeah. We are going to the whole time in this loop we are tracking certain things um to measure sort of like the health of the Hiro Tamada: Target. Mack Myers: whole situation. Um and some of that data this formation five minute interval group we will always send we're capturing sort of an an interval of the last five minutes um to see kind of what happened here. And so this is an example of one of those five minute interval groups where it's going to give you a snapshot of that interval and the occurrence that that interval is sort of at. 00:17:49 Mack Myers: So it'll it'll be somewhere between like one through seven. One being the first five minutes, two being the second five minutes, three being the third five minutes, etc. A good healthy user should really not get to like intervals three, four, five, six, seven. If we start seeing intervals like that, that means that those users had a like they may have had success, they may have had a failure, but they didn't quite have as efficient of a process as other users. Does that make sense? So, we capture Hiro Tamada: What's Mack Myers: some of these things. Um, the minute marker that they're at, 5, 10, 15, 20, 25, 30, 35, the number of events that happened in that five minute interval, uh, the events per minute, which is just some quick math to to try and be helpful. um events per minute. Like this would be a really f****** healthy interval. This is like a like perfect interval. 26 events in five minutes. That's that's probably a little bit unlikely, but that's really healthy. 00:18:51 Mack Myers: It's when we start to see the events per minute be less than like one or two where it starts to veer into the unhealthy category. Something's either slow on their machine, something's maybe getting tripped up. That's the user's kind of in and out a lot. That's an indicator of like lower health. A failure or I should say a success is if they've had more than if they've had one or more events in an interval, it's a success. Hiro Tamada: Um, Mack Myers: This is Hiro Tamada: sorry. Mack Myers: Yep. Hiro Tamada: What do you mean by that if if the user has like seven or eight more than seven or eight occurrence user is not healthy? Meaning that like it Mack Myers: if Hiro Tamada: should Mack Myers: if we start to see so the maximum occurrences that they could have is seven um because we we basically time out the entire experience around 30 at 35 minutes. So at the 35 minute marker, if the user still has not generated, that's where some of this comes back in. At the 35 minute marker, if the user has not hit their 30th event, there's a couple of different cases that we indicate 00:20:05 Hiro Tamada: I Mack Myers: like Hiro Tamada: see.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 14
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "or eight occurrence user is not healthy? Meaning that like it Mack Myers: if Hiro Tamada: should Mack Myers: if we start to see so the maximum occurrences that they could have is seven um because we we basically time out the entire experience around 30 at 35 minutes. So at the 35 minute marker, if the user still has not generated, that's where some of this comes back in. At the 35 minute marker, if the user has not hit their 30th event, there's a couple of different cases that we indicate 00:20:05 Hiro Tamada: I Mack Myers: like Hiro Tamada: see.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 15
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Mack Myers: this user had success or this user kind of failed. And Hiro Tamada: I Mack Myers: so Hiro Tamada: see. Mack Myers: if they had 10 under 10 events within that 35 minutes, we declare that a failure. something just wasn't right because it really it really should like this thing is taking snapshots every two seconds like it should really be forming multiple events per minute. Uh so if they had less than 10 in 35 minutes something was off. Hiro Tamada: Makes sense. Mack Myers: Uh this is like okay we're going to send a flag if they hit 35 and they did have over 10 events we'll send a flag here. But if they have over 10 or more events, then we do some math to try and see like what was the breakdown of those intervals and a good success. Let me see if I've got um short circuit in here. Okay. So, this right here is sort of how we're measuring. If they get again, if they get to 35 minutes and they have less than 10 events, we're going to run a little bit of math to figure out what was the sort of pattern of their 35 minutes. 00:21:34 Mack Myers: And so, each one of these O's and X represents one of those interval groups. And so an X is a failed interval group where they didn't have any events form. An O is a successful interval group uh interval group where they did have events form. If their pattern looks something like this where they started off with some events and then they ended with some events, we'll think that the system is is online and healthy enough to have declared that a success. Um and the reason is and this is again keep in mind this user has more than 10 events that formed. So it could be five and five, it could be two and eight, whatever it is, they were able to generate enough that maybe they left and came back to their computer or maybe they were just not doing a lot of work at that time. Like we don't think that this is a problem with our system functioning. If it's something like this where they started off slow, they picked up a little bit and then they, you know, ended success, uh, we're going to also declare that a success. 00:22:37 Mack Myers: These are the fails where maybe they started off with something and then we got nothing afterwards. Maybe the system was crashing. Maybe things were running really slowly and they couldn't use it. Who knows? But this is a pattern of failure. This is also a pattern of failure where we had nothing nothing nothing. Maybe the system failed to boot or who the f*** knows? But these would be some fail cases.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 16
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Myers: These are the fails where maybe they started off with something and then we got nothing afterwards. Maybe the system was crashing. Maybe things were running really slowly and they couldn't use it. Who knows? But this is a pattern of failure. This is also a pattern of failure where we had nothing nothing nothing. Maybe the system failed to boot or who the f*** knows? But these would be some fail cases.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 17
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "We could always modify this, but that's where this stuff this these data points right here come into play because these these three properties will always be top level on all of these events because these will basically tell you which version of the algorithm was running. So in this case the first one is the five you know the five minute interval algorithm with max intervals of seven and a max inter max time at 35 minutes. That's the version of the algorithm essentially that's running. I could also add like an algorithm version on here like one if that's helpful, which probably makes sense. 00:23:41 Mack Myers: But we we we intend to potentially modify this stuff over time. And from an analytics perspective, we want to make it easy for you guys to distinguish between what was a user cohort cohort using this algorithm versus what was a user cohort on this algorithm and so on. Does that make sense? Hiro Tamada: But essentially any of these can be um calculated by the row events, right? Like we we going to have like a list of five minute interval events. So like we we should be able to kind of like uh recalculate what you're doing on analytics side as well, right? Mack Myers: Yep. I'm trying to make it easy for you. Hiro Tamada: Okay. Mack Myers: Yep. Um, yeah. So, let's see where I landed here. So, I'm still forming. So last 12 minutes. So at this point in time, I should have had I should have sent two interval groups to the analytics um at this point. So you can see I've got a ton of logs. So if you guys pull down the staging build, you'll be able to see this stuff. 00:24:54 Mack Myers: Um so here's our race to start. basically the window of focus lost. So that was the event that ended up sending. Um and then we'll see 300. So a tick represents a second. So at tick 300 is our first five minute mark. So you'll see um yeah five minute interval group. This was the first occurrence. Minute five. I had four events. I had yeah 0.8 8 events per minute, which is, you know, not not not great. Um, and then yeah, there should be analytics events for that stuff. Uh, and then it keeps going. So, there should be a second one at tick 600. Yep. Um, yep. So there's our occurrence two minute 10 events seven events per minute in that group was 1.4. So is that yeah they had seven events in that five minute session. So they had a little bit over one event per minute. Yep. And then I do believe I'm also I think that with the analytics event I also send you both of the intervals that have occurred. 00:26:19 Mack Myers: So there's just data with it. Um so that's the 35 minutes. Uh it's possible and this is the report success report failed.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 18
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "600. Yep. Um, yep. So there's our occurrence two minute 10 events seven events per minute in that group was 1.4. So is that yeah they had seven events in that five minute session. So they had a little bit over one event per minute. Yep. And then I do believe I'm also I think that with the analytics event I also send you both of the intervals that have occurred. 00:26:19 Mack Myers: So there's just data with it. Um so that's the 35 minutes. Uh it's possible and this is the report success report failed.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 19
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "So that like X's and O's thing. Um if we kind of track their report and we deem it was a success, you'll get this event report success. Um if we deem it was a fail, then we'll get the report failed. Um and then yeah that in so any user who goes through this unless they quit it they should get a successfully completed an interval report success an interval report failed or a under 10 events failed basically Hiro Tamada: Makes sense. Mack Myers: um if their if their thing failed there's they're going to get a new UI UI. Uh their UI, there's a couple different things there, but they have an I need help button. Um so we'll probably want to keep track of how many people are clicking the I need help button. That's a pretty good indicator of how many people have kind of failed. Um obviously it will be a multiple of that because only a certain amount of people will click. 00:27:35 Mack Myers: Uh these are their outs. So we think that they won't have success with LTM. So, we're going to tell them to explore co-pilot or explore the drive. Those are those events. Um, we also, depending on their state, we give them a button to generate their first summary if it hasn't generated already. Um, and that can indicate a success or fail. So, if there's people that are clicking generate now button and they're having failures, it's a good indicator that something's wrong. on the success front. So there's two events. Uh so if the user hits a success, they're going to get a single button basically that says I'm ready. And depending on which route they got to success, um that might be a slightly different event. So if it's just a pure this was a good event or good situation, nothing wrong, it's just going to be success, I'm ready button. Um, if they hit a failure like on here and uh let me think about this for a second. Success from failed. 00:28:47 Mack Myers: I do believe that if they have a success generating a summary, I convert this to a success from failed. And then if they click I'm ready from there, that's this event. So they kind of failed it and then they kind of had a success. So we're like, \"Okay, let's air on a success.\" That's the success from failed. I'm ready button. Um and then trying to think, yep, that's pretty much the majority of these events you'll see in here. There's just other like just other mile markers basically. Um these are events like uh you know if the user hits their 30 memory marker which is the success basically you know kind of taking a gander of what happened um or what the state of their system is. So 30 memory marker no summaries. If the user hit the 30 memory marker and they don't have a summary that generated yet, we're going to generate one for them.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 20
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "from failed. I'm ready button. Um and then trying to think, yep, that's pretty much the majority of these events you'll see in here. There's just other like just other mile markers basically. Um these are events like uh you know if the user hits their 30 memory marker which is the success basically you know kind of taking a gander of what happened um or what the state of their system is. So 30 memory marker no summaries. If the user hit the 30 memory marker and they don't have a summary that generated yet, we're going to generate one for them.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 21
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "This is also an interesting indicator of like if if they hit this, it's likely that they were able to form their memories pretty quickly. 00:30:10 Mack Myers: Um because pieces OS hasn't been able to autogenerate a summary yet. 30 memory marker one summary. This is an indicator that maybe it was a little slower um because pieces OS had already formed its first memory based off of its initial boot up periodic. If they have a summary already generated, we're going to look at it and the goal is if their summary has less than 10 events associated with it, that indicates to us that maybe it's a kind of scarse summary. There's not a lot of data with it. So we're going to generate another one for them that hopefully has more data which should have somewhere around 20 events. So it should indicate you know more data. If they that's this under 10. If they have one summary and it's over 10 events then that indicates to us that their one summary probably has a good amount of data with it. Um we're not going to generate a new one for them. if they have over one summary. Uh I don't know if we'll see that very much, if at all. 00:31:20 Mack Myers: But it's a case I don't know what conclusions we'll draw from it, but it would be kind of weird. Just kind of a weird edge case. Um yeah, it's pretty much most of these. this last one here. Um, so I want to hit a success. So up to 15 till it's good with me. I'm going to have to jump here soon. Yes. Give me. Let's see. Come on. Generate some memories. Group tickets count deletion. We're getting closer. I just want you guys to see the full the full loop here. Weekly summaries. See what we get. See how it's like pretty quickly forming memories when you're like actually doing stuff. Oh, there we go. Okay. Uh, so this is like a success basically experience. Um, you can see the I'm ready button. Uh, you now have 30 memories in counting. 30 memories form in 21 minutes. Capture context from five sources. 00:32:50 Mack Myers: We do pass along the number of sources that users are interacting with along with some of these events. So we can kind of get a sense of, you know, what are the sources that users are using. Are they more? Are they less? Whatever. Um, we generated one work from activity summaries. You can see that in the background. Um, I'm ready. So, this is going to dispose of that dialogue. And then we're going to give the user 15 seconds to check out their first summary. As you can tell, like this is a pretty good rich data summary. It had 24 events in it. Um, there's like all kinds of stuff that they could explore in here. Blah blah blah blah blah. And so now notice this this pulse.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 22
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "sources that users are using. Are they more? Are they less? Whatever. Um, we generated one work from activity summaries. You can see that in the background. Um, I'm ready. So, this is going to dispose of that dialogue. And then we're going to give the user 15 seconds to check out their first summary. As you can tell, like this is a pretty good rich data summary. It had 24 events in it. Um, there's like all kinds of stuff that they could explore in here. Blah blah blah blah blah. And so now notice this this pulse.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 23
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Um, I do believe that the power menu I need to look at the power menu. Make sure that this has an event. I'll make sure that that's there. But basically, we'll we'll click we'll track how many times user clicks this. 00:33:45 Mack Myers: Um because this is we we want them to basically we want to bridge the gap between this and now the co-pilot. And so we're going to guide them to check out the power menu. We give them this little meet your power menu. Navigate anywhere and take action on any view and pieces. Um here's the hotkey. Continue. That's this desktop app onboarding power menu introduction continue button. That will be for users who experience the power menu for the first time. We're trying to just tell them like when in doubt, tap the home button. Um, great. Continue. It's going to show them this. Here's your full power menu. Great. Notice how we've got the the co-pilot highlighted and kind of indicating to the user that's what we want them to click. Uh, I don't think that I track that currently. maybe co-pilot button click as well and make sure that these are tracked and then cool. Now you're over here in the co-pilot. 00:34:41 Mack Myers: There's a couple different avenues that they can go but we're just calling out these two main bucket features. Uh the first one which is this their ability to change their language model. Great. Cool. And then the second one which is going to go to activate LTM context and again bring what they just did informing their memories into the co-pilot and indicate to them they can now interact with this stuff. So we'll have them activate it and then now you can see uh summarize what I was up to my recent work stream. We want them to click that. It's going to give them a pretty dope summary hopefully of what they just did. And now hopefully just with one click they can see that pieces copilot has access to their LTM memories. Um there you go. Hiro Tamada: Okay, that makes sense. Mack Myers: Yeah. Weekly product sync. It's got all kinds of s***. Looks like it did a fantastic job, too. It's like f***. Yep. 00:35:44 Mack Myers: Makes sense. Nikhil L: Yeah. Yeah. I mean so from the LTM when the transition happens from the LTM thing to the co-pilot where user can use the LTM thing that last event that you shared that would be the primary indicator that user flowed uh correctly from LTM to the co-pilot right Mack Myers: Yeah, I need to double check the events for that which I'll do today. But yeah, it's it look in a very ideal world a user follows the the blue lights and clicks everything how we want them to. Um it's very possible that they get sidetracked and go do something different.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 24
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "co-pilot where user can use the LTM thing that last event that you shared that would be the primary indicator that user flowed uh correctly from LTM to the co-pilot right Mack Myers: Yeah, I need to double check the events for that which I'll do today. But yeah, it's it look in a very ideal world a user follows the the blue lights and clicks everything how we want them to. Um it's very possible that they get sidetracked and go do something different.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 25
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Uh but but yeah and and for what it's worth too like if the user quits the desktop app and comes back the state of those blue pill those blue pulsing things it'll still be there. So it's possible that they like leave and come back and do it at a later time. So you know I'd factor that in. I think the most one of one of the more important things for us to track in this is is the user able to successfully activate LTM and is the user successfully able to form 30 memories or not. 00:36:51 Mack Myers: Um from like a very high level I think those are some of the more important things to draw conclusions from. And if they're not, h how many people are not able to activate it? How many people kind of come into the support? And we're we're being pretty we're being very opinionated with this where we're basically not letting the user use the application if they can't get up and running with LTM. Uh and so it's it's pretty opinionated. So I think we're just really trying to understand what's the ratio of people who are having success to failure out there in the wild. Nikhil L: Yeah, understood. Understood. And can you do also do one thing? So you also mentioned that uh the first page, the welcome page as well as the next page which is the authentication page. They do already do have some event but it's not listed on the sheet. If you can list it down then I can use it. Mack Myers: Yeah, but I can get those for you. Nikhil L: Nice. 00:37:44 Nikhil L: Nice. Thank nice thanks. That was good. Mack Myers: Get those for you for sure. That's interesting. Let me just make a note in this doc. And then nice. What do you guys think? What's your sort of first impression of that stuff? What are you guys thinking about it? It was a nice little demo there. Hiro Tamada: Yep. Nikhil L: Yeah. Hiro Tamada: I I like it. Um yeah, I guess we'll see. Uh so this these events are not there yet, right? I guess do we Nikhil L: Yeah. Hiro Tamada: have these? Mack Myers: Say it again. Hiro Tamada: What? So like these events going to start flowing through soon. Um and Mack Myers: Yeah, Hiro Tamada: yeah. Mack Myers: they're just if any are flowing through right now, it's just our team. Hiro Tamada: Okay. Yeah. Mack Myers: Yeah. Hiro Tamada: Okay. Sorry. Um, yeah, one thing, Nico, like we realize that there are a lot of OS ids that are from P.app and I'm I'm trying to fix it today, but that's something that we should be mindful about. But yeah, thank you so much for your time. Mack Myers: Yeah, thank you guys. Let Nikhil L: Yeah. Mack Myers: me know. Nikhil L: Is there any timeline when this will be released for the general access?",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 26
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "they're just if any are flowing through right now, it's just our team. Hiro Tamada: Okay. Yeah. Mack Myers: Yeah. Hiro Tamada: Okay. Sorry. Um, yeah, one thing, Nico, like we realize that there are a lot of OS ids that are from P.app and I'm I'm trying to fix it today, but that's something that we should be mindful about. But yeah, thank you so much for your time. Mack Myers: Yeah, thank you guys. Let Nikhil L: Yeah. Mack Myers: me know. Nikhil L: Is there any timeline when this will be released for the general access?",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 27
  },
  {
    "speaker": "Unknown",
    "timestamp": "",
    "text": "Mack Myers: Hopefully sometime within the next 24 or 48 hours. Nikhil L: Ah, nice. Mack Myers: Yeah. Okay, Nikhil L: We'll Mack Myers: you Nikhil L: have Mack Myers: guys Nikhil L: something. Yeah. Nice. Thank you. Thank you very much for the call. Hiro Tamada: Thank you. Mack Myers: Thank you. Yeah, Holler. If you guys have any questions, you need anything, happy to help. Hiro Tamada: Thank you. Mack Myers: Yes. Transcription ended after 00:39:27 This editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "source_id": "1e2ZBqEwyNClxCWOGjSyQ1oS4voSe0dqL7OKFFiXUOmM",
    "chunk_index": 28
  }
]